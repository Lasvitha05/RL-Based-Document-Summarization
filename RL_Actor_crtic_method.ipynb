{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZwrh3FY-c1r",
    "outputId": "e06e7165-818a-481b-acde-86368972de57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUS7OwUS-WBc",
    "outputId": "fe6c50fa-7e22-4d51-b6d7-f45c11d73546"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rouge import Rouge\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"Reviews.csv\",nrows=5000)\n",
    "# Drop Duplicates and NA values\n",
    "data.drop_duplicates(subset=['Text'], inplace=True)  # dropping duplicates\n",
    "data.dropna(axis=0, inplace=True)  # dropping na\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "data['Text'] = data['Text'].apply(preprocess_text)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(data['Text'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data['Text'], data['Summary'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "empty_summaries = y_train[y_train == '']\n",
    "if len(empty_summaries) > 0:\n",
    "    print(\"Found {} empty summaries in y_train.\".format(len(empty_summaries)))\n",
    "    # Handle empty summaries as needed (e.g., remove them from the dataset)\n",
    "# Handle empty summaries in y_train (e.g., remove them)\n",
    "y_train = y_train[y_train != '']\n",
    "\n",
    "# Pad sequences\n",
    "max_length = 100  # Assuming maximum sequence length\n",
    "# Pad sequences with zeros and apply masking\n",
    "X_train_padded = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\n",
    "X_val_padded = tf.keras.preprocessing.sequence.pad_sequences(X_val_seq, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Masking for padded tokens\n",
    "mask = (X_train_padded != 0).astype(float)\n",
    "\n",
    "# Actor-Critic model\n",
    "class ActorCritic(tf.keras.Model):\n",
    "    def __init__(self, num_actions, vocab_size):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        # Actor network\n",
    "        self.actor = tf.keras.Sequential([\n",
    "            tf.keras.layers.Embedding(vocab_size, 128, input_length=max_length),\n",
    "            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "            tf.keras.layers.GlobalMaxPooling1D(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(num_actions, activation='softmax')\n",
    "        ])\n",
    "        # Critic network\n",
    "        self.critic = tf.keras.Sequential([\n",
    "            tf.keras.layers.Embedding(vocab_size, 128, input_length=max_length),\n",
    "            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "            tf.keras.layers.GlobalMaxPooling1D(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, state):\n",
    "        # Forward pass for actor network\n",
    "        action_probs = self.actor(state)\n",
    "        # Forward pass for critic network\n",
    "        value = self.critic(state)\n",
    "        return action_probs, value\n",
    "\n",
    "# Custom loss functions\n",
    "def actor_loss(action_probs, advantages):\n",
    "    return -tf.reduce_mean(tf.math.log(action_probs) * advantages)\n",
    "\n",
    "def critic_loss(value, returns):\n",
    "    return tf.reduce_mean(tf.square(returns - value))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Training function\n",
    "def train_step(actor_critic, states, actions, returns, advantages):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        action_probs, values = actor_critic(states)\n",
    "        # Calculate actor and critic losses\n",
    "        actor_loss_val = actor_loss(action_probs, advantages)\n",
    "        critic_loss_val = critic_loss(values, returns)\n",
    "        total_loss = actor_loss_val + critic_loss_val\n",
    "    # Compute gradients\n",
    "    grads = tape.gradient(total_loss, actor_critic.trainable_variables)\n",
    "    # Apply gradients\n",
    "    optimizer.apply_gradients(zip(grads, actor_critic.trainable_variables))\n",
    "    return total_loss\n",
    "\n",
    "# Example usage\n",
    "num_actions = 10  # Number of actions (e.g., size of vocabulary for text summarization)\n",
    "actor_critic = ActorCritic(num_actions, vocab_size)\n",
    "\n",
    "# Define ROUGE score calculation function\n",
    "def calculate_rouge(generated_summary, ground_truth_summary):\n",
    "    if not ground_truth_summary.strip():  # Check if the ground truth summary is empty\n",
    "        return 0.0  # Return a default value or handle it as appropriate\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(generated_summary, ground_truth_summary)\n",
    "    return scores[0]['rouge-1']['f']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FLxJ-q0-KI3G"
   },
   "outputs": [],
   "source": [
    "def generate_summary(actor_critic, text):\n",
    "    state = tokenizer.texts_to_sequences([text])\n",
    "    state = tf.keras.preprocessing.sequence.pad_sequences(state, maxlen=max_length, padding='post')\n",
    "    action_probs, _ = actor_critic(state)\n",
    "    action_probs = action_probs[0]  # Extract probabilities from batch\n",
    "    print(\"Action probabilities before softmax:\", action_probs)  # Print action_probs for debugging\n",
    "    # Use softmax with epsilon for numerical stability\n",
    "    epsilon = 1e-8  # Small epsilon value\n",
    "    action_probs = tf.nn.softmax(action_probs + epsilon).numpy()\n",
    "    print(\"Action probabilities after softmax:\", action_probs)  # Print action_probs after softmax for debugging\n",
    "    # Choose action index based on probabilities\n",
    "    action = np.random.choice(len(action_probs), p=action_probs)\n",
    "    summary = tokenizer.index_word.get(action, 'UNK')  # Get word corresponding to action index\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXEpPvwfB-vX",
    "outputId": "f09aae3b-29c0-40fb-a6ef-62c53e9333b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.03008639]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.28712884, shape=(), dtype=float32)\n",
      "Input sequence: [[ 425  488  197  373    1    1  161  483  842 1166    1    1  373 1772\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.03274434]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0773394e-01 3.1577027e-08 5.9852987e-06 1.9246735e-01 5.3178866e-07\n",
      " 5.9166610e-01 3.6684403e-07 8.0965422e-03 2.6170626e-05 2.9668481e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10933156 0.08882349 0.08882401 0.10767511 0.08882353 0.16050373\n",
      " 0.0888235  0.08954557 0.08882581 0.08882374]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.03274434]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.29494235, shape=(), dtype=float32)\n",
      "Input sequence: [[  154   201   174   115    57   365    28    71    33    73   180    29\n",
      "    348   201    22    44   180   326   195 10327     3   964   336   472\n",
      "    364   193     8    73 10328     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.02695893]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1576257e-01 1.9233710e-08 4.3457576e-06 2.0393798e-01 3.5563690e-07\n",
      " 5.7319796e-01 2.4615085e-07 7.0758564e-03 1.8358862e-05 2.2740335e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11031277 0.088904   0.08890439 0.10901606 0.08890404 0.15770955\n",
      " 0.08890402 0.0895353  0.08890564 0.08890421]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02695893]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.24920964, shape=(), dtype=float32)\n",
      "Input sequence: [[  70   12    8   27   46   31   41  644  644 1914    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02894799]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.2520660e-01 1.4952732e-08 4.0131845e-06 1.7014244e-01 2.8374234e-07\n",
      " 5.9817135e-01 2.0777115e-07 6.4551607e-03 1.8100862e-05 1.8919160e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11120865 0.08878357 0.08878393 0.10525059 0.0887836  0.16147865\n",
      " 0.08878358 0.08935853 0.08878518 0.08878373]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02894799]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.27075905, shape=(), dtype=float32)\n",
      "Input sequence: [[  131  2993   565  1618    44  4822   160   478   322  3656  3750  1541\n",
      "    428     6 10358   199    29     9  3656    63   279   115   458  4822\n",
      "     29    22  1343   271    98   201     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.02975029]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0240937e-01 1.3477544e-08 3.2979974e-06 2.0379379e-01 2.6110374e-07\n",
      " 5.8794320e-01 1.7377394e-07 5.8334097e-03 1.4876833e-05 1.6274939e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10876773 0.08883718 0.08883747 0.10891841 0.08883721 0.15993196\n",
      " 0.08883721 0.08935692 0.08883851 0.08883733]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02975029]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2810759, shape=(), dtype=float32)\n",
      "Input sequence: [[  175    37   251   132    37  1499   574    46    49    90   293   546\n",
      "     46    49  6362  1823   251   546    86    49  5223    24   709   851\n",
      "   2946  1693    63 10507    45  6362  2946   566     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.02418131]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.97298825e-01 8.08880252e-09 2.38869461e-06 1.75652981e-01\n",
      " 1.62692743e-07 6.22199595e-01 1.11021535e-07 4.83280979e-03\n",
      " 1.21590174e-05 1.01231024e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10800731 0.08866809 0.0886683  0.10569453 0.08866812 0.16519056\n",
      " 0.08866811 0.08909764 0.08866918 0.08866818]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02418131]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.23521276, shape=(), dtype=float32)\n",
      "Input sequence: [[  83  695    8  434 1091  329  663 1342  342   34  858   99 2036  760\n",
      "   348  112 1879  329 1342  156 2052 1170  760   20 1879   13  787  158\n",
      "     7  159 1351  321 8132  236  305  342    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02872016]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.8446307e-01 1.5154439e-08 3.4019249e-06 1.7514753e-01 2.5649251e-07\n",
      " 6.3531035e-01 1.6932778e-07 5.0562094e-03 1.7798482e-05 1.1857854e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10654781 0.08859991 0.0886002  0.10555987 0.08859992 0.16724187\n",
      " 0.08859992 0.08904903 0.08860148 0.08860001]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02872016]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2723569, shape=(), dtype=float32)\n",
      "Input sequence: [[ 159   58  103  344   76  239  351 1592 2163  159  750    7  145    4\n",
      "  1928  351  914    5  316  428    2    1    1   27 1809  165   20  235\n",
      "   175  178  146   13  485    6  183  409   27    4 1333  228  257    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02569804]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1026410e-01 7.2008266e-09 2.1456058e-06 1.8069546e-01 1.4970766e-07\n",
      " 6.0399842e-01 1.0359233e-07 5.0280378e-03 1.0533179e-05 1.0401856e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10952832 0.08875848 0.08875868 0.10633712 0.0887585  0.16237645\n",
      " 0.08875849 0.08920589 0.08875942 0.08875858]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02569804]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.25093076, shape=(), dtype=float32)\n",
      "Input sequence: [[   18     3   125    14    85  1050  1033 11133  1389   111   125    14\n",
      "    488   197   164    33     2  2121 11134  3542    40   269    14     1\n",
      "      1   125    14    53  1679  4098  5464    95   252    53   136   225\n",
      "      4     2  4577 11135     1     1   177   125    14   192     1     1\n",
      "   3601     1     1 11136 11137     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.02733262]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.56702453e-01 3.71339648e-09 1.49754544e-06 2.26417080e-01\n",
      " 1.02497076e-07 5.13240635e-01 5.50303625e-08 3.63197131e-03\n",
      " 5.39132543e-06 7.84983627e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11519907 0.0891178  0.08911793 0.11176252 0.08911782 0.14888881\n",
      " 0.08911781 0.08944207 0.08911829 0.08911788]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02733262]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.27517667, shape=(), dtype=float32)\n",
      "Input sequence: [[  21    9  982 1369  708   49  982 1369   19  946 1369 1639    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02928742]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.18762740e-01 1.32765505e-08 3.12880206e-06 2.14978978e-01\n",
      " 2.54370889e-07 5.61395347e-01 1.50436804e-07 4.84494399e-03\n",
      " 1.30612907e-05 1.40854786e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11070057 0.08894927 0.08894955 0.1102825  0.08894929 0.15593848\n",
      " 0.08894929 0.08938128 0.08895043 0.0889494 ]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.2857142832653061\n",
      "Returns: [0.28571428]\n",
      "Advantages: tf.Tensor([[0.25642684]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(2.5117912, shape=(), dtype=float32)\n",
      "Input sequence: [[  51   36  387 1392  106    5   10   18    3  182    7  134   76  239\n",
      "     7 3554  261    4  258  170    2  203  134  582    3    4 5709    1\n",
      "    13  138   25   37    5  264    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02311278]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1348652e-01 7.8471585e-09 2.1820920e-06 1.6857238e-01 1.5196012e-07\n",
      " 6.1297035e-01 1.0450543e-07 4.9563968e-03 1.0969825e-05 9.2699372e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10982374 0.08871155 0.08871175 0.10500022 0.08871156 0.1637532\n",
      " 0.08871156 0.08915232 0.08871251 0.08871163]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02311278]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.22575097, shape=(), dtype=float32)\n",
      "Input sequence: [[ 438   10    8  262   30   91   10   82  391  613  191   10  116    2\n",
      "   122 3816    1    1  138  158  375    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02915936]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.07388416e-01 5.78195047e-09 1.86891066e-06 1.73087090e-01\n",
      " 1.18601555e-07 6.15586579e-01 7.65999744e-08 3.92569276e-03\n",
      " 9.45140528e-06 6.82440430e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10914028 0.08869874 0.08869891 0.10546011 0.08869874 0.16415846\n",
      " 0.08869874 0.08904763 0.08869958 0.0886988 ]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02915936]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.289607, shape=(), dtype=float32)\n",
      "Input sequence: [[  12  206 1225    8  492  121   12  261  368   13   74   64  400 1124\n",
      "    43  228   25    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02649824]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3819414e-01 9.4149115e-09 2.5833479e-06 2.0773721e-01 2.0094409e-07\n",
      " 5.4919636e-01 1.2136422e-07 4.8577646e-03 1.0322478e-05 1.2698069e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11293066 0.08899496 0.0889952  0.10954298 0.08899499 0.15412688\n",
      " 0.08899497 0.08942833 0.08899587 0.08899508]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02649824]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.25548965, shape=(), dtype=float32)\n",
      "Input sequence: [[ 382 1317 3503  122  596 1896 1885  687 1799  640  586 1000  176  585\n",
      "  3504   24  816  404  233 1260 5020 4088  488  967  213  404  360  283\n",
      "   389    3    6    3  399    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02449978]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1202989e-01 8.4206828e-09 2.4026256e-06 1.9131896e-01 1.6981114e-07\n",
      " 5.9171706e-01 1.1983845e-07 4.9194652e-03 1.0926015e-05 1.0755653e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10979463 0.08881731 0.08881752 0.10754407 0.08881734 0.16050076\n",
      " 0.08881734 0.08925533 0.08881828 0.08881741]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02449978]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.23770513, shape=(), dtype=float32)\n",
      "Input sequence: [[1089 2326   57    6    6  105  389  713  743  607 2326  121 1410  389\n",
      "   227 1341 1069  607 2326  241  116 4216  217   25 1142  396  635   91\n",
      "   389  713 2564 3431    8 1205 2631 1038  144 2796  289  412   33    1\n",
      "     1  131    2   68  169 1117   26 5307  209    1    1  313  156    7\n",
      "  4217   18   68 1666    9 1142  396  635 3628  590  532  140    6    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02515058]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.09682480e-01 5.43860335e-09 1.75351272e-06 1.65210709e-01\n",
      " 1.14657325e-07 6.21048868e-01 7.47208873e-08 4.04622033e-03\n",
      " 8.98558665e-06 6.78642664e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10935453 0.08866921 0.08866937 0.10459789 0.08866922 0.16500264\n",
      " 0.08866922 0.08902871 0.08867001 0.08866928]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02515058]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2504873, shape=(), dtype=float32)\n",
      "Input sequence: [[   9  159  115   57  201   49  534  292  582   50  114  361 3318  102\n",
      "    15   71  160 1348   57  376 2057   57   54   13    2   30 1205   68\n",
      "     7   80  174  589  291  130  369  201  443   37    2   91  201  495\n",
      "    67 1601   83 1435  790  258 2852 3946    9    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.03173805]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.5334325e-01 2.3685451e-09 1.0630868e-06 2.1045740e-01 6.8995682e-08\n",
      " 5.3290147e-01 3.7632446e-08 3.2920022e-03 4.1687153e-06 5.5675122e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11472442 0.08904925 0.08904934 0.10990836 0.08904925 0.15172824\n",
      " 0.08904925 0.08934288 0.08904962 0.08904931]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.16666666513888892\n",
      "Returns: [0.16666667]\n",
      "Advantages: tf.Tensor([[0.13492861]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(1.4115617, shape=(), dtype=float32)\n",
      "Input sequence: [[1270   50  817  518  266    7 5437  671  495  157 7600 1175  512  224\n",
      "    48  263  444  404 1349  271  186  315   31   32   46   31  163   34\n",
      "   599  178   41 7601   41 5491 1353   95  731  777  518  266  569 1322\n",
      "    13  495    1    1   49    6   71  499 1644    5   86  551 3160  347\n",
      "   270  875    5  357  499 1024  343  817  469 2470    8   65   82  252\n",
      "  1057    1    1  450  477  518  740   25    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02247106]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0330772e-01 5.8085337e-09 1.7382541e-06 1.7011231e-01 1.2348320e-07\n",
      " 6.2205094e-01 8.2869974e-08 4.5172679e-03 9.0409731e-06 7.8185553e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10865675 0.08866686 0.08866701 0.10510906 0.08866686 0.1651637\n",
      " 0.08866686 0.08906829 0.08866765 0.08866692]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02247106]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.22275397, shape=(), dtype=float32)\n",
      "Input sequence: [[  82  726   61   38  347   74    8    5   26  213   47   78   82   66\n",
      "   755   29 2843  659   18   86   53  478    7  305  634   58 1132 7510\n",
      "    38  659 3068 7511 1091    3    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02526005]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1414654e-01 7.6680600e-09 2.2039781e-06 2.0864648e-01 1.6614166e-07\n",
      " 5.7299292e-01 9.8974674e-08 4.2011263e-03 9.4835632e-06 1.0129634e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1101296  0.08889993 0.08890013 0.10952554 0.08889995 0.15767\n",
      " 0.08889993 0.0892742  0.08890077 0.08890002]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02526005]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.24680012, shape=(), dtype=float32)\n",
      "Input sequence: [[  51  195  264   36  570  494   76  366  497  927 1799 3301   87   40\n",
      "   260    2  919  121 3453  168 1410 1150  101   15  123  112  100  831\n",
      "  5741    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02322334]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0687929e-01 6.9754993e-09 2.0387138e-06 1.6639332e-01 1.3760196e-07\n",
      " 6.2203836e-01 9.5162314e-08 4.6754582e-03 1.0442859e-05 8.6087562e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10904436 0.0886659  0.08866608 0.10471776 0.08866591 0.16515985\n",
      " 0.08866591 0.08908142 0.08866683 0.08866598]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02322334]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.22819842, shape=(), dtype=float32)\n",
      "Input sequence: [[199 191  33 494  76 239  10  63  45  19  28 245 252  31   8  27 179  13\n",
      "  138  15 148 340 706  77 451  53   8 469 561   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.02318261]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.9661045e-01 3.5702044e-09 1.3175091e-06 1.6472425e-01 7.8494409e-08\n",
      " 6.3512760e-01 5.1405770e-08 3.5287070e-03 7.0985511e-06 4.9685605e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10784568 0.08859637 0.08859647 0.10446113 0.08859637 0.16720463\n",
      " 0.08859637 0.08890954 0.08859699 0.08859641]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02318261]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2360075, shape=(), dtype=float32)\n",
      "Input sequence: [[  15   22 1411   23  182    1  581  278   27  896  459   51    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02772531]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0124219e-01 1.3261079e-08 3.1779598e-06 2.0214491e-01 2.5200376e-07\n",
      " 5.9137458e-01 1.6028555e-07 5.2201138e-03 1.3301404e-05 1.2938382e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10862039 0.08882044 0.08882073 0.10871848 0.08882047 0.16045147\n",
      " 0.08882046 0.08928531 0.08882163 0.08882057]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02772531]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2637472, shape=(), dtype=float32)\n",
      "Input sequence: [[ 195    2   75   66  106   17   49  104  609  302    4  707   10   25\n",
      "  5123   13    2  165   10  133 1920  190  105  134  112  271   49  122\n",
      "    10   30  289   84  150  121    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02343765]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3221199e-01 3.5917218e-09 1.3960756e-06 1.9329603e-01 8.9991602e-08\n",
      " 5.7086593e-01 5.4571220e-08 3.6177931e-03 6.0153793e-06 6.7696186e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11214264 0.08890422 0.08890434 0.10786232 0.08890422 0.15734258\n",
      " 0.08890422 0.08922644 0.08890475 0.08890428]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02343765]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2370774, shape=(), dtype=float32)\n",
      "Input sequence: [[  45   19  259  509 1015  227 1080  460  137  630  382 7707    9 1883\n",
      "    16 2304  166 1015 1464 1138   16    4  163 1507   79  841  885  266\n",
      "   729    4    2  746 1080  460  166    2 7708 7709   35 1195    7   22\n",
      "   235   31  378  678   94  509 1015    4    8    7 2405   11  657   56\n",
      "   698  152  148    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02052036]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.2976497e-01 3.1914091e-09 1.3283191e-06 1.9399160e-01 8.2983931e-08\n",
      " 5.7297707e-01 4.8241422e-08 3.2585626e-03 5.7250750e-06 6.0527833e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11185721 0.08889521 0.08889532 0.10792644 0.08889521 0.15765913\n",
      " 0.08889521 0.08918535 0.08889571 0.08889525]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02052036]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.20894475, shape=(), dtype=float32)\n",
      "Input sequence: [[ 282 4882  324  280  403  336   84   67   37   67  141  118    9  324\n",
      "     4 3663   84   67  100   17  307  660  122 6041  113  151  247  130\n",
      "  9068  208  844  387  294  676  641    1    1  141  736  150 1516 1308\n",
      "   294  854  390    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02931906]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1607594e-01 4.8394568e-09 1.6144545e-06 1.7664367e-01 1.0974866e-07\n",
      " 6.0327595e-01 6.9172614e-08 3.9942171e-03 7.6699453e-06 7.3344097e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11016689 0.08875861 0.08875875 0.10590729 0.08875862 0.16225941\n",
      " 0.08875862 0.08911384 0.08875928 0.08875868]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02931906]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2928953, shape=(), dtype=float32)\n",
      "Input sequence: [[1965    3  364  832    5  323   13  138   56  158  785    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02681745]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.9782831e-01 1.6056191e-08 3.4200591e-06 1.8047309e-01 2.6882356e-07\n",
      " 6.1661756e-01 1.8022436e-07 5.0594583e-03 1.6430145e-05 1.3175522e-06], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10810029 0.08869744 0.08869775 0.10624038 0.08869747 0.1643254\n",
      " 0.08869746 0.08914734 0.0886989  0.08869756]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02681745]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.25364426, shape=(), dtype=float32)\n",
      "Input sequence: [[229  60 110 710 175   6   2 683   6 288  12 519  35 295 342  43   2 385\n",
      "   38  35 979  16 414   4 133   3  26 559   3  23 109  43 591 288 183   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.02315125]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0105316e-01 4.0919388e-09 1.4043195e-06 1.5743309e-01 8.6120949e-08\n",
      " 6.3796347e-01 5.8464277e-08 3.5405671e-03 7.6179326e-06 5.2687602e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1083045  0.08857889 0.08857902 0.10368181 0.0885789  0.16764641\n",
      " 0.0885789  0.08889307 0.08857957 0.08857894]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02315125]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2344487, shape=(), dtype=float32)\n",
      "Input sequence: [[  36   45 2206  331 1848  323    5 3028 2206   15  179  272    8   77\n",
      "    16  202    9   23 1169  331  160   40  153   56    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02787913]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1176581e-01 3.1011820e-09 1.1960769e-06 1.6985901e-01 7.2025088e-08\n",
      " 6.1498648e-01 4.5812939e-08 3.3809773e-03 5.9534573e-06 5.0218478e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10962    0.0886995  0.0886996  0.10512113 0.0886995  0.16406138\n",
      " 0.0886995  0.0889999  0.08870002 0.08869954]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02787913]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.28528923, shape=(), dtype=float32)\n",
      "Input sequence: [[  80   38  248 1469 7796   65  497  526  727  502 5575   24  727 1274\n",
      "    79  486  502  526 1334  285 1057  301 1057  767  179  248  104  350\n",
      "  2066 2169  202  527  248  521  727  101   17  147 3783   32   63  102\n",
      "  1274   79  182  155   19    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01933053]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.93766505e-01 5.68742786e-09 1.72059401e-06 1.79969102e-01\n",
      " 1.14363225e-07 6.22591257e-01 7.58828733e-08 3.66178434e-03\n",
      " 8.69833002e-06 6.59681405e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10762256 0.08866487 0.08866502 0.10614784 0.08866488 0.16524926\n",
      " 0.08866487 0.08899013 0.08866563 0.08866493]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01933053]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.19285323, shape=(), dtype=float32)\n",
      "Input sequence: [[  23    6   90   19 1444    8  189   17 3678  275  567 1061  448 1959\n",
      "  2941   99  567  364  270  234    3 1261   17 1163    6  172  621 1504\n",
      "  3023   41  564 1559 9945 9946 9947  830   75 1005    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02412138]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1252124e-01 7.4314968e-09 2.0299647e-06 1.8929541e-01 1.5118361e-07\n",
      " 5.9408855e-01 9.3496801e-08 4.0824409e-03 9.2042783e-06 8.8237834e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10983291 0.08880464 0.08880482 0.10731134 0.08880465 0.16085888\n",
      " 0.08880465 0.08916792 0.08880546 0.08880472]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02412138]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2369814, shape=(), dtype=float32)\n",
      "Input sequence: [[  93   10   81   71    3   83  315    1    5  118  785   84   16    8\n",
      "    77 8064 3785  338  302 1154   85 4529  171  505   66 3322  164   16\n",
      "    91   10  587  122  268   16   18  100   99  154   81  159   58   10\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02332197]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.2853705e-01 1.9721231e-09 8.8430977e-07 1.7307484e-01 5.1874778e-08\n",
      " 5.9551901e-01 3.1025337e-08 2.8635631e-03 4.1666781e-06 3.7697311e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11158742 0.08878975 0.08878984 0.10556704 0.08878975 0.16106214\n",
      " 0.08878975 0.08904437 0.08879013 0.08878978]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02332197]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.24393822, shape=(), dtype=float32)\n",
      "Input sequence: [[  51  135   41 2051 4284  535   27  524    2  681  137 7162  131   13\n",
      "    30 1005   33  524  772  478  582 7163  904  281 2172 1436    4    2\n",
      "   385 4285  904  130  561   20   30 1666  772   33  257  217   25   88\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02104134]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1543521e-01 4.9805942e-09 1.5296358e-06 1.5331900e-01 1.0147586e-07\n",
      " 6.2737417e-01 6.7271763e-08 3.8614278e-03 7.9623642e-06 5.9799231e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10993871 0.08863154 0.08863168 0.10331751 0.08863155 0.16597912\n",
      " 0.08863155 0.08897445 0.08863224 0.08863159]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02104134]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.211296, shape=(), dtype=float32)\n",
      "Input sequence: [[1514  118  662    3   46  824  417  462    1    1   74  584 1589 1317\n",
      "     6   98  658 1458  221  199 2484 1839  145    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02504436]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0014706e-01 6.9062143e-09 1.8668986e-06 1.7249016e-01 1.3420703e-07\n",
      " 6.2354398e-01 8.6091688e-08 3.8066762e-03 9.3522885e-06 7.1056274e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10830403 0.0886588  0.08865896 0.10534971 0.08865881 0.16539544\n",
      " 0.08865881 0.08899693 0.08865963 0.08865886]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02504436]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.24786386, shape=(), dtype=float32)\n",
      "Input sequence: [[  19   93 6027 1200  176 6028   60 1200 2455   98   16    7 1200 2323\n",
      "   849 2323  679    6  423 1999  106 1269 1089  503 2393  507 2103  202\n",
      "     6  849 1257  587  259 6027    6    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02110208]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1492724e-01 3.8177697e-09 1.2897231e-06 1.6630654e-01 8.5376840e-08\n",
      " 6.1549652e-01 5.2886964e-08 3.2614612e-03 6.4166975e-06 5.0809575e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1099619  0.08869529 0.08869539 0.10474338 0.0886953  0.16413729\n",
      " 0.08869529 0.08898503 0.08869585 0.08869532]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02110208]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.21472727, shape=(), dtype=float32)\n",
      "Input sequence: [[  134 10065   219  6287    72   183   110     1     1   637    65   962\n",
      "   2378   553    65     3    88   256   569  2126    17  1179  1756     3\n",
      "   2378   917  1179  1756   103   889     1     1  1946   219    83   506\n",
      "    162   709    49    59    80   709     1     1  1847    65  1465     1\n",
      "      1   121     2  1065  6287   250  1640    71   170     1     1  3944\n",
      "   1066  2800  3371     1  3945  1357     1     7  2783     1   184   145\n",
      "    103  1096     1     1   686     2   101   962  2378  3795   102    89\n",
      "   1805     2   853  1880  3050   228  1600     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.02075718]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1565941e-01 2.1767108e-09 8.8253199e-07 1.6254395e-01 5.3448161e-08\n",
      " 6.1904746e-01 3.2369382e-08 2.7434444e-03 4.4715612e-06 3.4979445e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11001772 0.08867536 0.08867543 0.10432656 0.08867536 0.16468416\n",
      " 0.08867536 0.08891898 0.08867574 0.08867539]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02075718]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.21708198, shape=(), dtype=float32)\n",
      "Input sequence: [[3732   83  193   20   87   78  306   26  280   40  188  405   97  110\n",
      "  2601  336  964  694  472  143    9    9   54  106  222  273 2524   39\n",
      "   573   78 2524  440  404   22  180   29    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0225764]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7505045e-01 2.5689257e-09 9.5113688e-07 1.5861630e-01 5.4883113e-08\n",
      " 6.6373098e-01 3.8086679e-08 2.5952498e-03 5.5856653e-06 2.9262745e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10535239 0.08843433 0.08843443 0.10363515 0.08843435 0.17174165\n",
      " 0.08843435 0.08866414 0.08843484 0.08843436]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0225764]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.23549137, shape=(), dtype=float32)\n",
      "Input sequence: [[  21 3244  164  396    9 1359 7644 1939   41 1560 1535  754 7645 3475\n",
      "   126   50 1145  420 1551  345 2222   17  129    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02989965]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1319233e-01 3.1324923e-09 1.0988007e-06 1.7766570e-01 7.2986680e-08\n",
      " 6.0632664e-01 4.3085478e-08 2.8083958e-03 5.2602832e-06 4.4302595e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10982981 0.08874256 0.08874266 0.10599642 0.08874256 0.16272573\n",
      " 0.08874256 0.08899213 0.08874302 0.0887426 ]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02989965]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.3074601, shape=(), dtype=float32)\n",
      "Input sequence: [[   9  375    4    8  150   91   10  607 1220  179  657  375  219  142\n",
      "   263  423   91   10 1461 8043  173   69   10  121 2291   67  202  451\n",
      "   302 8044  143 1462  375   20  175  157   67   16   32    4    3  190\n",
      "   179  318  931   66  302   18  120   76  314    5   22   76  239  866\n",
      "   599  332   15  123  296  756   39 1491  984  129 1271  205  302  153\n",
      "    56  677   42   69   10   80  658  107  303    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.03227072]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.4424180e-01 9.8251074e-10 5.1314902e-07 1.9735175e-01 3.0534306e-08\n",
      " 5.5621862e-01 1.6610654e-08 2.1848939e-03 2.1359281e-06 2.4169572e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11357031 0.08895942 0.08895947 0.10836791 0.08895942 0.15515101\n",
      " 0.08895942 0.08915401 0.08895962 0.08895944]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.03227072]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.34902683, shape=(), dtype=float32)\n",
      "Input sequence: [[   8  569  488  197  360 2166 1686    3 2122  203  384   56    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02272276]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.2582197e-01 4.8338387e-09 1.4175397e-06 1.9723140e-01 1.0695502e-07\n",
      " 5.7382697e-01 5.9244222e-08 3.1115687e-03 5.9052495e-06 6.1219021e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11141358 0.08889244 0.08889257 0.1082733  0.08889245 0.15778828\n",
      " 0.08889245 0.08916947 0.08889297 0.0888925 ]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02272276]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.22919263, shape=(), dtype=float32)\n",
      "Input sequence: [[  28   71  157  438   10  348   22  297 1594  302  609    8  586  391\n",
      "   835    3  438    5  700  755   33  863  612   90   16   16  353 6823\n",
      "    70    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01884213]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3423506e-01 1.4338271e-09 6.4899382e-07 1.7449187e-01 3.8794585e-08\n",
      " 5.8894271e-01 2.2353364e-08 2.3264384e-03 2.9710764e-06 2.6809141e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11226057 0.08881784 0.08881791 0.10575018 0.08881785 0.16005705\n",
      " 0.08881785 0.08902472 0.08881811 0.08881788]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01884213]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.20114411, shape=(), dtype=float32)\n",
      "Input sequence: [[ 118  553  337  170  803  993  321 1106  453   19    4  683 7290 4322\n",
      "   113   27    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02171985]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1734616e-01 3.5054024e-09 1.1341388e-06 1.9144675e-01 7.7677399e-08\n",
      " 5.8855140e-01 4.4974236e-08 2.6490607e-03 4.9855921e-06 4.2729903e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11039218 0.08882721 0.08882731 0.1075698  0.08882722 0.1600113\n",
      " 0.08882722 0.08906283 0.08882765 0.08882724]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02171985]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.22316507, shape=(), dtype=float32)\n",
      "Input sequence: [[ 634 4981  756 3957  238  546    6 1320  252 1400 1865  651    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01971252]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0545781e-01 4.7340203e-09 1.3769579e-06 1.6103993e-01 9.1010797e-08\n",
      " 6.3068020e-01 5.7751976e-08 2.8132221e-03 6.9389798e-06 4.2702567e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10882924 0.08861688 0.08861699 0.10410106 0.08861688 0.16650118\n",
      " 0.08861688 0.08886651 0.08861748 0.08861691]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01971252]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.20034659, shape=(), dtype=float32)\n",
      "Input sequence: [[  89  184  174  100 1079  958  958  295   40   48  111    2  223  134\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0187562]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3959604e-01 1.0712656e-09 5.0086663e-07 1.7692077e-01 3.0343063e-08\n",
      " 5.8161372e-01 1.5695962e-08 1.8664411e-03 2.2636334e-06 1.9829250e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11290345 0.08884887 0.08884893 0.10604438 0.08884888 0.1589438\n",
      " 0.08884887 0.08901487 0.08884908 0.0888489 ]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0187562]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.20382912, shape=(), dtype=float32)\n",
      "Input sequence: [[ 262  830  534    7  630    5    8  303   91   69   10   40    1    1\n",
      "    22   65 1408    2  181  167  830   15   69  613  181  613  199  190\n",
      "   529  181  167    5  138  148    1    1   56  600  744    8  107  340\n",
      "    77    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01175446]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.2291730e-01 7.8517581e-10 3.9843121e-07 1.5006506e-01 2.0903757e-08\n",
      " 6.2524307e-01 1.2377839e-08 1.7718420e-03 2.1655298e-06 1.4099670e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11076988 0.08863596 0.088636   0.10298699 0.08863597 0.16563402\n",
      " 0.08863596 0.08879314 0.08863614 0.08863597]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01175446]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.1298801, shape=(), dtype=float32)\n",
      "Input sequence: [[  506  4256 10166     3  1179    88 10167  4802   515   330   612  1047\n",
      "     26  2720  2513   342  2513   222 10168  1734   591   959  1177  1395\n",
      "    937   814  3342  1673  2341  1734   521  1073  1177   120  6308  1179\n",
      "   2697   515   551  3750   192 10169  1640    49     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.01550196]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1782833e-01 3.5751486e-09 1.0496500e-06 1.7274928e-01 7.4617361e-08\n",
      " 6.0676080e-01 4.4919993e-08 2.6549271e-03 5.0951630e-06 4.1160075e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11033492 0.08873834 0.08873844 0.10547157 0.08873834 0.16278867\n",
      " 0.08873834 0.08897424 0.0887388  0.08873837]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01550196]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.15965764, shape=(), dtype=float32)\n",
      "Input sequence: [[  64 1293   12  491   52   22   92 1034   25    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01568574]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.2779858e-01 9.0449770e-10 4.2269767e-07 1.6522373e-01 2.5331694e-08\n",
      " 6.0531336e-01 1.3230110e-08 1.6616805e-03 2.1162839e-06 1.5544647e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11144151 0.08873916 0.0887392  0.10468178 0.08873917 0.16255473\n",
      " 0.08873916 0.08888675 0.08873936 0.08873919]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01568574]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.17238608, shape=(), dtype=float32)\n",
      "Input sequence: [[ 479  195  741 1162   99  803   77  116   31 7291  209  228   42  628\n",
      "   138 1149  210    1   95   28   77  337 5323  168 7292    1    2  120\n",
      "   395    1  369 1011 2383    6 7293    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00897106]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1597432e-01 5.6524097e-10 3.0698624e-07 1.4886144e-01 1.5069766e-08\n",
      " 6.3372654e-01 8.7700709e-09 1.4355949e-03 1.7375378e-06 9.5898443e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10994949 0.08859246 0.08859249 0.10281263 0.08859246 0.16696317\n",
      " 0.08859246 0.08871974 0.08859261 0.08859248]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00897106]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.10103713, shape=(), dtype=float32)\n",
      "Input sequence: [[ 107  988  482   25  107    4    2    9    3  195  199  759    4  152\n",
      "  9358 1845  990    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02115587]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0754887e-01 6.3210498e-10 3.4650159e-07 1.3627726e-01 1.6034408e-08\n",
      " 6.5497547e-01 9.3069810e-09 1.1958901e-03 2.1004112e-06 8.4856389e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10887932 0.08847245 0.08847249 0.1013894  0.08847245 0.1703179\n",
      " 0.08847245 0.08857832 0.08847264 0.08847247]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02115587]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.23770732, shape=(), dtype=float32)\n",
      "Input sequence: [[ 581  174 2323  495  278    2 1887   20 1601   51   18  759  385  520\n",
      "   747  249  773 7472  647    4 1983  553  113 7473  610   10    8    6\n",
      "     8   27    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01135396]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.15341985e-01 7.22703564e-10 3.49484139e-07 1.51655138e-01\n",
      " 1.88577953e-08 6.31489754e-01 1.07881579e-08 1.51074107e-03\n",
      " 1.90091976e-06 1.07557824e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10989627 0.08860559 0.08860563 0.10311554 0.08860559 0.16661483\n",
      " 0.08860559 0.08873955 0.08860576 0.08860561]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01135396]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.12662776, shape=(), dtype=float32)\n",
      "Input sequence: [[1337   81   41   59  580   35   10  312   59   59    3   13   56 1851\n",
      "  6072  336  986  337 1337 2406  407  336  141   26    5 6073  986  114\n",
      "  1246    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01208539]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.16541603e-01 8.50686910e-10 3.83268912e-07 1.52326271e-01\n",
      " 2.16922604e-08 6.29659891e-01 1.17688215e-08 1.46970002e-03\n",
      " 2.09561586e-06 1.16804507e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11003997 0.08861509 0.08861512 0.10319582 0.08861509 0.16632803\n",
      " 0.08861509 0.08874542 0.08861527 0.0886151 ]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01208539]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.13400058, shape=(), dtype=float32)\n",
      "Input sequence: [[  10 1235 2442  467 6899 1248   30  341   76 1665  239  344    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01443889]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.40472540e-01 8.22556134e-10 4.03954544e-07 1.91938370e-01\n",
      " 2.41190321e-08 5.66199899e-01 1.18316965e-08 1.38681824e-03\n",
      " 1.71512715e-06 1.44984000e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11308956 0.08891737 0.0889174  0.10773192 0.08891737 0.1566333\n",
      " 0.08891737 0.08904077 0.08891752 0.08891737]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01443889]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.15960294, shape=(), dtype=float32)\n",
      "Input sequence: [[  51 1963 1845 1079  167   29  500   44   58  160  500  380 2978 1141\n",
      "  1173 1550  380   51 1963 1845 2808  104  192   33   81  214  568   25\n",
      "  1963 1845  547   53  136  380   53  380 1577 1217  284  750  380    6\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0085835]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.2403441e-01 1.7101793e-09 6.0021642e-07 1.5760715e-01 3.8881058e-08\n",
      " 6.1647522e-01 2.1779702e-08 1.8793435e-03 3.0393694e-06 1.9534122e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11095281 0.0886832  0.08868326 0.10382197 0.08868321 0.16427563\n",
      " 0.08868321 0.08885002 0.08868348 0.08868323]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0085835]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.09217685, shape=(), dtype=float32)\n",
      "Input sequence: [[  21    9   11   18    2   94  254 1292  119   21   11  590   25   33\n",
      "    41   13  879    6    1    1  119  429  241  307  158  632   27  142\n",
      "   770   27 1868  169  805 1171  623  165   74  264  286  319   32 1022\n",
      "  3135  824 4672 3303 1171  770   27 1171    2    7  770 1139    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01914556]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.33952075e-01 4.19678958e-10 2.37247448e-07 1.58500060e-01\n",
      " 1.24408155e-08 6.06319368e-01 6.60368871e-09 1.22691994e-03\n",
      " 1.22366964e-06 8.02007420e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11211691 0.08872929 0.08872931 0.10396874 0.08872929 0.16270024\n",
      " 0.08872929 0.08883823 0.08872941 0.08872931]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01914556]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.21853274, shape=(), dtype=float32)\n",
      "Input sequence: [[    6   142   390    23  6298    49   106  1962     7  2191    79  1616\n",
      "    216   673   253  2784  2115  3807  1346   119    24  4239  1672    54\n",
      "  10114   209    65    20   502  1620  1449   962   119    74   377   253\n",
      "   3118  1389  4172    54    24   370    89   937   962  1805   840    57\n",
      "   3050  1805  2387  3332 10115   556   216  2399     1     7   119   959\n",
      "   1734  2119   370   370 10116    50  1725   262  5703   628  1066   959\n",
      "   3751 10117    15   105     6   419  1010  1295   340    89  1640   254\n",
      "  10118    80  1631   814  1546    80  1830   164   217   814  3407  2115\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.00168073]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3369369e-01 6.9529998e-10 3.2923822e-07 1.5595441e-01 1.8827077e-08\n",
      " 6.0894859e-01 1.0127642e-08 1.4012250e-03 1.6599239e-06 1.1300643e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11207107 0.08871594 0.08871597 0.10368878 0.08871594 0.16310401\n",
      " 0.08871594 0.08884034 0.08871609 0.08871594]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00168073]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.018803248, shape=(), dtype=float32)\n",
      "Input sequence: [[  60   10   91 1301  294  854   10  390   16  753  594  238  363 2453\n",
      "   480  229  147 1260  222  147   10   19  634   19   93 2029  228 1276\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00893769]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.32324436e-01 4.08584888e-10 2.39844809e-07 1.64022356e-01\n",
      " 1.25213315e-08 6.02586508e-01 6.28048014e-09 1.06516667e-03\n",
      " 1.19469928e-06 7.50734088e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11196002 0.08874945 0.08874948 0.10456824 0.08874945 0.16213088\n",
      " 0.08874945 0.08884405 0.08874957 0.08874946]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00893769]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.10234974, shape=(), dtype=float32)\n",
      "Input sequence: [[ 790  185 6987  144 6988   28  109   16  135   41  732   51  589  378\n",
      "   241 1929    5  145   22 3211   11  588    5    2 3212  486  334  139\n",
      "   614  233  628 3428 6989   11    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01131982]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0525247e-01 3.7062295e-10 2.0906008e-07 1.3297899e-01 9.7052206e-09\n",
      " 6.6078550e-01 5.5017466e-09 9.8146440e-04 1.3075867e-06 4.9821864e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10858726 0.088438   0.08843802 0.10101618 0.088438   0.17124361\n",
      " 0.088438   0.08852483 0.08843811 0.088438  ]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01131982]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.1310338, shape=(), dtype=float32)\n",
      "Input sequence: [[6950 3175   10  196 1023  820 3165  402    5  820  298  421 6951 2810\n",
      "    90   16    1    1   24  193   10 1044  695 2624  601  191   11 2469\n",
      "    23 4203 2470  149 6952 1824 2157  128   15  191    6  128 1330   57\n",
      "   883 2589  556 1826   65 1303  273 1702 1823    6 5172 1153  643 1798\n",
      "   908 4204  883  150  402 2427  883  150   57 2819  574 5173  165 1490\n",
      "   883  150  896  291 4155  144 1257   88  128    1    1   31   10  144\n",
      "    69    5   24  344 1964   69   10  203 1182   76  992 1964   10   22\n",
      "    17 1456]]\n",
      "Value estimates: tf.Tensor([[0.00491545]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[0.0723649  0.01884624 0.11944727 0.05577478 0.16930352 0.08465356\n",
      " 0.14328374 0.10008513 0.07043643 0.16580446], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09716832 0.09210471 0.10185264 0.09556959 0.10705935 0.09836975\n",
      " 0.10430962 0.09989953 0.09698112 0.1066854 ]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00491545]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.012042622, shape=(), dtype=float32)\n",
      "Input sequence: [[152 617 125  14  46 441  29  80   6 110  78  26 273  39   4 152 617 125\n",
      "   14 227 184   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.00594797]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3077072e-01 5.9058947e-10 2.8680572e-07 1.6516270e-01 1.6674029e-08\n",
      " 6.0287499e-01 8.3728180e-09 1.1897600e-03 1.3981280e-06 9.2037126e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11178581 0.08874916 0.08874919 0.10468718 0.08874916 0.1621771\n",
      " 0.08874916 0.08885482 0.08874929 0.08874916]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00594797]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.06718307, shape=(), dtype=float32)\n",
      "Input sequence: [[ 712   63 1207   13   53  500    1    1 1014 1010 1382 1213 4477 1968\n",
      "   626  436  420  136   31  193  186 6112 3392   49 1020 1968 3392  186\n",
      "  6112 9270  264  130  960  848  119 4726 3085    1    1 2528  960 1466\n",
      "  3232   46   15  110  474  131 2085 3008   74 1117  612  264  960  439\n",
      "   568  485 1552 3391  299 1552 4193  377  591  960    1    1  264   96\n",
      "    89  109 3087  416   96   20  928   46 1790  209   85   75 3114 2143\n",
      "   110 1755 1779  623 2274 1784 1010  260  612  900 2178 3040  147  921\n",
      "   400  900]]\n",
      "Value estimates: tf.Tensor([[0.0039849]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[0.05654656 0.02392356 0.12445805 0.04603406 0.20253845 0.06491303\n",
      " 0.1665599  0.09107137 0.06532631 0.15862873], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09559298 0.09252477 0.10231036 0.09459332 0.11061893 0.09639611\n",
      " 0.10670977 0.09895094 0.09643596 0.10586677]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0039849]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.009889531, shape=(), dtype=float32)\n",
      "Input sequence: [[   9    9    9  434    6   26    7    9    9    9   23   17  127  281\n",
      "   118   54  972 3148 1807   66   11   17  802 4115 5070 1463   17 1627\n",
      "    11  552  225  792   20  119  746  121  133   20 5071  268    9    6\n",
      "    59  317   19   17    7 6764 6765 4115   16    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.03200807]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.7386978e-01 2.4212971e-10 1.6190121e-07 1.8665150e-01 8.7107530e-09\n",
      " 5.3862292e-01 3.6804868e-09 8.5492124e-04 6.5919534e-07 5.8303055e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11705142 0.08900953 0.08900955 0.10727493 0.08900953 0.15253077\n",
      " 0.08900953 0.08908566 0.08900959 0.08900953]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.03200807]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.3744413, shape=(), dtype=float32)\n",
      "Input sequence: [[1865  977  217    6 2452  577  165  858 2750  583  236 9700  112    4\n",
      "    29 9701 1519  696  133  145  261    4    2  194  511  858   29   13\n",
      "  4535   62  100  101  273  354  951    2   54   62 2123  284   61 1181\n",
      "  4473   29 6202 2123  101   78 2672  414  951   34  596  893   29  126\n",
      "  1489  133 1502  576   47 1329  112  368  197 2324  308  283   29  173\n",
      "    47  162   15   53  197 2750 2755  799 3187   29  428  185   87   29\n",
      "     3 4009    2  245 3002   62 6202   80  455  293  133  118   59   46\n",
      "    18  118]]\n",
      "Value estimates: tf.Tensor([[0.00250858]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[0.05418295 0.0157381  0.12995498 0.03473674 0.20477664 0.06219328\n",
      " 0.1794893  0.08366577 0.06291465 0.17234756], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09532955 0.09173417 0.10283357 0.09349366 0.11082291 0.09609624\n",
      " 0.10805563 0.09818198 0.09616558 0.10728667]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00250858]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.006404071, shape=(), dtype=float32)\n",
      "Input sequence: [[   1    1   95  734  111 2512   29   92 1531 2477    4  190  179   95\n",
      "  4007 2477   86   17 1021  697  593  155  100  747  106  287 5133   40\n",
      "   576   61 1451  339 1517  482 5543  482   23 3287  866   82 1040 1240\n",
      "    15 1493 2562   89  426 1927 3348   37   22  470  409 3912 6108  910\n",
      "   543  169    1    1  317   19 1347  178   41  579   27   59   18   86\n",
      "   551   88   18  828   27 1084 1232  260 9396    8 1469   22    6 1076\n",
      "    22  146  240    1    1   25    8 6142  639  517  182   48  428  247\n",
      "  2328  223]]\n",
      "Value estimates: tf.Tensor([[0.00300625]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[0.13471997 0.00567384 0.09626272 0.08876304 0.11077676 0.1901717\n",
      " 0.09081403 0.12538669 0.05449599 0.10293515], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10342303 0.09090195 0.09952117 0.09877758 0.10097615 0.10932\n",
      " 0.09898038 0.10246224 0.09545011 0.10018744]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00300625]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.007644133, shape=(), dtype=float32)\n",
      "Input sequence: [[   9   10   25   67  142   16   98  113 1086 2018  122   65   20  443\n",
      "    16 1103  381  975  100 1165   74   72    8  173    5    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01487677]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.7321932e-01 1.6662159e-10 1.2473045e-07 1.8287688e-01 6.4684094e-09\n",
      " 5.4313141e-01 2.7820655e-09 7.7164581e-04 5.1604462e-07 4.4307043e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11695173 0.0889916  0.0889916  0.10684922 0.0889916  0.15318914\n",
      " 0.0889916  0.08906028 0.08899164 0.0889916 ]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01487677]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.17703807, shape=(), dtype=float32)\n",
      "Input sequence: [[ 42  16  90 335  55  22 218   3  77 256 290  36 748   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.01108101]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.5846022e-01 2.7477789e-10 1.6548819e-07 1.6767657e-01 9.0418864e-09\n",
      " 5.7283533e-01 4.3108277e-09 1.0269220e-03 7.3195923e-07 5.6412770e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11508683 0.08887462 0.08887464 0.10509905 0.08887462 0.15760028\n",
      " 0.08887462 0.08896594 0.08887469 0.08887463]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01108101]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.12931241, shape=(), dtype=float32)\n",
      "Input sequence: [[ 460 1932   32  495 1211   12 6227 1352   32 1635  137    8   27  265\n",
      "  1822   46    1    1 1031   27   53 9812  490 1211   27 2274    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01142766]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.5087097e-01 2.8753425e-10 1.6038489e-07 1.3936025e-01 8.1034806e-09\n",
      " 6.0885674e-01 3.9626311e-09 9.1105548e-04 8.5275894e-07 4.4962334e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11399263 0.08870027 0.08870029 0.10196434 0.08870027 0.16306023\n",
      " 0.08870027 0.08878111 0.08870035 0.08870027]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01142766]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.13395646, shape=(), dtype=float32)\n",
      "Input sequence: [[  93 3046  219   19   32  406 1334   33  260  585  453 1642  104    1\n",
      "   630  473  128   24 1567 2373  225   28   42   17  107  255 1604   48\n",
      "   111 1018 1303 1877   40   48  111  325  130  109 1099  304  305 2220\n",
      "    38  746  282 1334 3936 3046  473  128  950   67   13   56   33 4699\n",
      "  9645    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00309929]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.5148496e-01 1.2435847e-10 9.5588362e-08 1.5684472e-01 4.5056883e-09\n",
      " 5.9100688e-01 2.0500441e-09 6.6287006e-04 4.8999550e-07 2.9577629e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11418122 0.08879246 0.08879248 0.10387066 0.08879246 0.16034193\n",
      " 0.08879246 0.08885133 0.08879251 0.08879247]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00309929]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.03753428, shape=(), dtype=float32)\n",
      "Input sequence: [[123  58  73 180  29   4  22 203   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.00860543]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.5005046e-01 3.9572740e-10 2.1582434e-07 1.5294728e-01 1.1399177e-08\n",
      " 5.9606314e-01 5.6907004e-09 9.3780237e-04 1.0574264e-06 6.2799479e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11398681 0.08876853 0.08876856 0.10343875 0.08876853 0.16111131\n",
      " 0.08876853 0.08885183 0.08876863 0.08876854]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00860543]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.09920622, shape=(), dtype=float32)\n",
      "Input sequence: [[ 151  387  115  357   57  830 2165    5    1    1  170 4455  291  161\n",
      "  1557    3 5507 1026    5  285  526   26  744    1    1  187  493  157\n",
      "     4    3  168   66  975  152  872    4  618   56  618  324  526 5625\n",
      "    96   66 2744  618    5  153   56    4  618  324  437  949  213  437\n",
      "   357  324  526  246  618    1    1  414    4  782  429  241  888 1232\n",
      "    22  235 5626 5443 1121   27  888  526  922  249  529  770   27  321\n",
      "   441  187  493  157  290   41 1020    1    1   28   33  496  526  347\n",
      "    59  129]]\n",
      "Value estimates: tf.Tensor([[-0.00184611]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[0.05801777 0.00978056 0.11844449 0.0344848  0.22428454 0.07347366\n",
      " 0.18320233 0.08256789 0.04975513 0.16598883], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09567179 0.09116639 0.10163116 0.09344663 0.11297768 0.09716197\n",
      " 0.10843035 0.09804962 0.09488454 0.10657986]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00184611]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.0048159193, shape=(), dtype=float32)\n",
      "Input sequence: [[ 229  106 2173  394   52  678  678   68  268   60  162  130 1469   31\n",
      "     1   24  174 1294   80  358    1  268  383 1102    2  225    1  147\n",
      "     1  358   54   25   80   41    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00609425]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.4288015e-01 2.3355509e-10 1.3777749e-07 1.3751957e-01 6.7099664e-09\n",
      " 6.1884129e-01 3.2269094e-09 7.5798773e-04 7.6548633e-07 3.5371940e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11302572 0.08865346 0.08865348 0.10172314 0.08865346 0.16460958\n",
      " 0.08865346 0.08872069 0.08865354 0.08865348]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00609425]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.07227148, shape=(), dtype=float32)\n",
      "Input sequence: [[  70    1 1505   27  298    1 1613  472  213    1    8  386 8568  291\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00961355]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.4738142e-01 2.5014743e-10 1.6772425e-07 1.4397384e-01 7.5970981e-09\n",
      " 6.0786480e-01 4.1680068e-09 7.7886455e-04 8.6339560e-07 4.4133923e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11360679 0.08870904 0.08870906 0.10244598 0.08870904 0.16291468\n",
      " 0.08870904 0.08877816 0.08870912 0.08870906]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00961355]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.11295336, shape=(), dtype=float32)\n",
      "Input sequence: [[   5  356 4462   93 1247  543  155  416  244  356  229  268    3   83\n",
      "  2215 2342 2531 2792   95  166  703   12  164 4483 2531    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00640686]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3499915e-01 4.2745282e-10 2.1746284e-07 1.4151822e-01 1.1055570e-08\n",
      " 6.2259108e-01 5.8218665e-09 8.9011685e-04 1.1640619e-06 5.1967877e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11212158 0.08864012 0.08864015 0.10211533 0.08864012 0.16520312\n",
      " 0.08864012 0.08871906 0.08864024 0.08864014]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00640686]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.07398004, shape=(), dtype=float32)\n",
      "Input sequence: [[1201   29  140  830   23   39  626   23  114  222   15   30    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00329032]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3588768e-01 3.2764544e-10 1.7487037e-07 1.4503363e-01 9.1867696e-09\n",
      " 6.1823350e-01 4.5990722e-09 8.4401382e-04 9.5208793e-07 4.8459587e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11225079 0.08866346 0.08866347 0.10250192 0.08866346 0.1645281\n",
      " 0.08866346 0.08873832 0.08866355 0.08866347]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00329032]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.0384009, shape=(), dtype=float32)\n",
      "Input sequence: [[   59     6     3   257  1193   294     6   237   237   328   333   531\n",
      "    552   284   287    49   294   184    20     2   113    37   104     6\n",
      "  10447     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.00556483]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.4378517e-01 1.3510261e-10 9.8463062e-08 1.4217870e-01 4.3336472e-09\n",
      " 6.1347461e-01 1.9702822e-09 5.6082237e-04 5.4036803e-07 2.2756332e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1131644  0.08868196 0.08868197 0.10223102 0.08868196 0.16378114\n",
      " 0.08868196 0.08873171 0.088682   0.08868196]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00556483]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.0675966, shape=(), dtype=float32)\n",
      "Input sequence: [[ 400  991  643  182  142  130 2887  206   59  328   13    2 6896   69\n",
      "    10  182  204  200 1493  130  645 3534    3  478   59   13  646  206\n",
      "   177   69    5 1664  336  127  218   32   25  147   80  860  557   70\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00232505]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.4695967e-01 1.2926610e-10 9.0498901e-08 1.3983355e-01 4.2576369e-09\n",
      " 6.1255980e-01 2.0670194e-09 6.4630818e-04 5.0562045e-07 2.5447100e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11352668 0.08868389 0.0886839  0.10199377 0.08868389 0.16363494\n",
      " 0.08868389 0.08874123 0.08868393 0.0886839 ]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00232505]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.028241517, shape=(), dtype=float32)\n",
      "Input sequence: [[ 346  447    3    6  665  266 1573   31   41   18 1295  209   78  117\n",
      "   949  418 1091 1993  127  266 2601  101 6576  665  348 1994    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00225586]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3542699e-01 3.2671069e-10 1.6983287e-07 1.5281895e-01 9.2535801e-09\n",
      " 6.1099488e-01 4.3473189e-09 7.5810472e-04 8.9282310e-07 4.4699306e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11224901 0.08870292 0.08870293 0.10334902 0.08870292 0.16341412\n",
      " 0.08870292 0.08877019 0.08870299 0.08870292]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00225586]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.026396818, shape=(), dtype=float32)\n",
      "Input sequence: [[   8 1587 1437 6267    2   25   54  589    3  235  234    3    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00826529]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.8475839e-01 1.9764258e-10 1.2423146e-07 1.5381955e-01 6.4514478e-09\n",
      " 5.6070840e-01 2.8131819e-09 7.1294908e-04 5.6585014e-07 3.8207400e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11818987 0.08890194 0.08890194 0.1036846  0.08890194 0.15574847\n",
      " 0.08890194 0.08896535 0.088902   0.08890194]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00826529]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.098463476, shape=(), dtype=float32)\n",
      "Input sequence: [[ 331    3  218    2 2206    2  522 2363  147  383    3   11  121  596\n",
      "   271  753    6   90   26   96  273   66  293 8768 1830  582 2165   24\n",
      "   116  293 1356  109  293  419  893  109 2316 2967  116  163   42  182\n",
      "  2316   31  619 2719  293 8769    2  193 2363  147   11  133    3 1230\n",
      "  1096  331    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00117423]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.4840079e-01 1.3089667e-10 9.0069264e-08 1.3730520e-01 4.2593347e-09\n",
      " 6.1363220e-01 2.1211490e-09 6.6119723e-04 5.0728823e-07 2.6160258e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11368096 0.08867652 0.08867653 0.10172777 0.08867652 0.16379692\n",
      " 0.08867652 0.08873517 0.08867656 0.08867653]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00117423]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.014252501, shape=(), dtype=float32)\n",
      "Input sequence: [[  670    83   738    36    29    63  2691   115    57  3381   275    29\n",
      "   1355    73   160   573   306   114  3381    23   306   114   560    46\n",
      "    537    71    29    50    29  4011   306   114    18    30   327   560\n",
      "     22    29   537  1132   560  1059  1622    39   128    61   147   709\n",
      "    111    58    29   620   404  3593 10364   369  4823  6340   193  4823\n",
      "    692   253   341    13    30   136   151  1197   165     8  4823   386\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[-0.00228932]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.30036378e-01 1.57201280e-10 1.01533914e-07 1.40216827e-01\n",
      " 5.05080644e-09 6.29089355e-01 2.50157539e-09 6.56782824e-04\n",
      " 5.83468193e-07 2.75145648e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11152543 0.08860748 0.0886075  0.10194497 0.08860748 0.16621892\n",
      " 0.08860748 0.0886657  0.08860754 0.08860749]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00228932]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.027608728, shape=(), dtype=float32)\n",
      "Input sequence: [[ 95 966 163 395 166  10  28  33 494  76 239   5  81 295 489  16  10   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.00327526]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.32118145e-01 1.53578553e-10 1.03461055e-07 1.39646813e-01\n",
      " 4.76650230e-09 6.27696991e-01 2.18528795e-09 5.37343323e-04\n",
      " 5.91639889e-07 2.29412880e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1117654  0.08861347 0.08861347 0.10189375 0.08861347 0.16599886\n",
      " 0.08861347 0.0886611  0.08861353 0.08861347]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00327526]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.039665274, shape=(), dtype=float32)\n",
      "Input sequence: [[ 498  137  135  178   41  131   13   72    1    1  931  460   20  468\n",
      "   137   50  728  774   66  359   13 2082  148    6    1    1 1143 2201\n",
      "   170 2517    4 5915  100  187   39  187  114   79  106   54  187   39\n",
      "    97  125 8652  187  114   97   59   59  187  116  371  544 1460 1830\n",
      "     2  125  746 8653  746    4  106  193  187   59  187   64 2547 3027\n",
      "   208  120   34    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00419693]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3715249e-01 9.8209239e-11 7.5273178e-08 1.3284995e-01 3.1411929e-09\n",
      " 6.2947810e-01 1.5453819e-09 5.1899359e-04 4.4518444e-07 1.7594912e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1123106  0.08859858 0.08859858 0.10118653 0.08859858 0.16626681\n",
      " 0.08859858 0.08864456 0.08859861 0.08859858]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00419693]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.051720984, shape=(), dtype=float32)\n",
      "Input sequence: [[2537   38   35  672 1524 1586   47   57  812  584  759  113  510   43\n",
      "  1231  108    5  258  212   35   13   30  786    2  798 1385  114   35\n",
      "    30    1    1   51   67  252   31  135  178   41   51  194    7  802\n",
      "    67    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-5.846843e-05]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.5302604e-01 1.1745840e-10 8.2670496e-08 1.3628492e-01 3.7382160e-09\n",
      " 6.1010778e-01 1.7911269e-09 5.8066979e-04 4.6810129e-07 2.2447912e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11422627 0.08869071 0.08869074 0.10164031 0.08869071 0.16324678\n",
      " 0.08869071 0.08874223 0.08869077 0.08869072]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[5.846843e-05]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.0007145917, shape=(), dtype=float32)\n",
      "Input sequence: [[1083    3   88   42  831   51  139  482  299  379  482   30  899  399\n",
      "  1799   25  284  139  482 1488 8788  379  482  668  899  399   19  739\n",
      "   204  188   19   22   49  597    5  221   40  469  462  213   43   12\n",
      "  1365  321  221   30   38   11    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00021894]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3750867e-01 2.5128494e-10 1.3427814e-07 1.4338660e-01 7.3221385e-09\n",
      " 6.1837620e-01 3.4108958e-09 7.2755484e-04 7.4448189e-07 3.6648629e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11242992 0.08866111 0.08866112 0.10233051 0.08866111 0.16454722\n",
      " 0.08866111 0.08872565 0.08866118 0.08866112]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00021894]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.0025939015, shape=(), dtype=float32)\n",
      "Input sequence: [[ 315 2222  887    9  124 1306   33 1049  719  861  394 1290  435 9454\n",
      "   582  230   26 3697  107  154  149  359 3808  631   24 1049  719 1076\n",
      "   453 3042 1479    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00550459]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.6267502e-01 1.1855500e-10 8.3768022e-08 1.4758684e-01 4.0741046e-09\n",
      " 5.8912015e-01 1.8875255e-09 6.1746355e-04 4.2166926e-07 2.4229569e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11546359 0.08879056 0.08879057 0.10291126 0.08879056 0.16003627\n",
      " 0.08879056 0.08884539 0.0887906  0.08879057]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00550459]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.0670934, shape=(), dtype=float32)\n",
      "Input sequence: [[ 804   14    6  786   19 5267   23   14   16 1579   14  227   93 1077\n",
      "  1108  125   14  227   28  199 5987   25    5  125   14  227    9    1\n",
      "     1    5   47  213   23  905  415 8848 2309   64  112    1    1   22\n",
      "    54   14  227  278  104 1976  125   14   23    1    1    1    1  439\n",
      "   938  579 5988  277 1379   64 2307   14  227   64 2307   39  132   55\n",
      "    74   64  314 1736   26  142 5988  277 1379  585  128 3429 1004  811\n",
      "   466   17 4680 1168  268    1    1  428  247  328  520 1779  919   52\n",
      "   107  419]]\n",
      "Value estimates: tf.Tensor([[-0.00334455]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[0.07084056 0.00511902 0.11168762 0.03745672 0.19527043 0.10496051\n",
      " 0.18734998 0.09731027 0.04312505 0.1468798 ], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09695066 0.09078379 0.10099281 0.09376751 0.10979688 0.1003157\n",
      " 0.10893068 0.09955118 0.09430052 0.10461025]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00334455]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.008824989, shape=(), dtype=float32)\n",
      "Input sequence: [[4076    1    1   45 1752 2530  264  276 3786 3282  179  434  209  155\n",
      "    19  121  276  253  179  830  245  127   26 1332  598 2764  116 1264\n",
      "  3181 1482  660  137  146   20 2764  290   46  127  116    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00523416]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1763755e-01 9.8621576e-11 7.7169972e-08 1.2969260e-01 3.0336202e-09\n",
      " 6.5222651e-01 1.5267856e-09 4.4280686e-04 4.9017456e-07 1.4796597e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10999388 0.08848093 0.08848095 0.10073363 0.08848093 0.16986664\n",
      " 0.08848093 0.08852013 0.08848098 0.08848093]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00523416]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.06472434, shape=(), dtype=float32)\n",
      "Input sequence: [[ 681   35   10  403   22   35   10  403   50  178   41 1421  364    3\n",
      "   173  432   35   10   15   82   77  837  501   48  363    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00419841]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.52503157e-01 6.48488069e-11 5.57976847e-08 1.34204760e-01\n",
      " 2.24467644e-09 6.12845540e-01 1.07109721e-09 4.46058286e-04\n",
      " 3.34716219e-07 1.44270045e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11414777 0.08867612 0.08867613 0.10141242 0.08867612 0.16366738\n",
      " 0.08867612 0.08871569 0.08867616 0.08867612]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00419841]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.052581515, shape=(), dtype=float32)\n",
      "Input sequence: [[1537    2   75  369   29   15  139   37   99 1085  329 2725  862  326\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00070667]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.4797536e-01 1.1913137e-10 8.5568296e-08 1.2970155e-01 3.7120673e-09\n",
      " 6.2179911e-01 1.8118175e-09 5.2329258e-04 5.1061721e-07 2.0723608e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11357445 0.08863113 0.08863115 0.10090553 0.08863113 0.16505559\n",
      " 0.08863113 0.08867753 0.08863118 0.08863114]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00070667]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.008643962, shape=(), dtype=float32)\n",
      "Input sequence: [[ 324  740   20  443 3163  324  619  170  457  251  454  824   90   48\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00161826]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.5881496e-01 1.5847530e-10 9.8631382e-08 1.3055974e-01 4.8851945e-09\n",
      " 6.1000288e-01 2.2999920e-09 6.2181102e-04 5.6425608e-07 2.6688125e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11488146 0.08868457 0.08868458 0.10105306 0.08868457 0.16321833\n",
      " 0.08868457 0.08873973 0.08868462 0.08868457]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00161826]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.019548565, shape=(), dtype=float32)\n",
      "Input sequence: [[  86   42 1110 1174    4  202   24   59    4 1174  195   59  479  345\n",
      "  1110   42    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00551899]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.5157911e-01 1.7277381e-10 1.0589081e-07 1.6003422e-01 5.6227862e-09\n",
      " 5.8776337e-01 2.4841365e-09 6.2260870e-04 5.3154150e-07 3.1229288e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11421254 0.08880846 0.08880847 0.10422127 0.08880846 0.1598515\n",
      " 0.08880846 0.08886378 0.0888085  0.08880847]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.6666666622222223\n",
      "Returns: [0.66666666]\n",
      "Advantages: tf.Tensor([[0.6611477]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(8.384406, shape=(), dtype=float32)\n",
      "Input sequence: [[ 52 375 500   9  30 404 822   9  10  51  85 308   1   1 401   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.0080878]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.4830863e-01 1.7660898e-10 1.1329853e-07 1.6118473e-01 6.0185044e-09\n",
      " 5.8975965e-01 2.8271829e-09 7.4637332e-04 5.4744322e-07 3.4526526e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11383083 0.0888016  0.08880161 0.10433318 0.0888016  0.16015856\n",
      " 0.0888016  0.0888679  0.08880164 0.0888016 ]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0080878]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.096671835, shape=(), dtype=float32)\n",
      "Input sequence: [[ 125  711   58   33 2850   58   12  125  711  270    5  145  559    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00959978]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.2720499e-01 7.5275319e-10 3.1086589e-07 1.5919520e-01 1.8691695e-08\n",
      " 6.1254507e-01 9.1751007e-09 1.0527235e-03 1.5853138e-06 8.5469203e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11132748 0.08870099 0.08870102 0.10400785 0.08870099 0.1636641\n",
      " 0.08870099 0.08879442 0.08870114 0.088701  ]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00959978]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.10799085, shape=(), dtype=float32)\n",
      "Input sequence: [[1153  654  718  162  346   60  194  330  826  216  718 3765  731  162\n",
      "   778  172  236  194 1681    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00910563]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.3268221e-01 3.8585202e-10 2.0559581e-07 1.4703156e-01 1.1265651e-08\n",
      " 6.1932713e-01 5.5018661e-09 9.5774536e-04 1.1034193e-06 6.1179442e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11188754 0.08866028 0.0886603  0.10270323 0.08866028 0.16470222\n",
      " 0.08866028 0.08874523 0.08866037 0.08866029]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00910563]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.10510936, shape=(), dtype=float32)\n",
      "Input sequence: [[ 398   53  115   57  257  115   57  283  389   29   51  323    2  327\n",
      "   201  318  249 1094    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00677289]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.5918213e-01 2.6267108e-10 1.6886172e-07 1.6463843e-01 8.8574215e-09\n",
      " 5.7521921e-01 4.1616488e-09 9.5923129e-04 7.9025006e-07 5.8822046e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11515448 0.08886269 0.08886271 0.10476616 0.08886269 0.15795521\n",
      " 0.08886269 0.08894797 0.08886275 0.08886269]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.33333333055555564\n",
      "Returns: [0.33333333]\n",
      "Advantages: tf.Tensor([[0.32656047]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(3.9224987, shape=(), dtype=float32)\n",
      "Input sequence: [[ 552  148   69   10 1887   41   93  147  380   16 1679 1607    8 1044\n",
      "     4    8   17   69    5  222   76  158    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01185422]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.1539631e-01 5.3443211e-10 2.7096402e-07 1.5008391e-01 1.4963218e-08\n",
      " 6.3328069e-01 7.9170706e-09 1.2372090e-03 1.5158340e-06 8.5293927e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10988925 0.08859511 0.08859513 0.10294146 0.08859511 0.16689374\n",
      " 0.08859511 0.08870479 0.08859525 0.08859512]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01185422]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.1342902, shape=(), dtype=float32)\n",
      "Input sequence: [[1134  822  562   66 4668  988  482  253  305   88 4668   66   17 8789\n",
      "   482  490   13   17  183    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01317039]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0531437e-01 1.7076126e-09 6.0012314e-07 1.6246848e-01 3.9847880e-08\n",
      " 6.3028675e-01 2.2149219e-08 1.9264281e-03 3.1317850e-06 2.0375619e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10881488 0.08861788 0.08861794 0.10425109 0.0886179  0.1664376\n",
      " 0.0886179  0.08878876 0.08861817 0.08861791]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01317039]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.1412401, shape=(), dtype=float32)\n",
      "Input sequence: [[1447    7 9918   43  326  208  101  136  664 3060   79 1122   44 1122\n",
      "   519   70  169  188  271 1632    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01606362]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.0616029e-01 8.5145302e-10 4.2275320e-07 1.5504526e-01 2.2790941e-08\n",
      " 6.3708198e-01 1.3816104e-08 1.7095777e-03 2.3189270e-06 1.4688909e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10885944 0.08857922 0.08857926 0.10343492 0.08857923 0.1674993\n",
      " 0.08857922 0.08873078 0.08857942 0.08857923]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01606362]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.17680861, shape=(), dtype=float32)\n",
      "Input sequence: [[ 258   30  127   46 2021 5540   87 1096 1127    4    8    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01787395]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.8505797e-01 3.8648253e-09 1.1309986e-06 1.5861668e-01 7.6573151e-08\n",
      " 6.5370792e-01 4.7023612e-08 2.6099582e-03 5.9995868e-06 3.3851708e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1064814  0.08849201 0.08849211 0.10370278 0.08849202 0.17013976\n",
      " 0.08849202 0.08872328 0.08849255 0.08849205]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01787395]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.18404272, shape=(), dtype=float32)\n",
      "Input sequence: [[   9  324 3020    6  557  788   65 2642  499 1044  302    4 3088  603\n",
      "   217   33    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02060946]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.2786880e-01 1.0371591e-09 5.3399663e-07 1.9763948e-01 3.2056580e-08\n",
      " 5.7258737e-01 1.6757459e-08 1.9013394e-03 2.2353565e-06 2.3347994e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.11164534 0.08889522 0.08889526 0.10832087 0.08889522 0.15759772\n",
      " 0.08889522 0.0890644  0.08889543 0.08889525]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02060946]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.22317593, shape=(), dtype=float32)\n",
      "Input sequence: [[ 348  126 1237  878  218   14   92 3448 2537   14  672   86   17  722\n",
      "   981  323   99  209   39   47  580  105  145    4    2 1768 5617 2705\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01778613]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7770725e-01 1.3930599e-09 5.9590946e-07 1.4429666e-01 3.2439214e-08\n",
      " 6.7599565e-01 2.0056170e-08 1.9959938e-03 3.6088543e-06 1.6981961e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10554054 0.08835721 0.08835726 0.10207263 0.08835722 0.17370935\n",
      " 0.08835722 0.08853375 0.08835753 0.08835723]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01778613]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.19192666, shape=(), dtype=float32)\n",
      "Input sequence: [[ 129  479  890  629  109  113   44  116   72  818  113   21  129 4624\n",
      "   151 2379 1718  109   21    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02154221]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6889261e-01 1.4488862e-09 6.3436607e-07 1.6131622e-01 3.6146105e-08\n",
      " 6.6777557e-01 2.1843539e-08 2.0110062e-03 3.6796298e-06 2.0884050e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10467659 0.0884098  0.08840986 0.10388651 0.08840981 0.17238985\n",
      " 0.08840981 0.08858778 0.08841013 0.08840983]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02154221]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.23113273, shape=(), dtype=float32)\n",
      "Input sequence: [[ 165   75  629  514  474   38   35   59    4  479  868  885  681  163\n",
      "  1037   52  185    6 2245 1610  185 9488 4402   15 2723    4    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02096909]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6661285e-01 1.9436830e-09 7.6151991e-07 1.4818330e-01 4.3080671e-08\n",
      " 6.8290937e-01 2.7008499e-08 2.2887143e-03 4.6641812e-06 2.3187822e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10432768 0.08831622 0.08831629 0.10242257 0.08831622 0.17483333\n",
      " 0.08831622 0.08851857 0.08831663 0.08831624]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02096909]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.22235502, shape=(), dtype=float32)\n",
      "Input sequence: [[  69  233   89   29 2322   40 3924  405   22  118  233 1020  198  233\n",
      "   190    3  175 1084   29    7   58    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01893202]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.8620589e-01 2.2131752e-09 8.8417755e-07 1.6859803e-01 5.5023978e-08\n",
      " 6.4250928e-01 3.4438511e-08 2.6808020e-03 4.6479868e-06 3.6235079e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10668116 0.08855631 0.08855638 0.10481916 0.08855631 0.1683673\n",
      " 0.08855631 0.08879403 0.08855671 0.08855634]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01893202]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.19786347, shape=(), dtype=float32)\n",
      "Input sequence: [[10982   175  1016   615   107  1875   783    21    11    63    27     3\n",
      "     83  1465    21  1213  1016   615   347     9    21    11  5021   111\n",
      "   1774 10983  1985    55   435    11    21     9    94   783    21    11\n",
      "    392    65    53     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.01958063]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7194730e-01 2.1255506e-09 8.4672632e-07 1.5541169e-01 4.8278309e-08\n",
      " 6.6970783e-01 3.4086352e-08 2.9269394e-03 4.8581110e-06 3.1830521e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10498387 0.0883989  0.08839897 0.10326218 0.08839891 0.17270195\n",
      " 0.08839891 0.08865801 0.08839933 0.08839893]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01958063]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.20529903, shape=(), dtype=float32)\n",
      "Input sequence: [[122  63  48 111  58  10 657 951  42  71   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.02482712]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6956893e-01 3.9522736e-09 1.2501266e-06 1.8259060e-01 8.7979835e-08\n",
      " 6.4399761e-01 6.0518886e-08 3.8346471e-03 6.2800368e-06 5.5408418e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10491361 0.08855008 0.0885502  0.10628868 0.08855009 0.1686062\n",
      " 0.08855008 0.08889028 0.08855063 0.08855012]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02482712]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.25180224, shape=(), dtype=float32)\n",
      "Input sequence: [[ 168 5973  436  516    6   44  112  768  228  158    6  805  759  433\n",
      "  2297 3257  849  696 5974  271  197    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01775254]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6611767e-01 6.4469430e-09 1.7465478e-06 1.7287183e-01 1.2861942e-07\n",
      " 6.5724438e-01 8.4500918e-08 3.7541462e-03 9.3335548e-06 6.8098285e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10446313 0.08847468 0.08847484 0.10517108 0.0884747  0.17070909\n",
      " 0.0884747  0.08880746 0.08847552 0.08847475]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01775254]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.17651242, shape=(), dtype=float32)\n",
      "Input sequence: [[  93   14  738  131  522   50 1396  194   33  800   14  677   16  738\n",
      "   668   88   14  448 2665  196 1705    4 2442    1 1930 3094 4101  426\n",
      "   541   62 4949  234  866   16    3 1262  131  234 3002    4 2896  366\n",
      "   841  173   19 3986   28    4 1165   62  234  279  261    4 2685 1290\n",
      "   517  800   14  444 1057  549  581    1   16 3321   14  866 1145  513\n",
      "   185   18  810   30    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0172319]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7468867e-01 2.1135347e-09 8.8600143e-07 1.7959042e-01 5.4342685e-08\n",
      " 6.4303386e-01 3.3432336e-08 2.6811771e-03 4.5334964e-06 3.5802063e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10545687 0.08855406 0.08855414 0.10597506 0.08855408 0.16845138\n",
      " 0.08855408 0.08879181 0.08855448 0.08855409]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0172319]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.18033601, shape=(), dtype=float32)\n",
      "Input sequence: [[  12 4367  212  442   12   92  166 1420  997  206 1225   12  417  445\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02135962]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.8300028e-01 2.3433535e-09 9.2859437e-07 1.7949973e-01 6.0882243e-08\n",
      " 6.3448691e-01 3.7043911e-08 3.0069896e-03 4.6139057e-06 4.2450867e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10639385 0.08860138 0.08860147 0.10602207 0.08860139 0.167107\n",
      " 0.08860139 0.08886821 0.0886018  0.08860142]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02135962]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.22194682, shape=(), dtype=float32)\n",
      "Input sequence: [[  12   82    5  261   82 1535   12    4  298    5 1330 1176   39 2384\n",
      "     9    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02302614]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7402624e-01 5.5427325e-09 1.6196270e-06 2.0315461e-01 1.2568320e-07\n",
      " 6.1917931e-01 7.4341656e-08 3.6297808e-03 7.4052741e-06 7.5429773e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10553785 0.0886808  0.08868094 0.1086572  0.08868081 0.16471599\n",
      " 0.0886808  0.08900328 0.08868146 0.08868087]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02302614]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.22972949, shape=(), dtype=float32)\n",
      "Input sequence: [[2644   36  108  763   83  166  105   18  105  880    5   68  555  225\n",
      "   131   38  108   18    3  771  298  169   62   59  368  134 1788   49\n",
      "   995   39  591  288  109 1131  490  256    4 1100   18    2    6    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01862542]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4971796e-01 2.0390354e-09 8.2335754e-07 1.4819923e-01 4.5171529e-08\n",
      " 6.9948471e-01 3.1280035e-08 2.5917601e-03 5.1532238e-06 2.5796828e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10245664 0.08821012 0.0882102  0.10230116 0.08821013 0.17754187\n",
      " 0.08821013 0.08843904 0.08821058 0.08821015]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01862542]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.19648856, shape=(), dtype=float32)\n",
      "Input sequence: [[  18    2  491   15  163 1141 1173 2372   68   81  115   57   73   13\n",
      "     3  903  275    2   33  115   57    1    1  189  834  661  280  898\n",
      "  1647  746 1647  682 1451 2259 1675  940  367    8    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01928632]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.8877827e-01 1.5676674e-09 7.6186240e-07 2.0610967e-01 4.7038725e-08\n",
      " 6.0246110e-01 2.7606793e-08 2.6463303e-03 3.3513254e-06 3.7931099e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10720586 0.08876324 0.0887633  0.1090801  0.08876324 0.16213572\n",
      " 0.08876324 0.08899845 0.08876354 0.08876327]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01928632]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.20351832, shape=(), dtype=float32)\n",
      "Input sequence: [[   4    8   27  602  229 1319 1764   79  331  151 3738  428   27   97\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0249527]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3519135e-01 8.1052702e-09 2.0037696e-06 1.5118767e-01 1.2494858e-07\n",
      " 7.1050149e-01 8.8152824e-08 3.1049217e-03 1.1833133e-05 4.9422829e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10089415 0.08813595 0.08813614 0.10252108 0.08813597 0.1793577\n",
      " 0.08813597 0.08841003 0.088137   0.08813599]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0249527]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2483118, shape=(), dtype=float32)\n",
      "Input sequence: [[   9   62   98  427   57   11    8 1422  428 1808   61  572  230 2324\n",
      "   121  951 1230  245  426  159   37  384  113  104 1157  857 2328  158\n",
      "  1234  101  177  113  337  425    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02629135]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7887235e-01 2.1665936e-09 8.9632130e-07 2.0573577e-01 6.1113276e-08\n",
      " 6.1250961e-01 3.5360209e-08 2.8768477e-03 4.0310251e-06 4.2943421e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10608966 0.08871353 0.08871361 0.10897822 0.08871353 0.1636814\n",
      " 0.08871353 0.0889691  0.08871388 0.08871356]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02629135]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2737091, shape=(), dtype=float32)\n",
      "Input sequence: [[1091 8539 2564 5049 5877  450 3871  307  277  266  216  142 1170  634\n",
      "   619  142 4625 1485  130 2404 1382  112 2404    2 5878 8540   52  893\n",
      "   756  266  857  893   79 5878  120   79  756   55    7  326    7  445\n",
      "    47   18  918   47   42   55  266    4    3   88  367 1513    1    1\n",
      "   189   53 2991   11  171 8541  266  583   87  177  235 2706 1091 5534\n",
      "  8542 8543 1898 3469 5713 8544 8545    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01783361]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4623770e-01 2.1986879e-09 8.3130647e-07 1.5196720e-01 5.1095416e-08\n",
      " 6.9875509e-01 3.6709892e-08 3.0335232e-03 5.2021110e-06 3.2589065e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10210682 0.08821543 0.0882155  0.10269353 0.08821543 0.17742303\n",
      " 0.08821543 0.08848344 0.08821588 0.08821546]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01783361]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.1867774, shape=(), dtype=float32)\n",
      "Input sequence: [[   9   73   96 1936  162  171   48  263  525  320  223    9   32  873\n",
      "    17  382 1683  320    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02749806]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7871828e-01 1.3800902e-09 6.6280535e-07 2.0262215e-01 4.1109427e-08\n",
      " 6.1618102e-01 2.3310998e-08 2.4744435e-03 3.0403680e-06 3.1146848e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10605095 0.0886948  0.08869486 0.10861653 0.0886948  0.1642488\n",
      " 0.0886948  0.08891455 0.08869507 0.08869483]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02749806]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.29264563, shape=(), dtype=float32)\n",
      "Input sequence: [[1155  122   63  109 2267    2  562 1253  192  104   32  446   41    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02319657]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4016123e-01 3.4142276e-09 1.1125610e-06 1.6299088e-01 7.1122834e-08\n",
      " 6.9323033e-01 5.3670764e-08 3.6094021e-03 6.4975529e-06 4.3592874e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10152955 0.08825132 0.08825141 0.10387409 0.08825132 0.17651731\n",
      " 0.08825132 0.08857043 0.08825189 0.08825136]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02319657]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.23783667, shape=(), dtype=float32)\n",
      "Input sequence: [[  81   11   21  846  230  360   69  988  585 1440 4167   19  637   11\n",
      "   846  315   50   11  522  122 1331  130  294   26  876   59  188    3\n",
      "     6    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02087793]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4182414e-01 2.9564746e-09 1.0297985e-06 1.7725737e-01 6.8079643e-08\n",
      " 6.7802304e-01 4.4775465e-08 2.8880006e-03 5.8698110e-06 4.0064631e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1018071  0.08834554 0.08834562 0.10547913 0.08834554 0.17403889\n",
      " 0.08834554 0.08860105 0.08834605 0.08834557]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02087793]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.21574372, shape=(), dtype=float32)\n",
      "Input sequence: [[ 501   65  134 3242  796 1199 2677   58    7  189   17 2105   83  819\n",
      "    89   54   36    7  165  419  796  344 1288 7236 5088 2035  226   97\n",
      "  1812  920   49   15  832 2498   26  391   76 4173  479  920  130   76\n",
      "  1991    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01682484]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4204599e-01 2.7485378e-09 9.6095471e-07 1.6433276e-01 6.2023105e-08\n",
      " 6.9080061e-01 4.1155999e-08 2.8135353e-03 5.6612016e-06 3.5945567e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10173817 0.08826614 0.08826622 0.10403104 0.08826614 0.17611851\n",
      " 0.08826614 0.08851483 0.08826663 0.08826617]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01682484]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.17484741, shape=(), dtype=float32)\n",
      "Input sequence: [[491  28   6  55 263 257  12   3   5 186 556  82 213 722   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.01932873]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5570636e-01 6.8987234e-09 1.7506140e-06 1.9745170e-01 1.3723107e-07\n",
      " 6.4337289e-01 8.3343110e-08 3.4577625e-03 8.5409820e-06 7.0727356e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10346839 0.08854933 0.08854949 0.10787914 0.08854934 0.16849948\n",
      " 0.08854934 0.08885605 0.08855008 0.08854939]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01932873]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.19208655, shape=(), dtype=float32)\n",
      "Input sequence: [[ 350  132  255   10  336  456  860  186   76 1405   78   66    5    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01940731]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4160150e-01 1.9420077e-09 8.1843348e-07 1.5405200e-01 4.1966558e-08\n",
      " 7.0214015e-01 2.9577214e-08 2.2001367e-03 5.0019789e-06 2.3234060e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10160711 0.08819163 0.0881917  0.10288009 0.08819164 0.17797662\n",
      " 0.08819164 0.08838587 0.08819208 0.08819165]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01940731]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.20568405, shape=(), dtype=float32)\n",
      "Input sequence: [[ 199 2608 6605  109   20   97 1450   83  291  109  683 2823  453   40\n",
      "   474  842  489 6606   34   70    4  484  138  343 2823  590  532  153\n",
      "   366    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01890231]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3084920e-01 1.6953967e-09 6.7260669e-07 1.5598413e-01 3.8687720e-08\n",
      " 7.1088403e-01 2.5847784e-08 2.2775943e-03 4.1636463e-06 2.0627873e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10045192 0.08813151 0.08813157 0.10300878 0.08813152 0.17941725\n",
      " 0.08813152 0.08833247 0.08813187 0.08813153]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01890231]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.20198625, shape=(), dtype=float32)\n",
      "Input sequence: [[   8    6  882  416  384  136 1220   50  303   10    8  186  150  149\n",
      "     5 7974  471  147 1119    5  257  787    6  303  149  150   10  240\n",
      "  1723  123 2298  684  164  541    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02125639]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5395881e-01 3.5327226e-09 1.0676366e-06 1.9395421e-01 8.3805396e-08\n",
      " 6.4910203e-01 4.7660471e-08 2.9778057e-03 5.3663334e-06 4.8373471e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10324974 0.08851676 0.08851686 0.10746296 0.08851677 0.16940528\n",
      " 0.08851677 0.08878075 0.08851724 0.08851681]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02125639]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.2180686, shape=(), dtype=float32)\n",
      "Input sequence: [[ 175   29   23  159 3527 4560 1344  180  519  406  402  330   43   29\n",
      "    15  296 1344  180  608 3584  301    5   29  393   62  368    2   17\n",
      "   385 1219   33    2  201  158  123    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01526113]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3577501e-01 1.3514161e-09 5.7867470e-07 1.5610063e-01 3.2829359e-08\n",
      " 7.0583159e-01 2.2860304e-08 2.2883024e-03 3.6353626e-06 2.1072846e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10098788 0.08816637 0.08816642 0.10306153 0.08816637 0.17858365\n",
      " 0.08816637 0.08836836 0.08816669 0.08816639]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01526113]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.16426724, shape=(), dtype=float32)\n",
      "Input sequence: [[ 274   58  445   22  260   22 1811  361  592 1467 3675  445    8  539\n",
      "  1118  361    9    9    9   33    5   59  175  545  126    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02165747]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5510374e-01 3.0399414e-09 1.0148138e-06 2.1335921e-01 7.3211261e-08\n",
      " 6.2896085e-01 4.2333781e-08 2.5699975e-03 4.6836622e-06 4.4568318e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10349121 0.08862226 0.08862235 0.10969922 0.08862226 0.16622525\n",
      " 0.08862226 0.08885031 0.08862267 0.08862229]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02165747]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.22379598, shape=(), dtype=float32)\n",
      "Input sequence: [[ 584 7003   30  444  104 3602  240  123 1827   98 1143 3206  422   79\n",
      "    33  584 7004   30 3600    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01862342]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3549791e-01 3.6757191e-09 1.0981082e-06 1.6039863e-01 7.4925232e-08\n",
      " 7.0123351e-01 5.1934148e-08 2.8617610e-03 6.5341910e-06 3.8617614e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10099549 0.08819744 0.08819754 0.10354192 0.08819744 0.17782705\n",
      " 0.08819744 0.0884502  0.08819801 0.08819748]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01862342]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.19160306, shape=(), dtype=float32)\n",
      "Input sequence: [[  9  38  35  82 771   5  27   3   9 335  67   5 240 666   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.02581329]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6212690e-01 1.0314269e-09 5.0591478e-07 2.0646799e-01 3.0639477e-08\n",
      " 6.2937933e-01 1.7750702e-08 2.0227409e-03 2.3544383e-06 2.2530608e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10422094 0.08862253 0.08862258 0.10894619 0.08862253 0.16629535\n",
      " 0.08862253 0.08880197 0.08862274 0.08862256]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02581329]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.27983475, shape=(), dtype=float32)\n",
      "Input sequence: [[  26  257   29 1042 1007  147  244  490   17  148 1007   67   32 1816\n",
      "   235 2313   22   49  470  154 8183    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01533546]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3021845e-01 1.7527299e-09 6.6443226e-07 1.5861443e-01 3.9840852e-08\n",
      " 7.0907301e-01 2.5906399e-08 2.0891197e-03 4.1142403e-06 2.1663483e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10040198 0.08814326 0.08814332 0.10329386 0.08814327 0.17911652\n",
      " 0.08814327 0.0883276  0.08814362 0.08814328]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01533546]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.16390687, shape=(), dtype=float32)\n",
      "Input sequence: [[  50   20 1623  334  864 1002  140   88  101    1    1  130 4948  865\n",
      "   301 6567    1    1  319   26 3456 1646    5    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01699921]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4254452e-01 5.0335403e-09 1.2958275e-06 1.9390157e-01 1.0218059e-07\n",
      " 6.6036052e-01 6.6686148e-08 3.1847456e-03 6.5942745e-06 5.7300656e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1020005  0.08844962 0.08844974 0.1073758  0.08844964 0.17119338\n",
      " 0.08844963 0.08873177 0.08845021 0.08844968]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01699921]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.1719773, shape=(), dtype=float32)\n",
      "Input sequence: [[3459  594    6  142   90  142   37 1366 1221    7  293 5814  182  142\n",
      "     7  147   39 5309  238   55    1    1  799  102 1920   37    1    1\n",
      "    39    6  253  146  291  119    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0114694]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.2514904e-01 1.4867471e-09 5.8129837e-07 1.5605754e-01 3.6141017e-08\n",
      " 7.1667719e-01 2.4741361e-08 2.1117332e-03 3.6854572e-06 2.0307205e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09983463 0.08809061 0.08809067 0.10296855 0.08809063 0.18037593\n",
      " 0.08809063 0.08827684 0.08809094 0.08809064]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0114694]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.123377025, shape=(), dtype=float32)\n",
      "Input sequence: [[   8  177  187 1688  187    4  707 1261   62    4  734  187   39  464\n",
      "    64    3 3125   44 3288   34   30   18    4  281 3591    6 1442  187\n",
      "    39    4    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0168226]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4064008e-01 1.8523848e-09 6.4505974e-07 1.9147548e-01 4.5613579e-08\n",
      " 6.6575903e-01 2.5734268e-08 2.1209696e-03 3.3646656e-06 2.6288984e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10176799 0.08841624 0.08841629 0.10707517 0.08841624 0.17205508\n",
      " 0.08841624 0.08860397 0.08841654 0.08841626]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0168226]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.179164, shape=(), dtype=float32)\n",
      "Input sequence: [[  301   236    16   430  1180  1147    59   550   298   492  4444  2723\n",
      "     54    97     2    12    26  1709    49    43   379    12    39   870\n",
      "     12   688  6368  2880 10525  1049  2859    45   997     2  2879     9\n",
      "   1395   774 10526    54   213    26   207   207    79   285   415    13\n",
      "    153    56    12   445   837   557  2365    12  1465   717  3230    36\n",
      "    430  4791   440   379     1     1  4450    83     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.01146521]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3394463e-01 1.0965392e-09 4.6533924e-07 1.4435695e-01 2.5701549e-08\n",
      " 7.1980089e-01 1.7638273e-08 1.8939520e-03 3.0248264e-06 1.5423078e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10069351 0.08807041 0.08807046 0.10174744 0.08807042 0.18089877\n",
      " 0.08807041 0.08823738 0.08807068 0.08807043]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01146521]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.12538816, shape=(), dtype=float32)\n",
      "Input sequence: [[  61    1 1778   69 2157 1824  128  351  227 5185 1087  367  351   76\n",
      "   518  227 1103  314  379  493  548  227 2799  314  761 2435 4191  556\n",
      "  1724  680  493  128 3193  314  198  314 2027    1    1  159   61    1\n",
      "    69 2157 1824  128   47  761 1087  367   76 1602 1531  680  381  518\n",
      "   227  548  227  761 2435 1103  227 4191  556  144    5 2027  680    1\n",
      "     1 2164  674   61   60  384  278  159 1189  489 1733  250   80   17\n",
      "  1806    8    4 1330   16  787 1602    1    1    8  969  191   65 2021\n",
      "     8   54]]\n",
      "Value estimates: tf.Tensor([[0.01011784]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[0.04333555 0.01344    0.13209619 0.03265473 0.20728524 0.06608351\n",
      " 0.1764112  0.07420737 0.05199342 0.20249277], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09426125 0.09148496 0.10301049 0.09325983 0.11105437 0.09643008\n",
      " 0.10767806 0.09721665 0.0950809  0.11052342]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01011784]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.026279192, shape=(), dtype=float32)\n",
      "Input sequence: [[ 1916    51 10045 10046  1287   188    90  1945    23   561   222  3842\n",
      "     22   124   107   245    18   105    99   571     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.01652155]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.2903336e-01 9.2170060e-10 4.0100247e-07 1.4768937e-01 2.2343416e-08\n",
      " 7.2136557e-01 1.5717708e-08 1.9085412e-03 2.6172149e-06 1.4361731e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10018708 0.0880589  0.08805893 0.10207371 0.0880589  0.18115833\n",
      " 0.0880589  0.08822712 0.08805913 0.08805891]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01652155]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.18192206, shape=(), dtype=float32)\n",
      "Input sequence: [[  49  370 1023 3776 1833 1899 4399   35 7770  463 7771  167  274 1908\n",
      "   102 7772 7773 1077  631 3777  463 3776 1833  402 7774 1068 4460   11\n",
      "  2025 3776 1833 3149  409 4235 7775 2242  421 2970  452  109    6   53\n",
      "   155   65  223  622 1582   23  282 1702 2191 2600 7776 7777 1506 1349\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01311703]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.34052947e-01 6.05028805e-10 3.13193055e-07 1.72897846e-01\n",
      " 1.76169994e-08 6.91429138e-01 1.10594405e-08 1.61778298e-03\n",
      " 1.80803784e-06 1.27883581e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10091919 0.08825825 0.08825827 0.10491652 0.08825825 0.17621349\n",
      " 0.08825825 0.08840115 0.08825841 0.08825825]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01311703]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.14678095, shape=(), dtype=float32)\n",
      "Input sequence: [[  3 265  24 309  50 309  76  69  10 852 265 400  13 712   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.01549874]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.31451473e-01 6.74800604e-10 3.26584257e-07 1.48870528e-01\n",
      " 1.71260108e-08 7.18023479e-01 1.20040946e-08 1.65193202e-03\n",
      " 2.10172539e-06 1.14681775e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10045616 0.08808216 0.08808219 0.10222134 0.08808216 0.1806016\n",
      " 0.08808216 0.08822779 0.08808234 0.08808216]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01549874]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.17318544, shape=(), dtype=float32)\n",
      "Input sequence: [[  45 2293    5 4650 2751  768 3824  268  748  131    5   22 2737  477\n",
      "  4379 4177   67 9605  434  158  219   67  174 4016  999 2090    5 1298\n",
      "  3571 2737  768    1    1  522 3106  148   65 2318 3516 1097    5 2737\n",
      "    22   49 4102  954 1297 4053 2737  865  617  489  421  865  617 1370\n",
      "    24 9606 1730  219  301  335 2090 9607  353    1    1  879 2090   22\n",
      "     5 1967  159  682 9608  599  332 1205    5 2737 1370 2090  557 2022\n",
      "  2737 2805  308 1730 1266 5800  449 1297    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00596285]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3167500e-01 4.2004539e-10 2.5265726e-07 1.8415776e-01 1.3313422e-08\n",
      " 6.8290508e-01 7.9338571e-09 1.2604237e-03 1.4036669e-06 9.6172549e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1007378  0.08830937 0.08830938 0.10616601 0.08830937 0.17481902\n",
      " 0.08830937 0.08842074 0.0883095  0.08830938]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00596285]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.06792846, shape=(), dtype=float32)\n",
      "Input sequence: [[  45  426   16  430  244  145  323  298   12  234  707   12  933  685\n",
      "  1477 3692  479  226 1505    4  646 5009  529   12  729   64    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00951311]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.32150769e-01 8.07423906e-10 3.82358792e-07 1.94783121e-01\n",
      " 2.32912480e-08 6.71675384e-01 1.29149385e-08 1.38815667e-03\n",
      " 2.01682633e-06 1.43063701e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10086227 0.08837643 0.08837646 0.10738155 0.08837643 0.1729981\n",
      " 0.08837643 0.08849919 0.0883766  0.08837644]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00951311]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.10547227, shape=(), dtype=float32)\n",
      "Input sequence: [[  154    31     6    45  3727    49    91   201    48  1406   803   993\n",
      "   1885    73   292  1846   418   143 10320    73   196   694  1529  3663\n",
      "      1     1   372 10321   183   113    37   109   143   816   688    37\n",
      "  10322   326    73    37    15  2016   109   577    73  1475   273   335\n",
      "    255 10323   417     9   165   201  6248   443    37   590   259   282\n",
      "    201    73   389    29    37    67     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.00760415]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.2289310e-01 3.9503667e-10 2.2123137e-07 1.6462739e-01 1.1624561e-08\n",
      " 7.1110791e-01 7.6672482e-09 1.3699317e-03 1.3844789e-06 8.4780247e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09965013 0.08812641 0.08812643 0.10389697 0.08812641 0.17944705\n",
      " 0.08812641 0.08824722 0.08812653 0.08812643]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00760415]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.08704036, shape=(), dtype=float32)\n",
      "Input sequence: [[ 382   55   93  238  735   55  527 3447 2999   44   60  238  781  480\n",
      "    27   81  811  237 1380 8596  762 2889  384  164  293   78  146 3487\n",
      "    97   26  132  293 2016  135 3010 1157  132 1380  490  162   27  885\n",
      "  1380   55    1    1    5 8597 8598  110 1380  116  338  116   46   42\n",
      "    85 8599 1380 1380  501 5896   12   14  108 5896  581 2898   14    4\n",
      "     8 1380  863 1056    1    1    2  640    5  265  174 3735    5   58\n",
      "  1380    5    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00461298]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.1994246e-01 3.2414255e-10 1.9402593e-07 1.5908428e-01 9.4790149e-09\n",
      " 7.1970212e-01 6.5439796e-09 1.2696090e-03 1.2591270e-06 7.1063404e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09928981 0.08806723 0.08806725 0.10325326 0.08806723 0.18087435\n",
      " 0.08806723 0.08817911 0.08806734 0.08806723]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00461298]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.05331669, shape=(), dtype=float32)\n",
      "Input sequence: [[ 125   14    3 1285 1574 1455 8880 2943 2943 2943   95  205 8881    4\n",
      "   665  493   72   82    5    8   78  285   39  172   53   85 1384  870\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01429748]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.10505566e-01 5.71091674e-10 2.85092796e-07 1.52064472e-01\n",
      " 1.47634687e-08 7.36133099e-01 1.01611635e-08 1.29449938e-03\n",
      " 1.93422647e-06 8.76490631e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09822523 0.08794905 0.08794906 0.10239337 0.08794905 0.18362407\n",
      " 0.08794905 0.08806296 0.08794921 0.08794905]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01429748]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.16169673, shape=(), dtype=float32)\n",
      "Input sequence: [[ 28 106  33 187  39  58 187  39 916 352  58   5 265  27  13  97 136 300\n",
      "    9 124   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.01179803]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3286658e-01 4.1442114e-10 2.2793361e-07 1.6594170e-01 1.2064496e-08\n",
      " 6.9982892e-01 7.6850748e-09 1.3611240e-03 1.3284864e-06 8.7320110e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1007374  0.08820385 0.08820387 0.10412502 0.08820385 0.17759036\n",
      " 0.08820385 0.08832399 0.08820397 0.08820385]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01179803]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.13479646, shape=(), dtype=float32)\n",
      "Input sequence: [[  58  331   63 1971  406   31  240  595   27  596   99    3 1097  348\n",
      "    19    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01390968]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.10701345e-01 1.41701251e-09 5.18517993e-07 1.63146213e-01\n",
      " 3.22046496e-08 7.24343300e-01 2.26308998e-08 1.80528348e-03\n",
      " 3.19095739e-06 1.70165137e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09833756 0.08803238 0.08803243 0.10363249 0.08803239 0.18164387\n",
      " 0.08803239 0.08819144 0.08803266 0.08803239]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01390968]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.15086195, shape=(), dtype=float32)\n",
      "Input sequence: [[ 10 118 186  84 115  57   8 386  77   9   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.01582602]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3528685e-01 2.9165029e-10 1.8376579e-07 1.7964280e-01 9.1580636e-09\n",
      " 6.8396217e-01 5.3543880e-09 1.1069102e-03 1.0019354e-06 6.6261563e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10109651 0.08830429 0.08830431 0.10568167 0.08830429 0.17499386\n",
      " 0.08830429 0.08840209 0.08830439 0.0883043 ]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01582602]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.18375148, shape=(), dtype=float32)\n",
      "Input sequence: [[7017   14  277 1063   52   22 2001 1714   92  166   93  750   19  577\n",
      "  1518  140   34  485  251  452 1553 1437  668   14  127 1534 2040 3521\n",
      "  1342 7018 4230 1734   14  488  275  127 1784   19  112   23 1126    2\n",
      "  2001 1714  129   14    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00854754]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.1219413e-01 3.8434766e-10 2.0396506e-07 1.4438939e-01 1.0164086e-08\n",
      " 7.4221349e-01 6.9981092e-09 1.2012459e-03 1.4142031e-06 6.4391969e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09834257 0.08790553 0.08790556 0.10156025 0.08790553 0.18465261\n",
      " 0.08790553 0.0880112  0.08790566 0.08790554]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00854754]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.09859919, shape=(), dtype=float32)\n",
      "Input sequence: [[  49   29   15  167  756  942  102 9197  128 1101   39   57 1199  306\n",
      "   131  167   82    5  705  620  198  167    2 1908  167  322  135   41\n",
      "    31   96  175  440  167   29   59    3   29   46   18    4  440    5\n",
      "   131   82    5  167 1079 1314    2  345  167    2  371  181  190  198\n",
      "   181  131  755   98   59   13  148   13   15  352 3037  167    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00364817]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.2270675e-01 2.9877764e-10 1.7840074e-07 1.6488269e-01 9.1621963e-09\n",
      " 7.1123326e-01 5.8670042e-09 1.1758908e-03 1.0809645e-06 6.8016433e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09963024 0.08812524 0.08812526 0.10392211 0.08812524 0.17946716\n",
      " 0.08812524 0.08822893 0.08812533 0.08812524]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00364817]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.04236409, shape=(), dtype=float32)\n",
      "Input sequence: [[  51   14  303  876 5195  269   14   43   90  326  270  728   14    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01279601]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.1638316e-01 9.9333153e-10 3.9709440e-07 1.5712754e-01 2.3708751e-08\n",
      " 7.2495985e-01 1.6025842e-08 1.5264612e-03 2.4540136e-06 1.2824434e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09889533 0.0880301  0.08803014 0.10300798 0.08803011 0.18175119\n",
      " 0.0880301  0.08816458 0.08803032 0.08803012]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01279601]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.14132264, shape=(), dtype=float32)\n",
      "Input sequence: [[ 38  35   3 432 529  38  35  28 249  13  56   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.01413605]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.2435709e-01 2.5824567e-10 1.6526202e-07 1.6918081e-01 8.3007352e-09\n",
      " 7.0544797e-01 5.1578892e-09 1.0129466e-03 9.9433919e-07 6.1503059e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09983847 0.08816381 0.08816382 0.10441542 0.08816381 0.17850998\n",
      " 0.08816381 0.08825316 0.08816389 0.08816382]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01413605]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.1650691, shape=(), dtype=float32)\n",
      "Input sequence: [[ 262  311  616 3814   97  695  364    4  912  136 1730   86   42    7\n",
      "    37    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0091547]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0659863e-01 3.5451755e-10 1.8488034e-07 1.5406930e-01 1.0155557e-08\n",
      " 7.3825020e-01 6.3827610e-09 1.0803698e-03 1.2505102e-06 6.1752111e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09782336 0.08793208 0.08793209 0.10257907 0.08793208 0.18397775\n",
      " 0.08793208 0.08802713 0.08793219 0.08793209]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0091547]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.10608671, shape=(), dtype=float32)\n",
      "Input sequence: [[  54 2022  186   84  150    9 3837    5    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01522786]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.1630096e-01 9.1438823e-10 3.5609236e-07 1.8259825e-01 2.2588516e-08\n",
      " 6.9975168e-01 1.3593462e-08 1.3464855e-03 2.0056777e-06 1.2469715e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09907456 0.0881969  0.08819693 0.10586556 0.0881969  0.17756264\n",
      " 0.0881969  0.08831573 0.08819707 0.0881969 ]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01522786]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.1691271, shape=(), dtype=float32)\n",
      "Input sequence: [[ 542  187   39  916  352  266    4  205  302   34 1378 1284   18  105\n",
      "   254  512  228  259    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00573981]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.1030480e-01 5.0688470e-10 2.3827083e-07 1.6623221e-01 1.3684458e-08\n",
      " 7.2231811e-01 8.4373140e-09 1.1431434e-03 1.4573952e-06 7.9143433e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.0983128  0.08804513 0.08804515 0.10396785 0.08804513 0.18130264\n",
      " 0.08804513 0.08814583 0.08804525 0.08804514]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00573981]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.06553817, shape=(), dtype=float32)\n",
      "Input sequence: [[  78 1675 4671  990  692  196 9351 9352  275   75    3  124  990  988\n",
      "     4   26  145   18  156 1484  990   77  202    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01208192]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.2093515e-01 2.1786835e-10 1.3573819e-07 1.5708756e-01 6.5313404e-09\n",
      " 7.2096246e-01 4.2922883e-09 1.0137858e-03 8.4106603e-07 4.8234305e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09937866 0.08805858 0.08805858 0.10303716 0.08805858 0.18108466\n",
      " 0.08805858 0.08814789 0.08805865 0.08805858]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01208192]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.14265421, shape=(), dtype=float32)\n",
      "Input sequence: [[ 137  827    4 1084  635    6 1549  693  411   29  121   50 2337 1653\n",
      "     5  213  719 3117  455   29 1868   20  416 2956  606 1273  417    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00628352]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0360595e-01 2.8161307e-10 1.6279617e-07 1.4216463e-01 7.7591444e-09\n",
      " 7.5334871e-01 5.0263629e-09 8.7934174e-04 1.1359365e-06 4.4166299e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09740686 0.08782012 0.08782014 0.10123608 0.08782012 0.1865388\n",
      " 0.08782012 0.08789738 0.08782021 0.08782012]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00628352]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.07383276, shape=(), dtype=float32)\n",
      "Input sequence: [[  23  115   57  201   15 2380  309  176  180   73  292  176  685  909\n",
      "    71  160  240   15  340   89  248   18    2  256   42  222  223  115\n",
      "    57  248    7  686  115   57 1243  656  115   57    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01072978]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.1197266e-01 2.1285451e-10 1.3101456e-07 1.5259159e-01 6.3823848e-09\n",
      " 7.3449612e-01 4.1363690e-09 9.3863736e-04 8.5801128e-07 4.5054474e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09838259 0.08796079 0.08796079 0.10246105 0.08796079 0.18334822\n",
      " 0.08796079 0.08804339 0.08796086 0.08796079]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01072978]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.12705934, shape=(), dtype=float32)\n",
      "Input sequence: [[   9  245 1470 1124  274   58  499  308    3  661 1228    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01741822]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.2616716e-01 1.7839710e-10 1.2437597e-07 1.8906927e-01 6.3313190e-09\n",
      " 6.8391865e-01 3.5104464e-09 8.4403524e-04 6.5238498e-07 4.7351723e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1001735  0.08829968 0.08829969 0.10667701 0.08829968 0.1749771\n",
      " 0.08829968 0.08837424 0.08829974 0.08829969]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01741822]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.20696218, shape=(), dtype=float32)\n",
      "Input sequence: [[  51   33 4193   63  994    1    1 1078  144 6924  390   16  371  421\n",
      "    18 2292  122   10  236   16  184    2  758  197   68  105 1343   90\n",
      "    16 1212  123   95   25   33    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00587589]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0014014e-01 2.2665739e-10 1.3239881e-07 1.4082295e-01 6.3688543e-09\n",
      " 7.5808090e-01 4.4703015e-09 9.5486065e-04 9.4031270e-07 4.1465483e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09702922 0.08778337 0.08778337 0.10105804 0.08778337 0.1873452\n",
      " 0.08778337 0.08786723 0.08778345 0.08778337]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00587589]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.06960088, shape=(), dtype=float32)\n",
      "Input sequence: [[ 131   12   18    3   59  317   19   60   60   96   66 1709    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01000817]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0636223e-01 2.5138794e-10 1.4287873e-07 1.5845554e-01 7.5716606e-09\n",
      " 7.3432153e-01 4.4414818e-09 8.5957127e-04 9.1433884e-07 4.6321396e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09783085 0.08795962 0.08795965 0.10306227 0.08795962 0.1833138\n",
      " 0.08795962 0.08803526 0.08795971 0.08795962]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01000817]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.118036464, shape=(), dtype=float32)\n",
      "Input sequence: [[ 505  170   54  355  935   10    5    4    3  164  289   11  686  112\n",
      "  2034   15    4   30   30  309   10 1248   28 1855  262   20    7   54\n",
      "  1034 1145 8117 2807  136   10  138 1464    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00657998]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0454640e-01 2.8514741e-10 1.5408531e-07 1.6178679e-01 8.4204332e-09\n",
      " 7.3273081e-01 5.1465618e-09 9.3477842e-04 9.6907411e-07 5.2260951e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09766494 0.08797003 0.08797004 0.1034184  0.08797003 0.18304406\n",
      " 0.08797003 0.0880523  0.08797011 0.08797003]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00657998]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.07715371, shape=(), dtype=float32)\n",
      "Input sequence: [[ 282 1209  762 1953   73  180   29  383   67    1  143  193   22   44\n",
      "  3568  458  815    1 1700  815   73  155   24  193   22 8229    3  165\n",
      "    26    7  533 2147    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00513086]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0930999e-01 2.4542482e-10 1.4159596e-07 1.5798797e-01 7.2658848e-09\n",
      " 7.3182380e-01 4.4925135e-09 8.7714719e-04 8.7944971e-07 4.6652353e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09814078 0.08797855 0.08797856 0.10303625 0.08797855 0.18289582\n",
      " 0.08797855 0.08805575 0.08797862 0.08797855]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00513086]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.0605658, shape=(), dtype=float32)\n",
      "Input sequence: [[  21 4620  623  214 3418  310  306  349 5871 1431 5198  887   49 2067\n",
      "   163   68  129  866    8  976 1703   24  109  100   72  408   44    3\n",
      "    61  441 1390   26  649   99 1160 1390    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01079267]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0236914e-01 1.9916901e-10 1.2028269e-07 1.5338187e-01 6.0983130e-09\n",
      " 7.4344242e-01 3.8020374e-09 8.0563867e-04 7.9019628e-07 3.9653674e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09736665 0.08789252 0.08789252 0.10246247 0.08789252 0.18485229\n",
      " 0.08789252 0.08796335 0.08789258 0.08789252]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01079267]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.1285771, shape=(), dtype=float32)\n",
      "Input sequence: [[ 152   88  186  390  294  854 3330  338  302   77  488  171  156 4448\n",
      "  3330  601 1307  876   10   95  984   10  279    1    1  580   22  391\n",
      "     5   10   92   28   30   33  984   10   28   63  101  641  676  247\n",
      "    26   16  390  157   67  247  760 8104   58    5  438  239 1791  649\n",
      "    76  239    5    4    2 1552    9  549    5    9   76 4276   98  320\n",
      "  1154  968 1879  308  101    1    1 1004  345  126  142  122  208   25\n",
      "   147   32 1907   60 1346  241  146  490  596  344   96   30   97  448\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00067802]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[9.9884577e-02 1.0854040e-10 7.7033604e-08 1.4725059e-01 3.5022787e-09\n",
      " 7.5207496e-01 2.4342406e-09 7.8923802e-04 5.3779638e-07 2.7518727e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09705388 0.08782812 0.08782813 0.10176155 0.08782812 0.18631834\n",
      " 0.08782812 0.08789746 0.08782817 0.08782813]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00067802]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.008280411, shape=(), dtype=float32)\n",
      "Input sequence: [[ 498  139   11  131  423 1312  412 2005   19   45   16  565  195  202\n",
      "   748  264   36    5    8   65  786    2  334   24  202    9  134  156\n",
      "    30  600 1340  704   10    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00329406]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0044921e-01 1.9238408e-10 1.1368672e-07 1.3734519e-01 5.3882867e-09\n",
      " 7.6147795e-01 3.2859122e-09 7.2673860e-04 7.8846904e-07 2.9888582e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09703044 0.08775734 0.08775735 0.10067734 0.08775734 0.18792698\n",
      " 0.08775734 0.08782115 0.08775741 0.08775735]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00329406]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.03954937, shape=(), dtype=float32)\n",
      "Input sequence: [[1590  810  296  127 1869 1172   56 4796  328  152  148  254  251  257\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00983302]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0280084e-01 4.9084115e-10 2.0877916e-07 1.5405634e-01 1.2466221e-08\n",
      " 7.4209708e-01 7.7123774e-09 1.0440991e-03 1.3291552e-06 6.6650330e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09742004 0.08790275 0.08790277 0.10254353 0.08790275 0.18462525\n",
      " 0.08790275 0.08799458 0.08790286 0.08790275]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00983302]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.11304261, shape=(), dtype=float32)\n",
      "Input sequence: [[ 176   94   21   11   11  575 1683 1995 1265  429  241 1245 2014  722\n",
      "   446    1    2    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00907746]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0645177e-01 2.1082844e-10 1.2282203e-07 1.3937896e-01 6.0635790e-09\n",
      " 7.5331175e-01 3.9691810e-09 8.5639575e-04 8.1994466e-07 3.9570807e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09768572 0.08782127 0.08782127 0.10095578 0.08782127 0.18653435\n",
      " 0.08782127 0.08789651 0.08782133 0.08782127]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00907746]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.10800661, shape=(), dtype=float32)\n",
      "Input sequence: [[  13 2998    6  253   88    4   18    3   82  336   77  248   80  247\n",
      "  5768 1770  992    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00567878]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0642812e-01 1.4129226e-10 9.1786220e-08 1.4378878e-01 4.2628314e-09\n",
      " 7.4902564e-01 2.7771332e-09 7.5676176e-04 6.1334396e-07 3.0240187e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09771886 0.08785313 0.08785314 0.10143875 0.08785313 0.18580393\n",
      " 0.08785313 0.08791964 0.08785319 0.08785313]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00567878]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.068756364, shape=(), dtype=float32)\n",
      "Input sequence: [[ 325  846  360 2402 1281  171   51   15  180 1475   90   55  189   17\n",
      "   180   37  140    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00381808]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[9.7320378e-02 1.4345859e-10 9.2309151e-08 1.5009257e-01 4.5226871e-09\n",
      " 7.5189209e-01 2.8040363e-09 6.9424772e-04 6.2325290e-07 2.9386960e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09680547 0.08782824 0.08782825 0.1020513  0.08782824 0.18628451\n",
      " 0.08782824 0.08788924 0.0878283  0.08782825]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00381808]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.046254642, shape=(), dtype=float32)\n",
      "Input sequence: [[   8  235  238 1825    4   22   28   33   18   81 1028    4   98    7\n",
      "    42   98  172  120    4    3  154  148   27    8   24    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0018151]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[9.94194597e-02 1.93956212e-10 1.10145045e-07 1.70325324e-01\n",
      " 6.13776896e-09 7.29487419e-01 3.50928930e-09 7.66956073e-04\n",
      " 6.63255662e-07 3.87128054e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09718689 0.0879894  0.0879894  0.10432819 0.0879894  0.18249151\n",
      " 0.0879894  0.08805691 0.08798945 0.0879894 ]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0018151]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.021709267, shape=(), dtype=float32)\n",
      "Input sequence: [[  218    12    64    43   430  1180   196   442  2068   771     5   492\n",
      "  10522   502    82   492  1436   363   169    44   321     2    12   671\n",
      "    444  1176    72  4828   101     1     1   291  1842   119  1947  2661\n",
      "   1542    95   119   550  2075  1042  2445    12 10523    67   430  1542\n",
      "    236    16  3740  1056  1802    75   379    12  1634   762   305  1620\n",
      "      7    46  3362  1542  1947    67     5    46  3362   687   236    13\n",
      "   1802   258    55   188    12   379  1634     1     1  1003   196   442\n",
      "    140   492  2068   771     4     1     1  1001   244 10524   116   236\n",
      "     67     1     1   414]]\n",
      "Value estimates: tf.Tensor([[0.00131534]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[0.01504501 0.00449345 0.12656932 0.01169476 0.24876139 0.03808961\n",
      " 0.2645487  0.03828946 0.02410883 0.22839956], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09136949 0.09041046 0.10214936 0.09106389 0.11542581 0.09349951\n",
      " 0.11726253 0.0935182  0.09220141 0.1130993 ]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00131534]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.004019339, shape=(), dtype=float32)\n",
      "Input sequence: [[ 330  744    6   34  134  100    3   83   63  249  475  359   87   28\n",
      "   396 2626   87   34  249  396 2626   87  521  475  359  475  865   61\n",
      "   133  599  475  359  400 3069   63   87    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00164946]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[9.2076272e-02 2.1759412e-10 1.1430720e-07 1.5106998e-01 6.3541949e-09\n",
      " 7.5607204e-01 3.8838417e-09 7.8083813e-04 7.8118745e-07 3.7989647e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09626242 0.08779474 0.08779477 0.10211214 0.08779474 0.18699348\n",
      " 0.08779474 0.08786333 0.08779482 0.08779475]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00164946]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.01968057, shape=(), dtype=float32)\n",
      "Input sequence: [[ 103 7231 1776   83 7232  253   88   14 2599  133   20   90   55  182\n",
      "   714   48   95   17  994  140  326   14  270   85 7233  169 1463 2021\n",
      "  7234   23  632   39    2   26  415 5302 1646  144  755 4307  393 3494\n",
      "  1074   51  194   79  345    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00065107]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[9.8686352e-02 1.1927656e-10 7.9263351e-08 1.4682601e-01 3.7761279e-09\n",
      " 7.5382864e-01 2.3256814e-09 6.5841305e-04 5.2823566e-07 2.5322446e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09692251 0.08781441 0.08781441 0.10170247 0.08781441 0.18661621\n",
      " 0.08781441 0.08787225 0.08781445 0.08781441]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00065107]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.007960485, shape=(), dtype=float32)\n",
      "Input sequence: [[ 191   10 1113 3566  134 6974   19   10  351 1592    5    8 1261  302\n",
      "     4  249   10  113    8  783  113   77    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0063407]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[9.6837111e-02 7.9398946e-11 6.2370745e-08 1.4056781e-01 2.5130737e-09\n",
      " 7.6203382e-01 1.6699285e-09 5.6069402e-04 4.4030887e-07 1.8200394e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.0966743  0.08775164 0.08775164 0.10099574 0.08775164 0.18801925\n",
      " 0.08775164 0.08780085 0.08775169 0.08775164]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0063407]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.078820005, shape=(), dtype=float32)\n",
      "Input sequence: [[ 102  688  117  285 2955 2256  302  609 8392  450 1927  628  526   40\n",
      "    44  117 1243   40  349  340   89 3140    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00695481]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0112204e-01 1.2701389e-10 8.4651752e-08 1.6335599e-01 4.3029944e-09\n",
      " 7.3489070e-01 2.4477211e-09 6.3069077e-04 5.1526581e-07 2.8719136e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09731185 0.08795266 0.08795267 0.10356037 0.08795266 0.18340364\n",
      " 0.08795266 0.08800815 0.08795271 0.08795267]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00695481]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.08465277, shape=(), dtype=float32)\n",
      "Input sequence: [[  18    8   77 4698 3396 1924  274  120  893   53 2131  754  697  203\n",
      "  2099   31    3  737    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00446459]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.1758197e-01 7.5620885e-11 6.4211889e-08 1.8555345e-01 2.8685456e-09\n",
      " 6.9631302e-01 1.6271353e-09 5.5123511e-04 3.4032291e-07 2.3088630e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09922532 0.08821802 0.08821803 0.10620431 0.08821802 0.1769955\n",
      " 0.08821802 0.08826666 0.08821806 0.08821803]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00446459]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.055314187, shape=(), dtype=float32)\n",
      "Input sequence: [[ 146    8  199    6   37   26 1827 1342  778  799   25   26    7   65\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00082378]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0184772e-01 2.1513394e-10 1.1983656e-07 1.5170898e-01 6.4523569e-09\n",
      " 7.4569088e-01 3.7664414e-09 7.5149175e-04 7.4389800e-07 3.8747533e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09729748 0.08787587 0.08787589 0.10227183 0.08787587 0.18523332\n",
      " 0.08787587 0.08794194 0.08787595 0.08787588]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.6666666622222223\n",
      "Returns: [0.66666666]\n",
      "Advantages: tf.Tensor([[0.6674905]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(8.407862, shape=(), dtype=float32)\n",
      "Input sequence: [[    1   571   223   828  2014   254     6    18  1804    91   201 10382\n",
      "    203  1454     1     1    15   409   104  1157     1     1    63   128\n",
      "    201   409  1164  1804    15   345    19    26  1469    99   219     1\n",
      "      1    80   177   201   560   160   769   560   201    23  1603   275\n",
      "    114   227    23  1233   227    34 10383   227    15    43    19    41\n",
      "     40    23   283    23   283  1070    80     2   181   283    69  1448\n",
      "    135  1008    41   471  2418   173  2317   598  1299    90    79    43\n",
      "      1     1    31   160  2195  1352 10384   201   560  4780    29     1\n",
      "      1  6268  1141  1173]]\n",
      "Value estimates: tf.Tensor([[0.00403022]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[0.01417251 0.00357967 0.13196608 0.01154175 0.2415575  0.04665123\n",
      " 0.2724428  0.03472677 0.02157613 0.22178553], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09129256 0.09033062 0.1027052  0.0910527  0.11460073 0.0943063\n",
      " 0.11819544 0.09318842 0.09197097 0.11235711]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00403022]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.012422813, shape=(), dtype=float32)\n",
      "Input sequence: [[ 175 1016  615  107  294  392  867 3804 1066 7942 1457    9  213 3328\n",
      "  3805   67    9   24   13  153   56  225  965   98  113  109   21    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00304972]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.0407173e-01 1.7428854e-10 1.1262121e-07 1.3821794e-01 4.8924576e-09\n",
      " 7.5689352e-01 3.5036711e-09 8.1584725e-04 8.0631992e-07 3.3876283e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09742267 0.08779349 0.0877935  0.10080674 0.08779349 0.18714446\n",
      " 0.08779349 0.08786515 0.08779357 0.08779349]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00304972]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.036568243, shape=(), dtype=float32)\n",
      "Input sequence: [[  9 803  45  19  73 199 549 143  42 360   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.01280701]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.2188692e-01 2.4312716e-10 1.4516174e-07 2.0504950e-01 8.3772793e-09\n",
      " 6.7216223e-01 4.4202872e-09 9.0037927e-04 7.5384685e-07 5.8181907e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09982046 0.08836592 0.08836593 0.10847675 0.08836592 0.17306176\n",
      " 0.08836592 0.08844551 0.08836598 0.08836592]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01280701]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.15041377, shape=(), dtype=float32)\n",
      "Input sequence: [[  22   92  501    2  914    2    1 3978    6    1   45  517 8750  219\n",
      "    48  263  274 1423    1 2915   49 1022  214 1394  136    1  716 1097\n",
      "   384 3674    1  240    1  221   70   53   40   58  304    1  310 3479\n",
      "   163  120  914   78    1   26    1   72   36  228 1123    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00406844]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[9.9008359e-02 2.0040219e-10 1.3058037e-07 1.3319054e-01 5.3857705e-09\n",
      " 7.6702607e-01 3.6991683e-09 7.7381928e-04 1.0303268e-06 3.0930309e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09684303 0.08771414 0.08771414 0.10021057 0.08771414 0.18887947\n",
      " 0.08771414 0.08778204 0.08771423 0.08771414]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00406844]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.048589855, shape=(), dtype=float32)\n",
      "Input sequence: [[ 3952   334    62   292  1033   292   534   292  1555  3952    44    70\n",
      "     89   560    29   111   160   773   115    57    29    50  1155   209\n",
      "   1524   276   300  4779    17     3  4480   410    86   912  1210     2\n",
      "   1041  1210  2558  1634   389  2058  2316    50    15  1438  3103   743\n",
      "   1253   348    72    91   842  3952   292    24    49   223   820   499\n",
      "    176   909   648   123  2004    82   407   942    23  6171 10345  2004\n",
      "    295   201    29    44  1141  1173   185   448  1141  1173   167   990\n",
      "     29  1557  3886    70   309     3   201    29   429   241    15  1005\n",
      "     15   123    92   377]]\n",
      "Value estimates: tf.Tensor([[0.00657021]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[0.0062171  0.00176835 0.11062312 0.00590083 0.2534597  0.02163264\n",
      " 0.33816758 0.02288184 0.01131746 0.22803143], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09037292 0.08997176 0.10031855 0.09034434 0.11572158 0.09177686\n",
      " 0.12595126 0.09189157 0.09083502 0.11281608]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00657021]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.022807932, shape=(), dtype=float32)\n",
      "Input sequence: [[   9  617 1187  353    4   30  225   28  265  192   86   42    7  268\n",
      "  7449   70    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01458765]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4246234e-01 1.9556697e-10 1.4039161e-07 1.9666778e-01 6.9245201e-09\n",
      " 6.5984708e-01 3.9843662e-09 1.0218483e-03 7.3620021e-07 5.7127131e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10199124 0.08844885 0.08844887 0.1076723  0.08844885 0.17110401\n",
      " 0.08844885 0.08853928 0.08844893 0.08844886]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01458765]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.17183335, shape=(), dtype=float32)\n",
      "Input sequence: [[   9    9    9  338   26  129 1782 2361   85  609 8041 1721  189    2\n",
      "   349   77    8 1261 1161  368  429   95  377    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.02239462]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5919636e-01 2.7177913e-10 1.8290632e-07 1.9480588e-01 9.1618926e-09\n",
      " 6.4487565e-01 5.1130749e-09 1.1209321e-03 9.2140118e-07 7.2930590e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10381748 0.08853853 0.08853856 0.10758097 0.08853853 0.16873233\n",
      " 0.08853853 0.08863784 0.08853862 0.08853855]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.02239462]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.25967202, shape=(), dtype=float32)\n",
      "Input sequence: [[   49    25   135   289    11    41   789  1196  1134    50   789  1587\n",
      "    275   965   441   211  2522  2945   383    46   319    50    32    18\n",
      "    495   276  3328 10931     2    17  1092     2  5995    74   192    33\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.01055291]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3850138e-01 4.6050122e-10 2.5034095e-07 1.7761639e-01 1.3549562e-08\n",
      " 6.8249595e-01 8.3097715e-09 1.3844697e-03 1.4479155e-06 9.7467201e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1014342  0.08831491 0.08831494 0.10548042 0.08831491 0.17475848\n",
      " 0.08831491 0.08843726 0.08831504 0.08831491]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01055291]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.11985459, shape=(), dtype=float32)\n",
      "Input sequence: [[ 194  511 1065  129  338    2  372   21   86 7649  809  182    2 7650\n",
      "   168    3  836  129  109  338  315   50    9    2  600    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01249564]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4069076e-01 4.3847689e-10 2.4109221e-07 1.8420476e-01 1.2999643e-08\n",
      " 6.7375445e-01 7.9416127e-09 1.3483572e-03 1.3576985e-06 8.8475161e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10171803 0.08836835 0.08836837 0.1062419  0.08836835 0.1733423\n",
      " 0.08836835 0.08848758 0.08836847 0.08836836]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01249564]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.14229693, shape=(), dtype=float32)\n",
      "Input sequence: [[1150 2922 1084  693  411   29 1269 1622    6   63  693  139  360  411\n",
      "     2 1622  115   57    8    6   45  432  369  309    3 2095  934  706\n",
      "   340   15    2  369    6  133 1314  439  455   15   82  679  894  786\n",
      "   213   66   47 9698  160  573  317  577   24   78  127  455  273  508\n",
      "   629   17   26   37   15  109  411    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00895925]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.26813680e-01 5.86889148e-10 2.85125878e-07 1.57422617e-01\n",
      " 1.54429074e-08 7.14268744e-01 1.01413145e-08 1.49270752e-03\n",
      " 1.90483797e-06 9.39796223e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10001913 0.08810662 0.08810665 0.10312794 0.08810662 0.17997473\n",
      " 0.08810662 0.08823825 0.08810679 0.08810664]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00895925]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.10100526, shape=(), dtype=float32)\n",
      "Input sequence: [[  48  111 3436 1457  555  794   21   11   72  105  821 1532  149  186\n",
      "   219  142   21   11   13  247  523  308  522   50  194   33   21   11\n",
      "    94  921 4607  821    1 2363   16  111   33 2095  996   32    7  469\n",
      "    55  131  112  744  165    2  154 1896    9   72  763  821  631 1641\n",
      "   107   40 1737  165    2   33   27    6  149   88   94   86 3362   20\n",
      "   272   32  429  241   17 1328  575   98 1067  939  138   86  551    1\n",
      "   414  833  590  148    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01186648]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.30982563e-01 3.47031431e-10 2.19612545e-07 1.72663331e-01\n",
      " 1.10694405e-08 6.95021451e-01 7.33615657e-09 1.33094587e-03\n",
      " 1.39386646e-06 8.32479614e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10058216 0.088234   0.08823402 0.10486309 0.088234   0.17679906\n",
      " 0.088234   0.08835152 0.08823412 0.08823401]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01186648]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.13599402, shape=(), dtype=float32)\n",
      "Input sequence: [[ 10 302   1   2 391 113  16   1 778 147 466 302  10   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.01527942]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4755909e-01 4.9274212e-10 2.8214788e-07 1.9853631e-01 1.5162026e-08\n",
      " 6.5253752e-01 8.8522505e-09 1.3652092e-03 1.4997836e-06 1.0463864e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10256296 0.08849249 0.08849251 0.10792688 0.08849249 0.16994166\n",
      " 0.08849249 0.08861338 0.08849262 0.0884925 ]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01527942]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.17256992, shape=(), dtype=float32)\n",
      "Input sequence: [[  873  1463   667   909  1151   363   254  1055  1777  3029   783   815\n",
      "   1426   143  1792    48   263   803  1406   667   909    36    42   104\n",
      "    918    11    18 10329   731   369   201  1463  3679   909   182   566\n",
      "     45    19  2396   179    29    89    23   303  1076   402  3580   408\n",
      "    165   369     6    51    37  1740   908   322   924   429   241  1151\n",
      "    369   762     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.00996584]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3246985e-01 6.0070532e-10 3.0031833e-07 1.6922951e-01 1.6586869e-08\n",
      " 6.9672459e-01 1.0764067e-08 1.5736456e-03 1.9330216e-06 1.0757834e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10072047 0.08822402 0.08822405 0.10449181 0.08822402 0.1770804\n",
      " 0.08822402 0.08836297 0.08822419 0.08822404]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00996584]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.11184512, shape=(), dtype=float32)\n",
      "Input sequence: [[   9  462    4    3    3 7389   86   31  462  135  772   33 1503    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01250519]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6409656e-01 1.2450835e-09 5.3200347e-07 2.3402098e-01 3.6162231e-08\n",
      " 6.0015041e-01 1.8741190e-08 1.7288576e-03 2.3373377e-06 2.2620003e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10459037 0.08876166 0.0887617  0.11216553 0.08876166 0.16175862\n",
      " 0.08876166 0.08891526 0.08876187 0.08876167]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01250519]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.13524652, shape=(), dtype=float32)\n",
      "Input sequence: [[ 920 2280  464  431  266 9444   43   43 1451  431   50 3044 4658  252\n",
      "    23   90  182  905 9445  160   22  198  431  117   92   44    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01025563]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3930877e-01 9.1826563e-10 4.0974413e-07 1.6537645e-01 2.3411204e-08\n",
      " 6.9361985e-01 1.4908682e-08 1.6918316e-03 2.5553945e-06 1.3147040e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10143693 0.088246   0.08824604 0.10411591 0.088246   0.17657544\n",
      " 0.088246   0.08839542 0.08824623 0.08824601]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01025563]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.11306343, shape=(), dtype=float32)\n",
      "Input sequence: [[ 179    1    1  233   29   28   32  978    1    1  136   15    8  457\n",
      "  1239    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00807069]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4133084e-01 5.9167637e-10 3.2361930e-07 1.8909325e-01 1.7564423e-08\n",
      " 6.6802478e-01 1.1363264e-08 1.5488634e-03 1.8766420e-06 1.2407128e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10182253 0.08840253 0.08840256 0.10680384 0.08840253 0.17241864\n",
      " 0.08840253 0.08853956 0.0884027  0.08840254]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00807069]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.09026715, shape=(), dtype=float32)\n",
      "Input sequence: [[  10    8  235  191  461  235  147   10  116   31 4168   58    5  146\n",
      "   346 2872  467    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0100048]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5113643e-01 1.1161755e-09 4.8252116e-07 2.2373593e-01 3.2347440e-08\n",
      " 6.2345362e-01 1.6834175e-08 1.6710047e-03 2.3569312e-06 1.8781788e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10310809 0.08864516 0.0886452  0.11087211 0.08864517 0.16535507\n",
      " 0.08864516 0.08879341 0.08864538 0.08864517]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0100048]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.108955994, shape=(), dtype=float32)\n",
      "Input sequence: [[ 159   38  745 6167   54 1939   54 9541 9542   44   68 1265  183 9543\n",
      "  1761 4707  944    1    1    9   38  745  813  213 1040  214    1    1\n",
      "    49 1177  944   12   14  356  182   48  718  305    1    1  254    2\n",
      "    14  745 1056 2395   12    1    1  787  158    7 1177   24  826   71\n",
      "     5   12   14   38  745 4230  870 1728    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01330391]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.46567091e-01 8.15213175e-10 3.87576108e-07 1.77623942e-01\n",
      " 2.17511822e-08 6.74128830e-01 1.35068525e-08 1.67721463e-03\n",
      " 2.31949002e-06 1.39607536e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10231784 0.08836862 0.08836865 0.10554537 0.08836863 0.17340776\n",
      " 0.08836862 0.08851697 0.08836883 0.08836865]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01330391]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.14702612, shape=(), dtype=float32)\n",
      "Input sequence: [[  67  335 2219   86   52  100    3   54    1    1  586  338    5  302\n",
      "     1    1  120   82  338 1528   77   86   53  478  375  748   15  123\n",
      "  1424   16   55    1    1   18    3  899  956  105    1    1 7982 7983\n",
      "   203   86 1363  164  111   16 3189 3581   86  321  587  974  348  136\n",
      "    16   17  478 7984 3189 3581    9  121   20  535   84    1    1 1126\n",
      "    72   36 3593   86   53  478   34 1019   84  992  120   40 1353    1\n",
      "     1  428  284   83  154   84 3333 4512    1    1   99 4177  107   65\n",
      "   375   77]]\n",
      "Value estimates: tf.Tensor([[0.00501727]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[7.1344090e-05 1.1995359e-04 3.3659574e-02 8.1893195e-05 2.1527159e-01\n",
      " 5.5219396e-04 5.4420489e-01 9.7953004e-04 5.4139993e-04 2.0451757e-01], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.08907776 0.08908208 0.09212053 0.08907869 0.11046623 0.08912059\n",
      " 0.15349118 0.08915868 0.08911963 0.10928463]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00501727]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.02860376, shape=(), dtype=float32)\n",
      "Input sequence: [[ 350   47  408  230  367  358  117 5974  272   42  198  374 2098   42\n",
      "   181  231 1306   25  117  209  248   17  659  596  248  209    1    1\n",
      "   238   55   79  172 1641  127 1746 1816 1833  111  543 1052   18   40\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00038335]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.1938271e-01 1.0177208e-09 4.2448610e-07 1.7635968e-01 2.5015382e-08\n",
      " 7.0261538e-01 1.6629768e-08 1.6387631e-03 2.8486656e-06 1.3020995e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09936221 0.08818079 0.08818083 0.10518796 0.0881808  0.17803933\n",
      " 0.08818079 0.08832542 0.08818104 0.0881808 ]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00038335]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.0042186584, shape=(), dtype=float32)\n",
      "Input sequence: [[  45   52   28  223   73  369  201  143  517   73  121  978  215  160\n",
      "    28 1141 1173  369  990  199  243 1045   26  273   36  369  201 2337\n",
      "   313  402   46   34  778 1107 1949 1743  339  114    6   56  215 1418\n",
      "    73   29  628  152    8  369   73  184 1278  369  201  188  484    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00517252]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4271985e-01 5.5513305e-10 3.1546827e-07 2.1151404e-01 1.7691127e-08\n",
      " 6.4432484e-01 1.0348590e-08 1.4390704e-03 1.7040593e-06 1.2139765e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10211569 0.08853398 0.08853401 0.10938794 0.08853398 0.16863075\n",
      " 0.08853398 0.08866149 0.08853415 0.088534  ]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00517252]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.05806656, shape=(), dtype=float32)\n",
      "Input sequence: [[5980  374   44 8836 4624 5980 8837 5412 8838 1498   63    9 1255   11\n",
      "  1773 1144  846  119  374 2544    4   30  374  501   75    7   58   11\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00695062]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3763162e-01 1.3796750e-09 5.3738694e-07 1.8164879e-01 3.3567279e-08\n",
      " 6.7870635e-01 2.1873245e-08 2.0093042e-03 3.2276996e-06 1.9191094e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10137315 0.08833855 0.0883386  0.10593496 0.08833855 0.17414406\n",
      " 0.08833855 0.08851623 0.08833882 0.08833856]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00695062]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.075172, shape=(), dtype=float32)\n",
      "Input sequence: [[   3    3  704  187   39   33  452  453 2368    2    4  334    7   30\n",
      "   479    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00319599]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5858655e-01 1.4311475e-09 5.6937296e-07 1.7380175e-01 3.5210626e-08\n",
      " 6.6532886e-01 2.3356760e-08 2.2787687e-03 3.2929829e-06 2.2825030e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10362048 0.08842445 0.0884245  0.10520916 0.08842445 0.17199707\n",
      " 0.08842445 0.08862619 0.08842474 0.08842447]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00319599]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.034359835, shape=(), dtype=float32)\n",
      "Input sequence: [[   2  339  152  107    8  218   77   86   53  478  640  391  195  398\n",
      "  4452  149 1325  230  367 1413 1826 1828  128  171  156   20   30  215\n",
      "    31  118   77  607    6   89 1134   31  168  144    9 1590  391   40\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.01354579]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3999020e-01 3.9236039e-10 2.4746748e-07 1.5978253e-01 1.1208633e-08\n",
      " 6.9897312e-01 7.4255997e-09 1.2520644e-03 1.7101135e-06 7.1544257e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10146578 0.08821097 0.08821099 0.10349402 0.08821097 0.17745276\n",
      " 0.08821097 0.08832148 0.08821112 0.08821097]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.01354579]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.1552406, shape=(), dtype=float32)\n",
      "Input sequence: [[ 22 218 415 227  28 227 766   4   7 398  51  16 378 223  65   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.00949322]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3076490e-01 1.0192849e-09 4.7073536e-07 1.6375054e-01 2.4372744e-08\n",
      " 7.0405370e-01 1.5461675e-08 1.4271016e-03 3.1501925e-06 1.1261505e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10049391 0.08817577 0.08817581 0.10386405 0.08817577 0.17828543\n",
      " 0.08817577 0.08830169 0.08817604 0.08817577]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00949322]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.104527034, shape=(), dtype=float32)\n",
      "Input sequence: [[  87 2169 7106 1703   99  536 1449 2906   49   25  178   41 1432   46\n",
      "    17  104  378   16  131    3  235   50    8  235    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00827285]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4704873e-01 9.9133368e-10 4.4627870e-07 1.9807318e-01 2.7599189e-08\n",
      " 6.5308225e-01 1.6880284e-08 1.7926573e-03 2.5325110e-06 1.8017452e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10250773 0.08848999 0.08849004 0.10787387 0.08848999 0.17002946\n",
      " 0.08848999 0.08864877 0.08849022 0.08849001]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00827285]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.09053932, shape=(), dtype=float32)\n",
      "Input sequence: [[ 3131    52   388    57    61    52   628     1    24    75   544     7\n",
      "   1487   544   388    11   894     2   793  3438   928   544   122   186\n",
      "   2362   171  1096     1   162   136   233   122   561  2645   828   560\n",
      "  10701   360     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[-0.00581622]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4056148e-01 1.0491683e-09 4.4668843e-07 1.7598610e-01 2.6467369e-08\n",
      " 6.8144023e-01 1.7853603e-08 2.0088132e-03 2.7015737e-06 1.5466995e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1016527  0.088323   0.08832305 0.10531825 0.088323   0.17459008\n",
      " 0.088323   0.0885006  0.08832324 0.08832303]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00581622]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.06365283, shape=(), dtype=float32)\n",
      "Input sequence: [[   6    3  679  281 1893 2550  576    3    4 1284    3   38 1495    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00038175]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5804398e-01 3.2059668e-09 9.3638624e-07 2.0106122e-01 7.2554315e-08\n",
      " 6.3838345e-01 4.1444736e-08 2.5050249e-03 4.9097721e-06 3.7540036e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10374077 0.08857514 0.08857523 0.10830081 0.08857515 0.16770974\n",
      " 0.08857515 0.08879731 0.08857558 0.08857518]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00038175]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.003962059, shape=(), dtype=float32)\n",
      "Input sequence: [[  51 1208 1662  468 1277 1008   41  671 1551  649  143  321    2   30\n",
      "  1901  372   66 1940 1352 1208 1219 4317    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00419814]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4872251e-01 1.0338287e-09 4.5972598e-07 1.6933261e-01 2.5995520e-08\n",
      " 6.8000931e-01 1.7506309e-08 1.9321587e-03 2.8545187e-06 1.5831833e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10249818 0.08833377 0.08833382 0.1046326  0.08833377 0.17436169\n",
      " 0.08833377 0.08850461 0.08833402 0.08833379]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00419814]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.045889124, shape=(), dtype=float32)\n",
      "Input sequence: [[   9  329  299  109  329  113 3138  329   97   71    5   59   16    8\n",
      "   155  377   59 2394    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00345647]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6804105e-01 9.5545472e-10 4.4926253e-07 2.4185960e-01 3.1028041e-08\n",
      " 5.8844823e-01 1.5325142e-08 1.6484766e-03 2.0688990e-06 1.9443506e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10506603 0.08881433 0.08881437 0.1131153  0.08881433 0.15997158\n",
      " 0.08881433 0.08896086 0.08881451 0.08881434]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00345647]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.037808217, shape=(), dtype=float32)\n",
      "Input sequence: [[  95  395  166    3 2487  793    3  177 2487  736  920   23   15    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00980315]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4107123e-01 1.6976106e-09 6.2609848e-07 1.8594110e-01 3.8372093e-08\n",
      " 6.7109299e-01 2.3675602e-08 1.8901149e-03 3.7245145e-06 1.9024436e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.101776   0.08838507 0.08838513 0.10644667 0.08838508 0.17291428\n",
      " 0.08838508 0.08855229 0.0883854  0.08838508]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00980315]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.10518861, shape=(), dtype=float32)\n",
      "Input sequence: [[ 580   45  311   79   48 1406  803  993    7 4167   54   72   82  516\n",
      "     2  177   54  599  100   71  185  573    6  311 4329 5283  267  226\n",
      "     2  177  311 2571  295  836  205 1421    2 1029  311   74    8  809\n",
      "   833  620  177  311    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00461782]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4587948e-01 7.3102074e-10 3.7479501e-07 1.8524070e-01 2.0011793e-08\n",
      " 6.6731346e-01 1.2392918e-08 1.5636191e-03 2.2510017e-06 1.2736348e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10229367 0.08840852 0.08840855 0.10640036 0.08840852 0.17230769\n",
      " 0.08840852 0.08854686 0.08840872 0.08840853]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00461782]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.051336005, shape=(), dtype=float32)\n",
      "Input sequence: [[  10    3   46  587  122  182    1    1  372  279  183  222   59   16\n",
      "    26  116  236  123  101   15   69   10   16 1920  168  101 1527  348\n",
      "   236   20  687    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.01735149]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5612291e-01 8.4628821e-10 4.1538183e-07 2.2554114e-01 2.7206266e-08\n",
      " 6.1668777e-01 1.4653546e-08 1.6453658e-03 2.2038253e-06 1.7268873e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10366516 0.08868077 0.08868082 0.11111707 0.08868077 0.16430606\n",
      " 0.08868077 0.08882681 0.08868098 0.0886808 ]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.01735149]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.19095801, shape=(), dtype=float32)\n",
      "Input sequence: [[131   3  10  70 513 377 259 513   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.00913502]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6144226e-01 9.8358410e-10 4.6988794e-07 1.9733666e-01 2.9027845e-08\n",
      " 6.3935375e-01 1.7848539e-08 1.8637616e-03 2.8474622e-06 1.8903366e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10408807 0.08857016 0.08857021 0.1078921  0.08857016 0.1678631\n",
      " 0.08857016 0.08873539 0.08857042 0.08857019]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00913502]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.099430054, shape=(), dtype=float32)\n",
      "Input sequence: [[4014  307 3617  964  363  307  507  299  158  453   16    8  399 1119\n",
      "   220 4014    9   11  103  184  721  122  382   98  939   86   53  478\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00591025]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5036339e-01 1.7738316e-09 6.5196622e-07 1.8500993e-01 4.3451578e-08\n",
      " 6.6243732e-01 2.7005186e-08 2.1845393e-03 3.8975427e-06 2.3977177e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10278914 0.08843929 0.08843935 0.10641284 0.08843929 0.17152922\n",
      " 0.08843929 0.0886327  0.08843963 0.0884393 ]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00591025]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.06303302, shape=(), dtype=float32)\n",
      "Input sequence: [[   6  316 3248  518  292  648 1000   15  323    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00846213]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5754539e-01 2.5354530e-09 8.3610007e-07 2.1048535e-01 6.5214195e-08\n",
      " 6.2931556e-01 3.9986638e-08 2.6477149e-03 4.6622804e-06 3.7349085e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10374378 0.08862189 0.08862196 0.10938396 0.0886219  0.16628353\n",
      " 0.0886219  0.08885684 0.08862229 0.08862192]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00846213]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.08814414, shape=(), dtype=float32)\n",
      "Input sequence: [[  26 1089   25  232   95   68  162   17  315  232   82 1125  329   89\n",
      "     8    4 1394  727  232  315    6    2  245  984  230  109    8    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00332034]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.40654936e-01 6.24737151e-10 3.31818654e-07 1.74792662e-01\n",
      " 1.94815435e-08 6.82805777e-01 1.33625155e-08 1.74362282e-03\n",
      " 2.54830297e-06 1.20274677e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10165214 0.08831427 0.08831431 0.10518223 0.08831427 0.17481136\n",
      " 0.08831427 0.08846839 0.0883145  0.08831428]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00332034]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.036949657, shape=(), dtype=float32)\n",
      "Input sequence: [[ 235   32  806   57  146   34  249  770 5490   15   75  837    2    7\n",
      "    58 4046 2177  304 1229  471  923 1202 1335 2407 1025   35  958   75\n",
      "    41 4357  504   33    8  137   25    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00589201]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5088823e-01 8.6975732e-10 4.0772812e-07 1.9012566e-01 2.6720972e-08\n",
      " 6.5711534e-01 1.6239081e-08 1.8674245e-03 2.8397408e-06 1.5553070e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10287797 0.08846927 0.0884693  0.10699488 0.08846927 0.17067662\n",
      " 0.08846927 0.08863463 0.08846952 0.08846929]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00589201]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.06464166, shape=(), dtype=float32)\n",
      "Input sequence: [[ 102 6269 4798   48  124  424   23  582  497  585  398  307  130  143\n",
      "   561   24  164  344 5920 1216  898  153   56    6  152    8    4   85\n",
      "  1188    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00187144]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7448756e-01 8.2010426e-10 4.1728961e-07 2.2327752e-01 3.1053258e-08\n",
      " 6.0019612e-01 1.7957273e-08 2.0354458e-03 2.6872458e-06 2.1619216e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10569038 0.08876799 0.08876803 0.11097486 0.088768   0.16177757\n",
      " 0.08876799 0.08894886 0.08876824 0.08876802]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00187144]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.020369146, shape=(), dtype=float32)\n",
      "Input sequence: [[1019   27 1548    3   17 1023   37  148   27    1  104 1326    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00093348]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5591912e-01 2.1585500e-09 7.5219543e-07 1.9966088e-01 6.0711628e-08\n",
      " 6.4201093e-01 3.5392382e-08 2.4030530e-03 4.8501674e-06 3.1326101e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10349691 0.08855489 0.08855496 0.10812452 0.0885549  0.16828072\n",
      " 0.0885549  0.08876795 0.08855532 0.08855491]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00093348]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.0097992495, shape=(), dtype=float32)\n",
      "Input sequence: [[ 325  152  177  311  670  219   83  106   33  311   93 1545  311  154\n",
      "  1545   60  513    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01244421]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6503792e-01 1.0638515e-09 4.9522765e-07 2.0007235e-01 3.6597150e-08\n",
      " 6.3288361e-01 2.1123395e-08 2.0019114e-03 3.4742268e-06 2.2032840e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10450478 0.08860559 0.08860563 0.10823093 0.08860559 0.16684721\n",
      " 0.08860559 0.08878314 0.08860589 0.08860561]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01244421]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.13418768, shape=(), dtype=float32)\n",
      "Input sequence: [[1554  111 3846   17    1    3    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0146498]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5524559e-01 4.0572465e-09 1.1532069e-06 2.0678130e-01 9.5425442e-08\n",
      " 6.3495415e-01 6.0600136e-08 3.0104860e-03 6.7259834e-06 4.8053477e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10347133 0.08859266 0.08859277 0.1089436  0.08859267 0.16716865\n",
      " 0.08859266 0.08885977 0.08859326 0.0885927 ]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0146498]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.14911984, shape=(), dtype=float32)\n",
      "Input sequence: [[ 164  344 1084  635    6    9  233   29   23   73   29 1746  139  614\n",
      "   635  614  360 9359 1686 2166   34  130 6132  988  482  214   44 1013\n",
      "  2847   48    9   36  159    1    1  149 1172    6  257  402   37  573\n",
      "    20  150  309  990 4292 1044  156  353  120 5364   35    5  253   13\n",
      "  3170 1321  402  954  829   37    1    1    7  119 4743  190   29 1658\n",
      "   150 3672    1    1   53  136  223  139  360  990  982   26   66   19\n",
      "  1550   26  104  553  990  129 2911   11  190   98    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00324105]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5682948e-01 8.7618840e-10 4.1989875e-07 1.8667457e-01 2.9236922e-08\n",
      " 6.5435916e-01 1.8806983e-08 2.1331287e-03 3.0178958e-06 1.9393299e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10351188 0.08848712 0.08848716 0.10664778 0.08848713 0.17024119\n",
      " 0.08848712 0.08867608 0.08848739 0.08848714]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00324105]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.035320893, shape=(), dtype=float32)\n",
      "Input sequence: [[  51  915  932 3038 2212 3414  638  295  300    9  638  295  254 3038\n",
      "   131   13    3   25    3  782    1    1 3038  638  295  118  432   24\n",
      "   199  190  364    1    1  105   54   52    6  463  609 2589 2362 6199\n",
      "   353  210  112  197    5 2063 1660  120    6 1715  168   74   60    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00560753]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4824633e-01 1.3635471e-09 5.3137006e-07 1.8024300e-01 3.6909444e-08\n",
      " 6.6936922e-01 2.2961919e-08 2.1371301e-03 3.5146631e-06 2.0617891e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10252403 0.08839813 0.08839818 0.10585749 0.08839814 0.172642\n",
      " 0.08839814 0.08858725 0.08839844 0.08839814]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00560753]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.06035622, shape=(), dtype=float32)\n",
      "Input sequence: [[ 177  235 7461 4376  668  125   14  817  371  181   16 1270 1032  170\n",
      "    14   46 1638   30 1311  588    5   64   55  155    2  228  257    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01158332]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6423358e-01 8.0066304e-10 4.0713641e-07 1.9821593e-01 2.6360823e-08\n",
      " 6.3569111e-01 1.5790803e-08 1.8561810e-03 2.6102705e-06 1.7360668e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10440288 0.08859041 0.08859045 0.10801172 0.08859041 0.16728765\n",
      " 0.08859041 0.088755   0.08859064 0.08859044]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01158332]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.12689385, shape=(), dtype=float32)\n",
      "Input sequence: [[ 175  174  152  159   51  159  161    1  436  420  872  185  703  416\n",
      "  1572  185  709    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00649143]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4459498e-01 2.0413626e-09 7.1482299e-07 1.9017491e-01 4.8876736e-08\n",
      " 6.6296905e-01 3.0488717e-08 2.2558609e-03 4.1132403e-06 2.4394731e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10219204 0.0884342  0.08843426 0.10695773 0.08843421 0.17161058\n",
      " 0.08843421 0.08863392 0.08843457 0.08843422]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00649143]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.06878473, shape=(), dtype=float32)\n",
      "Input sequence: [[   8  185   45   92  734  888  186  556  386  300    4  422   12   85\n",
      "  1050   15 1120  120 5772  231   85  261    4   24  853  269 1131    9\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00570247]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5684104e-01 7.1526074e-10 3.7177250e-07 2.0633517e-01 2.2231678e-08\n",
      " 6.3519531e-01 1.3022376e-08 1.6258137e-03 2.1041888e-06 1.5064276e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10363308 0.08858969 0.08858972 0.10889136 0.08858969 0.16720337\n",
      " 0.08858969 0.08873384 0.08858988 0.08858971]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00570247]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.0631748, shape=(), dtype=float32)\n",
      "Input sequence: [[ 189  352  187   64   64    4    8    4 2642  163  599 3027    5  161\n",
      "   552    4  352  187    4 1235   26  449    2   39   66   47 1519   18\n",
      "     4 2062  123  256 1327   64 2628   18  264    2  134  193  189    9\n",
      "   352  187   64    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00052277]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.2633283e-01 6.4398453e-10 3.4083646e-07 1.5360276e-01 1.4819218e-08\n",
      " 7.1880645e-01 1.0198775e-08 1.2549574e-03 2.5086104e-06 7.3495634e-08], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.09993543 0.08807524 0.08807527 0.10269816 0.08807524 0.18072885\n",
      " 0.08807524 0.08818584 0.08807547 0.08807524]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00052277]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.0058943555, shape=(), dtype=float32)\n",
      "Input sequence: [[ 325   58  242   11  126    7   42 1571   42  210  121    4  646  783\n",
      "   290  130 7332  641 1085  168  684  633  752  390  758  715  225  726\n",
      "   486  254    1 1031   83  627  498   26  293  407 7333  362   79  545\n",
      "   242   11  362  242   11 3674  834   22 1823  293  362 2503  600  242\n",
      "    11   34  134    2  203    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00155504]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4317685e-01 5.0954035e-10 2.8883568e-07 1.8599863e-01 1.5207606e-08\n",
      " 6.6927809e-01 9.9771205e-09 1.5442506e-03 1.7895713e-06 1.0934783e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10200313 0.088396   0.08839603 0.10646597 0.088396   0.1726221\n",
      " 0.088396   0.08853261 0.08839616 0.08839601]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00155504]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.017513882, shape=(), dtype=float32)\n",
      "Input sequence: [[1977  131   13 1927   37  462  222   37  462  495  462   27  272  146\n",
      "   156 2237 1321 1217    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00089489]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4407660e-01 1.3801031e-09 5.6522310e-07 1.8535651e-01 3.5056882e-08\n",
      " 6.6864508e-01 2.1912525e-08 1.9175874e-03 3.3685080e-06 1.9471395e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10210032 0.08840064 0.08840069 0.1064032  0.08840065 0.17252192\n",
      " 0.08840065 0.08857032 0.08840094 0.08840066]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00089489]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.009657227, shape=(), dtype=float32)\n",
      "Input sequence: [[  51   12   20  249 4973   94 6590 2413   40  107 1574  542    4    3\n",
      "   161   55  696  188 1317  112 4973 6591  104  192  520   12 1281    6\n",
      "   204    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00668633]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5121160e-01 1.0593462e-09 4.7158557e-07 1.7072845e-01 2.6537712e-08\n",
      " 6.7599481e-01 1.8557323e-08 2.0614904e-03 2.9418472e-06 1.7213098e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10278297 0.088359   0.08835905 0.10480867 0.08835901 0.17371272\n",
      " 0.088359   0.08854134 0.08835927 0.08835901]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00668633]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.07294171, shape=(), dtype=float32)\n",
      "Input sequence: [[  18    8  108  277  798 3366   18  565 2486    3   25   82  771   35\n",
      "     5  720   50 1094   27   30   67   72   36    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00701236]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7390254e-01 5.4072913e-10 3.1977450e-07 2.3565662e-01 1.8800053e-08\n",
      " 5.8903563e-01 9.6063228e-09 1.4032313e-03 1.4608524e-06 1.3300890e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10568472 0.0888152  0.08881523 0.11241691 0.0888152  0.16006714\n",
      " 0.0888152  0.08893991 0.08881533 0.0888152 ]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00701236]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.078563705, shape=(), dtype=float32)\n",
      "Input sequence: [[   1    1  318  205  876  866  973  251   37  793   43  148  229 1036\n",
      "   157 2020  169 1999  481   64 1007   67    3   29  954    1    1 2949\n",
      "    62   14 1685  269   14 1149   62   14 1543   62   14   62  665   14\n",
      "   207  207   14  106  481   12 1986 2990 2992  187  195    1    1   13\n",
      "   787  532  157   67  890  699   27  922   43   86 2592  278  121    3\n",
      "  1331  390 8278   58  148  335    5   37    1    1 3713  251   37   23\n",
      "  1007   13 2041 3126 1239   38  650  142  571  251   37   46  290   49\n",
      "  5766   27]]\n",
      "Value estimates: tf.Tensor([[-0.0051485]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[6.1687974e-06 1.8911407e-05 6.2352703e-03 6.9147909e-06 1.3614039e-01\n",
      " 7.7917772e-05 7.1438187e-01 1.0246669e-04 7.8746518e-05 1.4295140e-01], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.08811414 0.08811527 0.08866473 0.08811421 0.10096432 0.08812047\n",
      " 0.18000934 0.08812263 0.08812054 0.10165434]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.0051485]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.037199665, shape=(), dtype=float32)\n",
      "Input sequence: [[ 674 2059    3  539 3868  466   47    6  321   87   30  268  392  243\n",
      "    36   96  333  284   47  674 2059    3  539 3868  126  321  925   30\n",
      "    74 2746  104 1091 2473  321  691   20 4902  122   26 3024   74    9\n",
      "    42    3    6  123   47 1310   13  299   72  273   47 1288  204    3\n",
      "  1343    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00370627]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4244054e-01 1.3568651e-09 5.2301215e-07 1.8122508e-01 3.3260516e-08\n",
      " 6.7434567e-01 2.0767501e-08 1.9847697e-03 3.1824479e-06 1.8628202e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10189402 0.08836648 0.08836653 0.10592357 0.08836649 0.17344116\n",
      " 0.08836649 0.08854204 0.08836677 0.0883665 ]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00370627]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.04012201, shape=(), dtype=float32)\n",
      "Input sequence: [[ 3707  3960  4596  5742 11008  1657    35   267    92  1930  3960  1463\n",
      "     31  1341   527   131   259    67    13  6356   162    54     2  2332\n",
      "   1349   879  6100   273  1560  1634   831   856 11009     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.00056767]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5289894e-01 9.7015462e-10 4.3252805e-07 1.7298295e-01 2.4846514e-08\n",
      " 6.7221850e-01 1.6318939e-08 1.8963965e-03 2.6431551e-06 1.5329121e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10298324 0.08838192 0.08838195 0.10507248 0.08838192 0.17310284\n",
      " 0.08838192 0.08854967 0.08838215 0.08838193]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00056767]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.006225929, shape=(), dtype=float32)\n",
      "Input sequence: [[ 29 202 143  58   4   2 440 179  73 180   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[0.00576577]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5882598e-01 9.9916375e-10 4.6895991e-07 1.8814738e-01 2.6931474e-08\n",
      " 6.5123117e-01 1.6546176e-08 1.7921116e-03 2.6178393e-06 1.6818117e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10373928 0.08850463 0.08850466 0.1068261  0.08850463 0.16974308\n",
      " 0.08850463 0.08866338 0.08850486 0.08850464]\n",
      "Generated summary: like\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00576577]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.0630207, shape=(), dtype=float32)\n",
      "Input sequence: [[ 195   23  564  275  567  156   18    3  969 4634  564   26  876  869\n",
      "  1504   41   27   60  683    7  104  137  603   19   41  271 1789  395\n",
      "   416  859   17   71  137   32  582  429  241 1245    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00033278]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5791672e-01 7.0887535e-10 3.6680785e-07 2.1512339e-01 2.1994998e-08\n",
      " 6.2547576e-01 1.1835441e-08 1.4817899e-03 1.9067519e-06 1.4351380e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10380247 0.0886391  0.08863913 0.1099138  0.0886391  0.16567844\n",
      " 0.0886391  0.08877053 0.08863926 0.08863911]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00033278]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.003696057, shape=(), dtype=float32)\n",
      "Input sequence: [[   9  196  586  302   77  388  336   22    7   50   84  132   84   16\n",
      "    46 1395   42  688   16   91 1301  156  105    1    1  219    5  820\n",
      "   494   76   58  975 3028  144    5  181    1    1 4467  382  346  336\n",
      "  3589    8  148    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00766649]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.77757293e-01 3.17814886e-10 2.25482879e-07 2.19224587e-01\n",
      " 1.11564695e-08 6.01696193e-01 6.45130571e-09 1.32040866e-03\n",
      " 1.14474176e-06 1.01485874e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10602842 0.08876123 0.08876124 0.11051757 0.08876123 0.16200806\n",
      " 0.08876123 0.0888785  0.08876132 0.08876123]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00766649]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.08784869, shape=(), dtype=float32)\n",
      "Input sequence: [[2574 3357 3446   11  674  489  915 9629 1289  181 3109 9630  427   11\n",
      "    87    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00790428]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4825815e-01 2.0761723e-09 7.1870272e-07 1.8738635e-01 4.7836288e-08\n",
      " 6.6219926e-01 2.9619176e-08 2.1510622e-03 4.0907416e-06 2.4468957e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10257366 0.08843987 0.08843994 0.10666674 0.08843987 0.17148954\n",
      " 0.08843987 0.08863032 0.08844023 0.0884399 ]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00790428]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.083799064, shape=(), dtype=float32)\n",
      "Input sequence: [[ 250   26  246  124 1264   23 1884  365   22 3058 4996    1  207   29\n",
      "   207 6641    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00288244]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5007368e-01 2.5298217e-09 8.2400516e-07 1.9940129e-01 5.6570236e-08\n",
      " 6.4816403e-01 3.6453706e-08 2.3553353e-03 4.4681274e-06 3.0310446e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10285223 0.08851922 0.08851929 0.10805291 0.08851922 0.16925114\n",
      " 0.08851922 0.08872795 0.08851961 0.08851924]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00288244]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.030240213, shape=(), dtype=float32)\n",
      "Input sequence: [[3277  251  400   68  497  122 1966  157 2249   76 5858    1    1 3268\n",
      "   173   76 1478 1143 1561  697   20   76   13  894  109   76 3264    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00383575]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3972776e-01 1.7643912e-09 6.2942610e-07 1.9143343e-01 4.1128796e-08\n",
      " 6.6687346e-01 2.5306649e-08 1.9607239e-03 3.7126417e-06 2.0716321e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10166702 0.08840913 0.08840918 0.10706206 0.08840913 0.17223307\n",
      " 0.08840913 0.08858264 0.08840946 0.08840915]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00383575]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.04109058, shape=(), dtype=float32)\n",
      "Input sequence: [[3343  724 1793  356 1114 2935 1775  175  911   13    3 1437 1775  127\n",
      "  3831  356  697 4542   13  101  205  407  612 2504 1454   99 3006  724\n",
      "  1775 1795    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0003182]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4218390e-01 2.1792848e-09 7.2608407e-07 1.8827507e-01 4.8206008e-08\n",
      " 6.6744471e-01 3.0051122e-08 2.0909808e-03 4.2621618e-06 2.3480619e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10191474 0.08840714 0.0884072  0.10672206 0.08840714 0.17232762\n",
      " 0.08840714 0.08859219 0.08840752 0.08840717]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0003182]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.0033751798, shape=(), dtype=float32)\n",
      "Input sequence: [[ 195 2137  740  684  966  165 2807 4543   69   10 9335  135   41  543\n",
      "  2291   28    5    2 1103    2  136   82  252   25  377 1194  152    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00111661]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.68017283e-01 6.40098419e-10 3.47172687e-07 2.08282694e-01\n",
      " 1.94507432e-08 6.22185051e-01 1.10054135e-08 1.51268335e-03\n",
      " 1.80841027e-06 1.36602523e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10488111 0.08866011 0.08866014 0.10919036 0.08866011 0.16517328\n",
      " 0.08866011 0.08879433 0.08866028 0.08866012]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00111661]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.012445963, shape=(), dtype=float32)\n",
      "Input sequence: [[ 2287  1810   891   198    14  1049    14   261 10519   258  2324    17\n",
      "    413   139   463  6350    50 10520     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[0.00883189]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4490934e-01 2.0324509e-09 7.0144540e-07 1.8306521e-01 4.5534769e-08\n",
      " 6.6990703e-01 2.8715247e-08 2.1133029e-03 4.1152857e-06 2.2474302e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10217753 0.08839386 0.08839392 0.10615154 0.08839386 0.17272651\n",
      " 0.08839386 0.08858086 0.08839422 0.08839387]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00883189]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.09385232, shape=(), dtype=float32)\n",
      "Input sequence: [[   9 2713 4456  224  310 7762   34 5430    8   65  120 1750  760 2741\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00556268]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7224699e-01 1.3903986e-09 5.7086038e-07 2.5139683e-01 3.9417213e-08\n",
      " 5.7458776e-01 1.9802007e-08 1.7651097e-03 2.4259543e-06 2.3776292e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10557905 0.0888734  0.08887345 0.11427522 0.0888734  0.15787454\n",
      " 0.0888734  0.08903042 0.08887362 0.08887342]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00556268]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.05998035, shape=(), dtype=float32)\n",
      "Input sequence: [[  81   79   16  200   81  200  193 8385 8386   81  214 3119  624  426\n",
      "   627  378  215   31    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.01165347]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4631192e-01 1.3408610e-09 5.5469707e-07 1.9554271e-01 3.4157786e-08\n",
      " 6.5640461e-01 2.0262767e-08 1.7369045e-03 3.1315994e-06 1.7813078e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10241043 0.08847116 0.0884712  0.10757833 0.08847116 0.17055899\n",
      " 0.08847116 0.08862495 0.08847144 0.08847117]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.01165347]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.12605597, shape=(), dtype=float32)\n",
      "Input sequence: [[2043  396  231  181 1411   10   18  118 1364   16  325 4251  193 3618\n",
      "     3    3  373  124    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00227281]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4149325e-01 1.4627902e-09 5.4961276e-07 1.8460587e-01 3.6012345e-08\n",
      " 6.7201281e-01 2.1697550e-08 1.8840047e-03 3.3261219e-06 1.8968657e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1018129  0.08837981 0.08837985 0.10629831 0.08837982 0.1730631\n",
      " 0.08837982 0.08854647 0.08838009 0.08837982]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00227281]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.024530075, shape=(), dtype=float32)\n",
      "Input sequence: [[  34  134  137   52   67  229    7  626  165  193   32  130 4387  970\n",
      "  7507 1377   74  264  137   52  222  271 1306   32    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00779346]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6419917e-01 9.0233032e-10 4.1815707e-07 2.3223934e-01 2.6799380e-08\n",
      " 6.0192871e-01 1.4070683e-08 1.6302244e-03 1.9590025e-06 1.6722655e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10459167 0.08875366 0.08875369 0.11195579 0.08875366 0.16203193\n",
      " 0.08875366 0.08889847 0.08875383 0.08875367]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00779346]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.08564224, shape=(), dtype=float32)\n",
      "Input sequence: [[ 135   41    6 8984  922   51 1776  383  106 5693 1356  331 2373 3253\n",
      "  8985  636 1241  159 1591  636 1891  771 4247    5  431  230  636    1\n",
      "     1  177  331  794  112  331  290   55  103 5461  155 1482  612 1223\n",
      "   331    3  799 1488  123 8986   20   30  341  331 1123  669 8987   83\n",
      "    66  331  188  122  922   13   95   25    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00421976]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.3502616e-01 2.0637108e-09 6.9689185e-07 1.8411393e-01 4.5842683e-08\n",
      " 6.7877066e-01 2.9611705e-08 2.0840541e-03 4.2652159e-06 2.2255146e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10110778 0.08833717 0.08833724 0.10619479 0.08833717 0.17415255\n",
      " 0.08833717 0.08852147 0.08833755 0.08833719]\n",
      "Generated summary: br\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00421976]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.044893768, shape=(), dtype=float32)\n",
      "Input sequence: [[1506  312  114 1298 1303 9099   33 6065  312 1305  186 1172  316   52\n",
      "    30  538  312  318   86   52  551 1811  312  114  525  129 2245    2\n",
      "   167    2  312   86   53  478  312    1    1  662  875  136 1971  167\n",
      "  1536  139  159  312  517  606  188   36 9100 2984    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00411922]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4173552e-01 6.3962002e-10 3.2530420e-07 1.7324263e-01 1.7217914e-08\n",
      " 6.8336266e-01 1.1690046e-08 1.6565876e-03 2.1030146e-06 1.1219623e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10175832 0.08831104 0.08831107 0.10501547 0.08831104 0.17490232\n",
      " 0.08831104 0.08845744 0.08831122 0.08831104]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00411922]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.046076484, shape=(), dtype=float32)\n",
      "Input sequence: [[  9  10  20  86  17  70 157  27 424   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Value estimates: tf.Tensor([[-0.00498509]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7811404e-01 5.8680005e-10 3.3047934e-07 2.3206782e-01 1.9129638e-08\n",
      " 5.8835602e-01 9.8864259e-09 1.4602166e-03 1.4996552e-06 1.3634548e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10613715 0.08882055 0.08882059 0.11202096 0.08882055 0.15996805\n",
      " 0.08882055 0.08895035 0.0888207  0.08882056]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00498509]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.05578166, shape=(), dtype=float32)\n",
      "Input sequence: [[   9  352    5   15  156    2 1662  277 2547 3027  208   46   78   26\n",
      "  3908   18    4   30  352  187   39   28    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00302588]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7169994e-01 4.3892356e-10 2.6998461e-07 2.2472303e-01 1.4672923e-08\n",
      " 6.0220212e-01 8.0802076e-09 1.3732360e-03 1.3076532e-06 1.1268745e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10538224 0.08875628 0.0887563  0.11112072 0.08875628 0.16208102\n",
      " 0.08875628 0.08887824 0.08875639 0.08875629]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00302588]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.034274608, shape=(), dtype=float32)\n",
      "Input sequence: [[3701 7400   20 7401 2848  792 1825    1  149 1325  230  367 3597    1\n",
      "     1 2327 1820  294  959 5379    1 1868 1820 7402 2862    1 5380 7403\n",
      "   105 1308  558    1 1359 1825    1 3702 3703 3701    1    1 1589 1069\n",
      "    68 1393  271 1806 1772  184 1678  712 2626 3704 2563  572  149 1325\n",
      "   230 5381  149 1325  230  367   44 4362 1747  230 7404  816 2509 2248\n",
      "   482 3266 5382 5383 3267 2228 2228 3235 3187    6 3701  241  143 2228\n",
      "  1019 7405 2228   11  759   11  524   32  140 1761  483  289 5384   65\n",
      "    59   42]]\n",
      "Value estimates: tf.Tensor([[-0.00534603]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[2.7849464e-04 2.9423216e-04 3.7550610e-02 3.3798657e-04 2.7584505e-01\n",
      " 1.8135650e-03 4.6600798e-01 2.0684984e-03 1.1893333e-03 2.1461429e-01], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.08935128 0.08935268 0.09274443 0.0893566  0.11770037 0.08948855\n",
      " 0.14235231 0.08951136 0.0894327  0.11070969]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00534603]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.026977917, shape=(), dtype=float32)\n",
      "Input sequence: [[ 398  322  115   57    7   58   29   49  292   73    3   24   23  648\n",
      "  1210   15  723  176  935    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00234115]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5913139e-01 1.4132192e-09 5.5700690e-07 2.1342355e-01 3.7886149e-08\n",
      " 6.2543440e-01 2.1860091e-08 2.0069280e-03 2.8024590e-06 2.3398984e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10393076 0.08864091 0.08864097 0.10972937 0.08864092 0.16567498\n",
      " 0.08864092 0.088819   0.08864115 0.08864093]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00234115]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.025190277, shape=(), dtype=float32)\n",
      "Input sequence: [[ 257  229 2333  193  296 2333  184    2   96  616 1155   51  195  130\n",
      "  2045 8491  621  344   25 1743 8492   48 1478  810 5621   24  919 1183\n",
      "   709  137    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00915545]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6212744e-01 7.0947803e-10 3.6088005e-07 1.9956416e-01 2.0766201e-08\n",
      " 6.3673955e-01 1.1806819e-08 1.5664111e-03 1.9221541e-06 1.3442936e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10417532 0.08858371 0.08858372 0.10814924 0.08858371 0.16745044\n",
      " 0.08858371 0.08872257 0.08858386 0.08858372]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00915545]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.10169855, shape=(), dtype=float32)\n",
      "Input sequence: [[   9   12  265  174  537  379 2010   23 2627  222  188   71  349   12\n",
      "    28  321  349 2436 1903   12    7 5051    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00396429]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7740865e-01 5.2641164e-10 3.1326445e-07 2.3167089e-01 1.7177683e-08\n",
      " 5.8941859e-01 9.6812540e-09 1.4999951e-03 1.4607041e-06 1.3649300e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10605655 0.08881573 0.08881576 0.11197042 0.08881573 0.16012943\n",
      " 0.08881573 0.08894905 0.08881586 0.08881574]\n",
      "Generated summary: great\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00396429]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.044471268, shape=(), dtype=float32)\n",
      "Input sequence: [[ 161  460    3  411    4 3825  147  115   57    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00944378]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5483473e-01 4.6837254e-09 1.2305318e-06 2.0328411e-01 9.2086879e-08\n",
      " 6.3911587e-01 5.9088848e-08 2.7570913e-03 6.3340021e-06 4.5371078e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10340279 0.08857036 0.08857048 0.10853596 0.08857037 0.16782355\n",
      " 0.08857036 0.0888149  0.08857092 0.0885704 ]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00944378]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.096244164, shape=(), dtype=float32)\n",
      "Input sequence: [[ 203   28  203 1594 1231   22   54  203   46  405   72  183    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0023063]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5288986e-01 1.4639371e-09 5.7495521e-07 1.9800010e-01 3.7334868e-08\n",
      " 6.4713049e-01 2.2107566e-08 1.9756032e-03 3.1039631e-06 2.1329168e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1031495  0.0885254  0.08852546 0.10790916 0.08852541 0.16908813\n",
      " 0.08852541 0.08870046 0.08852567 0.08852543]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0023063]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.024820803, shape=(), dtype=float32)\n",
      "Input sequence: [[  18    2 1839  462   32   27    1   67    1    6 1887   41  209   37\n",
      "  3222 2391 7396    1   32   27  535    1    1 1839  169   95  459  134\n",
      "   773 1589    1   19  132   48 3222  178 1589  462  207    1 1687   27\n",
      "   543  317  219    1    1  467   32   27    2   63    1 1018  478    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.0022601]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.7007303e-01 3.5391920e-10 2.3680784e-07 2.3657426e-01 1.2901217e-08\n",
      " 5.9210020e-01 6.8544250e-09 1.2510285e-03 1.1314073e-06 1.0393598e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10526215 0.08879948 0.0887995  0.11250021 0.08879948 0.16053002\n",
      " 0.08879948 0.08891064 0.08879957 0.08879948]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.0022601]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.025809735, shape=(), dtype=float32)\n",
      "Input sequence: [[ 720 1544  139  834   33 2821 1074 2591  477 1544   21    9    8   21\n",
      "     2 1166   11    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00146866]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5498619e-01 1.0043427e-09 4.3207061e-07 1.7717135e-01 2.5443091e-08\n",
      " 6.6596997e-01 1.6003323e-08 1.8693599e-03 2.5516285e-06 1.5333002e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10324226 0.08841945 0.08841949 0.1055583  0.08841945 0.17209764\n",
      " 0.08841945 0.0885849  0.08841968 0.08841947]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00146866]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.01610377, shape=(), dtype=float32)\n",
      "Input sequence: [[1035   71  135   41   31    6   93 1265   32  330 2201  511   93   67\n",
      "    44   73   70 1583  646  103   78   26   96    5   73  905  440 1497\n",
      "   508   73  218  179 1554  111  199  153   56   36  369  201    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00165257]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5092205e-01 7.1173045e-10 3.5037380e-07 1.8994187e-01 1.9562513e-08\n",
      " 6.5748823e-01 1.2243495e-08 1.6453358e-03 2.0375035e-06 1.3022071e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10287859 0.08846682 0.08846685 0.10697225 0.08846682 0.17073552\n",
      " 0.08846682 0.08861249 0.08846699 0.08846682]\n",
      "Generated summary: good\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00165257]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.018385058, shape=(), dtype=float32)\n",
      "Input sequence: [[ 398  229  157   67  375  575   87  256    9    1    1   28    7    5\n",
      "    70  317    5  140  317    5  645 1154   34   30   17   30    1    1\n",
      "    22   77 1292 1831    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00188346]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6601177e-01 4.9452481e-10 2.8682751e-07 1.9235200e-01 1.4952471e-08\n",
      " 6.4011204e-01 9.2184376e-09 1.5221946e-03 1.6107936e-06 1.1652458e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1045609  0.08856688 0.0885669  0.10735166 0.08856688 0.1679842\n",
      " 0.08856688 0.08870179 0.08856702 0.08856689]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00188346]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.021229021, shape=(), dtype=float32)\n",
      "Input sequence: [[  21    9    6  439 1836  116   72   21   18    8    6    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00110088]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5095724e-01 1.2116410e-09 5.0015075e-07 2.0684634e-01 3.1695780e-08\n",
      " 6.4045900e-01 1.7954749e-08 1.7339208e-03 2.7104763e-06 1.8430497e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10299011 0.0885596  0.08855963 0.10891002 0.0885596  0.16802868\n",
      " 0.0885596  0.08871328 0.08855984 0.08855961]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00110088]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.011971765, shape=(), dtype=float32)\n",
      "Input sequence: [[ 238 1564  467    8  121  372  753    6 1781   26    2  585   11  972\n",
      "    74  166    2    8 1590  280  234 1791  766    2  585   11   24  265\n",
      "     6   94    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00455575]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6047679e-01 6.3125544e-10 3.3778508e-07 1.8941489e-01 1.7883302e-08\n",
      " 6.4855957e-01 1.0980430e-08 1.5464423e-03 1.8960563e-06 1.2215426e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10392814 0.0885195  0.08851953 0.10697956 0.0885195  0.16931865\n",
      " 0.0885195  0.08865649 0.08851967 0.08851951]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00455575]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.050886452, shape=(), dtype=float32)\n",
      "Input sequence: [[ 238  781  480  913 2696 1529   14    9  221  225   15 3482  481   14\n",
      "   221    9 1717 1033 2431  269   14  366    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00038593]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.47475243e-01 8.48130788e-10 3.93393606e-07 2.03291565e-01\n",
      " 2.38987532e-08 6.47616267e-01 1.38601655e-08 1.61422568e-03\n",
      " 2.18587547e-06 1.48265485e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10258577 0.0885196  0.08851963 0.10847455 0.0885196  0.1691592\n",
      " 0.0885196  0.08866259 0.0885198  0.08851962]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.00038593]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.004260853, shape=(), dtype=float32)\n",
      "Input sequence: [[  20   52   93   79  296  383 1451  431  431  636  223  513  238    3\n",
      "   710 1319    1    1  426  347 5403 6155  214  963  223  431  636  762\n",
      "   491 3927  109 2023  203 9446 5276  387   55 2817  428    2  431  636\n",
      "    54   46   17 5242    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00559534]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4630772e-01 9.5301433e-10 4.1668335e-07 1.8650383e-01 2.4969856e-08\n",
      " 6.6527361e-01 1.6036431e-08 1.9118026e-03 2.4188071e-06 1.5254432e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10235204 0.08842108 0.08842111 0.10654999 0.08842108 0.17198099\n",
      " 0.08842108 0.08859028 0.08842129 0.08842108]\n",
      "Generated summary: taste\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00559534]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.0614754, shape=(), dtype=float32)\n",
      "Input sequence: [[  110  2894  6299   215    15   917    20   687  1005     1    89   236\n",
      "    362   147   818  1051  3121   170   193   362   564   156   385     1\n",
      "    156    89   760   695   506   362   564   156  3121   228   760     1\n",
      "  10221   760  1038  2841   959   676   750  6310     1   558   605  1734\n",
      "   2274 10222   917   611   222  4715    19   530    88  6308 10223  1576\n",
      "    163   901    18    82   586   530  4804     3    88  1546  2070  2070\n",
      "    422   506  2115     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Value estimates: tf.Tensor([[-0.00579181]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4550802e-01 8.2945750e-10 3.8396070e-07 2.0173429e-01 2.3743857e-08\n",
      " 6.5114599e-01 1.3687114e-08 1.6089650e-03 2.1748253e-06 1.4643442e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.1023609  0.08849949 0.08849952 0.10828115 0.08849949 0.16971877\n",
      " 0.08849949 0.088642   0.08849969 0.0884995 ]\n",
      "Generated summary: UNK\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00579181]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.06403911, shape=(), dtype=float32)\n",
      "Input sequence: [[9529  705   20  131   13   72   36   96  106  288   52 1080  460    3\n",
      "    58  212   35  540    3   40  177  114   35  344  471   12 2079    3\n",
      "    13  138  148    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.0054891]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4540476e-01 8.5629398e-10 3.8196754e-07 1.7944889e-01 2.2647095e-08\n",
      " 6.7341703e-01 1.4066783e-08 1.7264276e-03 2.3461359e-06 1.3597644e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10220361 0.08837261 0.08837266 0.10574294 0.08837261 0.17329219\n",
      " 0.08837261 0.08852532 0.08837283 0.08837263]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[-0.0054891]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(-0.060633056, shape=(), dtype=float32)\n",
      "Input sequence: [[ 195  186  943  171   79   48  584  374   28  186  943  374  793  199\n",
      "   544  681    4 7884  198  139  360  374  773  186  943  374  517  342\n",
      "   857 1121 1144  308   68  419   86  690   36    6  544  681    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00191086]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.6134255e-01 5.4718141e-10 3.0402464e-07 2.0911577e-01 1.7057578e-08\n",
      " 6.2813252e-01 9.5546655e-09 1.4071251e-03 1.6081048e-06 1.1779252e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10414494 0.0886274  0.08862743 0.10924104 0.0886274  0.16609727\n",
      " 0.0886274  0.0887522  0.08862753 0.08862741]\n",
      "Generated summary: love\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00191086]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.021481749, shape=(), dtype=float32)\n",
      "Input sequence: [[ 491   51 3006  127  724 1093 2007 8147  279   36  647   87   40  100\n",
      "  1294   34 4053 8148  463 1947  235 2053  130  127 3344  130  136 1937\n",
      "   582 2161  204  624  565  204 1662  426 3344  127   55  384 1060   13\n",
      "  3843  125  155  245  946 3344  127  142  397  362   16 1076 2354   13\n",
      "    44   89    1    1  103   82  999  762 5727 2954    3    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00100456]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4356305e-01 8.4299806e-10 3.8642577e-07 1.9303252e-01 2.3675602e-08\n",
      " 6.6182876e-01 1.3859148e-08 1.5728290e-03 2.2470490e-06 1.3567006e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10209232 0.08843912 0.08843916 0.10726979 0.08843913 0.17142454\n",
      " 0.08843912 0.08857833 0.08843932 0.08843913]\n",
      "Generated summary: flavor\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00100456]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.011109991, shape=(), dtype=float32)\n",
      "Input sequence: [[  10   98  173  391  120    4   10 1513  847   34 4147  689    2  113\n",
      "    16   98  173   10    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[-0.00374973]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.5966156e-01 4.7592469e-10 2.8222615e-07 2.1204840e-01 1.5127259e-08\n",
      " 6.2696540e-01 8.3338696e-09 1.3227063e-03 1.4562568e-06 1.0240600e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10397578 0.0886323  0.08863232 0.10956794 0.0886323  0.1659127\n",
      " 0.0886323  0.0887496  0.08863243 0.08863231]\n",
      "Generated summary: one\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00374973]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.04245001, shape=(), dtype=float32)\n",
      "Input sequence: [[ 395 2993  730   50   19   13 2416  277   13  156    3  277   81  994\n",
      "  2794   39 2926  271  276  452  130 3897   18 1447   75   40 2095 1634\n",
      "  1816  822   54   93  531   14  732 1579   17   64  139   14  463   72\n",
      "    19 1574  580    3   81  268  147 1286 1532 1551  804   33   18    9\n",
      "     9 1077 1108    9  236  285  758 5284   78  512   39   65   98  163\n",
      "   333    9   65   15  156   20  359  557  319 2130   40  271  209   17\n",
      "  1092  408  123   28   33  156  833    7   27   24  249   59   53  478\n",
      "   341 8886]]\n",
      "Value estimates: tf.Tensor([[-0.00337937]], shape=(1, 1), dtype=float32)\n",
      "Action probabilities before softmax: tf.Tensor(\n",
      "[1.4169151e-01 8.2942903e-10 3.7744707e-07 1.8119994e-01 2.2403821e-08\n",
      " 6.7536926e-01 1.4332321e-08 1.7364604e-03 2.3412283e-06 1.3811028e-07], shape=(10,), dtype=float32)\n",
      "Action probabilities after softmax: [0.10180992 0.0883597  0.08835974 0.10591279 0.08835971 0.17360547\n",
      " 0.0883597  0.08851327 0.08835991 0.08835972]\n",
      "Generated summary: product\n",
      "Reward (ROUGE score): 0.0\n",
      "Returns: [0.]\n",
      "Advantages: tf.Tensor([[0.00337937]], shape=(1, 1), dtype=float32)\n",
      "Loss: tf.Tensor(0.037368845, shape=(), dtype=float32)\n",
      "Input sequence: [[1568   61 8742 8743 8744  800 1175  463  980 1432  398  378  102  124\n",
      "    48 8745  130  600 1175  100 2836  547 2518  980  194    6 1933 5947\n",
      "  1206 5950 3331  800  980  669 8746  463    1  165 2174    1    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "Value estimates: tf.Tensor([[0.00045007]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "NUM_EPOCHS = 5\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for text, summary in zip(X_train, y_train):\n",
    "        # Preprocess input text\n",
    "        state = tokenizer.texts_to_sequences([text])\n",
    "        state = tf.keras.preprocessing.sequence.pad_sequences(state, maxlen=max_length, padding='post')\n",
    "        if np.isnan(state).any():\n",
    "            print(\"NaN values found in input sequence:\", state)\n",
    "            continue\n",
    "        print(\"Input sequence:\", state)  # Debug print\n",
    "        # Forward pass through critic network to get value estimates\n",
    "        _, value = actor_critic(state)\n",
    "        if np.isnan(value).any():\n",
    "            print(\"NaN values found in value estimates:\", value)\n",
    "            continue\n",
    "        print(\"Value estimates:\", value)  # Debug print\n",
    "        # Generate summary using the actor network\n",
    "        generated_summary = generate_summary(actor_critic, text)\n",
    "        print(\"Generated summary:\", generated_summary)  # Debug print\n",
    "        # Calculate reward (ROUGE score)\n",
    "        reward = calculate_rouge(str(generated_summary), str(summary))\n",
    "        print(\"Reward (ROUGE score):\", reward)  # Debug print\n",
    "        # Compute returns and advantages\n",
    "        returns = np.array([reward])  # Use the ROUGE score as the reward\n",
    "        print(\"Returns:\", returns)  # Debug print\n",
    "        advantages = returns - value\n",
    "        print(\"Advantages:\", advantages)  # Debug print\n",
    "        # Perform training step\n",
    "        loss = train_step(actor_critic, state, summary, returns, advantages)\n",
    "        print(\"Loss:\", loss)  # Debug print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKEhS1UrLBBj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
