{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZwrh3FY-c1r",
        "outputId": "8e4bb9d1-66af-4b2a-f1e4-948b7c711688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUS7OwUS-WBc",
        "outputId": "bfb29542-74b2-41a5-9b84-3ad9caa1926f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from rouge import Rouge\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"Reviews.csv\",nrows=5000)\n",
        "# Drop Duplicates and NA values\n",
        "data.drop_duplicates(subset=['Text'], inplace=True)  # dropping duplicates\n",
        "data.dropna(axis=0, inplace=True)  # dropping na\n",
        "data = data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "data['Text'] = data['Text'].apply(preprocess_text)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(data['Text'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(data['Text'], data['Summary'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "empty_summaries = y_train[y_train == '']\n",
        "if len(empty_summaries) > 0:\n",
        "    print(\"Found {} empty summaries in y_train.\".format(len(empty_summaries)))\n",
        "    # Handle empty summaries as needed (e.g., remove them from the dataset)\n",
        "# Handle empty summaries in y_train (e.g., remove them)\n",
        "y_train = y_train[y_train != '']\n",
        "\n",
        "# Pad sequences\n",
        "max_length = 100  # Assuming maximum sequence length\n",
        "# Pad sequences with zeros and apply masking\n",
        "X_train_padded = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\n",
        "X_val_padded = tf.keras.preprocessing.sequence.pad_sequences(X_val_seq, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# Masking for padded tokens\n",
        "mask = (X_train_padded != 0).astype(float)\n",
        "\n",
        "# Actor-Critic model\n",
        "class ActorCritic(tf.keras.Model):\n",
        "    def __init__(self, num_actions, vocab_size):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        # Actor network\n",
        "        self.actor = tf.keras.Sequential([\n",
        "            tf.keras.layers.Embedding(vocab_size, 128, input_length=max_length),\n",
        "            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "            tf.keras.layers.GlobalMaxPooling1D(),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_actions, activation='softmax')\n",
        "        ])\n",
        "        # Critic network\n",
        "        self.critic = tf.keras.Sequential([\n",
        "            tf.keras.layers.Embedding(vocab_size, 128, input_length=max_length),\n",
        "            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "            tf.keras.layers.GlobalMaxPooling1D(),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(1)\n",
        "        ])\n",
        "\n",
        "    def call(self, state):\n",
        "        # Forward pass for actor network\n",
        "        action_probs = self.actor(state)\n",
        "        # Forward pass for critic network\n",
        "        value = self.critic(state)\n",
        "        return action_probs, value\n",
        "\n",
        "# Custom loss functions\n",
        "def actor_loss(action_probs, advantages):\n",
        "    return -tf.reduce_mean(tf.math.log(action_probs) * advantages)\n",
        "\n",
        "def critic_loss(value, returns):\n",
        "    return tf.reduce_mean(tf.square(returns - value))\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Training function\n",
        "def train_step(actor_critic, states, actions, returns, advantages):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass\n",
        "        action_probs, values = actor_critic(states)\n",
        "        # Calculate actor and critic losses\n",
        "        actor_loss_val = actor_loss(action_probs, advantages)\n",
        "        critic_loss_val = critic_loss(values, returns)\n",
        "        total_loss = actor_loss_val + critic_loss_val\n",
        "    # Compute gradients\n",
        "    grads = tape.gradient(total_loss, actor_critic.trainable_variables)\n",
        "    # Apply gradients\n",
        "    optimizer.apply_gradients(zip(grads, actor_critic.trainable_variables))\n",
        "    return total_loss\n",
        "\n",
        "# Example usage\n",
        "num_actions = 10  # Number of actions (e.g., size of vocabulary for text summarization)\n",
        "actor_critic = ActorCritic(num_actions, vocab_size)\n",
        "\n",
        "# Define ROUGE score calculation function\n",
        "def calculate_rouge(generated_summary, ground_truth_summary):\n",
        "    if not ground_truth_summary.strip():  # Check if the ground truth summary is empty\n",
        "        return 0.0  # Return a default value or handle it as appropriate\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(generated_summary, ground_truth_summary)\n",
        "    return scores[0]['rouge-1']['f']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FLxJ-q0-KI3G"
      },
      "outputs": [],
      "source": [
        "def generate_summary(actor_critic, text):\n",
        "    state = tokenizer.texts_to_sequences([text])\n",
        "    state = tf.keras.preprocessing.sequence.pad_sequences(state, maxlen=max_length, padding='post')\n",
        "    action_probs, _ = actor_critic(state)\n",
        "    action_probs = action_probs[0]  # Extract probabilities from batch\n",
        "    print(\"Action probabilities before softmax:\", action_probs)  # Print action_probs for debugging\n",
        "    # Use softmax with epsilon for numerical stability\n",
        "    epsilon = 1e-8  # Small epsilon value\n",
        "    action_probs = tf.nn.softmax(action_probs + epsilon).numpy()\n",
        "    print(\"Action probabilities after softmax:\", action_probs)  # Print action_probs after softmax for debugging\n",
        "    # Choose action index based on probabilities\n",
        "    action = np.random.choice(len(action_probs), p=action_probs)\n",
        "    summary = tokenizer.index_word.get(action, 'UNK')  # Get word corresponding to action index\n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FXEpPvwfB-vX",
        "outputId": "4b219fa2-121e-4833-c0ef-4ecbfd895631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-5.928392e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.3650592e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "great usb audio interface also shure perform wish would known spent way\n",
            "-----------\n",
            "Input sequence: [[   8  814 1179 1756   24 1958 3462  265   13 1032 1499   65    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.9442384e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001964 0.09996863 0.10000784 0.10004801 0.10001048 0.09999776\n",
            " 0.09999445 0.09999736 0.09998012 0.09997574], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000196 0.09999686 0.10000078 0.1000048  0.10000104 0.09999978\n",
            " 0.09999944 0.09999973 0.099998   0.09999757]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.9442384e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(6.779447e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "enjoying recent purchase popchips far enjoyed flavor choice individual serving bag make easy right portion serving meal craving snack thanks product jean roth\n",
            "-----------\n",
            "Input sequence: [[1036 1292  148  375  126  468    5  341  677  255   16   15   89   98\n",
            "   641  255  248  620   77  401    6 8055 8056    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.805522e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001959 0.09996864 0.10000776 0.10004794 0.10001051 0.09999775\n",
            " 0.09999447 0.09999745 0.09998015 0.09997573], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000195 0.09999686 0.10000076 0.10000478 0.10000105 0.09999977\n",
            " 0.09999945 0.09999975 0.099998   0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.805522e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(6.459961e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "fast delivery product arrived exactly described would purchase company\n",
            "-----------\n",
            "Input sequence: [[ 346  447    6  238  516 1788   13  148  185    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.1667366e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001954 0.09996868 0.10000768 0.10004787 0.10001052 0.09999774\n",
            " 0.0999945  0.09999754 0.09998019 0.09997573], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000195 0.09999686 0.10000076 0.10000478 0.10000106 0.09999978\n",
            " 0.09999945 0.09999976 0.09999802 0.09999757]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.1667366e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.686497e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "one cat tolerate particular fancy feast salmon product shredded one get get br everytime eats throw everywhere shoe white rug gratefully br br ate several year occasional upset every time family realize occurs individual basis br br also one younger kitty occasional upset stage kitty tender tummy would avoid\n",
            "-----------\n",
            "Input sequence: [[    7   220  1949   753  1815 11141  1407     6  2312     7    17    17\n",
            "      1  2601   741   758  1723  5586   198 11142 11143     1     1   458\n",
            "    219    48  1595  1263    90    19   143   919  4963   677  1301     1\n",
            "      1    24     7  1988  2083  1595  1263  1769  2083  1125  1373    13\n",
            "    848     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[2.9851739e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10004139 0.09997815 0.10005675 0.10007615 0.1000195  0.09998854\n",
            " 0.09996344 0.09994355 0.09994521 0.09998737], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000414 0.09999781 0.10000567 0.10000761 0.10000195 0.09999885\n",
            " 0.09999634 0.09999435 0.09999452 0.09999873]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.9851739e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-6.873529e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "agree positive review see nice flavor bitter conference coffee flavor mess br br reference purpose store drink starbucks br br favorite br starbucks french roast br starbucks caffe verona br starbucks pike place roast br green mountain xtra bold sumatran reserve br green mountain double black diamond br green mountain revv br green mountain dark magic br br tried coffee people jet fuel green mountain dark magic decaf emeril jazzed decaf starbucks caffe verona coffee people black tiger starbucks house blend starbucks breakfast blend starbucks sumatra wolfgang puck french roast green mountain lake lodge green mountain french roast caribou mahogony wolfgang puck sumatra kopi raya emeril big easy bold\n",
            "-----------\n",
            "Input sequence: [[   5  877    1    1 2039 1038   41   64  550    1    1   58    1  550\n",
            "   570  442    1  550 3880 2766    1  550 5899  404  442    1  125  711\n",
            "  5900  625 3878 3522    1  125  711 1009  269 1733    1  125  711 4643\n",
            "     1  125  711  212 1969    1    1   28   12  170 4641 3870  125  711\n",
            "   212 1969  244 3364 4645  244  550 3880 2766   12  170  269 4205  550\n",
            "   363  221  550  417  221  550 2320 2542 2345  570  442  125  711 4646\n",
            "  3365  125  711  570  442  897 3881 2542 2345 2320 5901 5902 3364  164\n",
            "    89  625]]\n",
            "Value estimates: tf.Tensor([[-3.738338e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10003367 0.0999747  0.10003931 0.10006626 0.10001639 0.09999178\n",
            " 0.09997445 0.09996275 0.09995757 0.09998315], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000337 0.09999748 0.10000394 0.10000663 0.10000164 0.09999917\n",
            " 0.09999745 0.09999628 0.09999575 0.09999832]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[3.738338e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(8.607982e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "used buy world market however discontinued br forced buy online rose violet flavor good however like anise flavor strong licorice tasting br br carry purse freshen breath really br also tin cute\n",
            "-----------\n",
            "Input sequence: [[  49   25  657  297  121 2484    1 2942   25  378  800 5738    5    3\n",
            "   121    2 3735    5  145  311  218    1    1  441 1510 4054 1297   18\n",
            "     1   24  950  973    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.2155142e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10004269 0.09995276 0.10002466 0.10007474 0.10000727 0.1000037\n",
            " 0.09999147 0.09997171 0.09996501 0.09996604], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000428 0.09999529 0.10000248 0.10000747 0.10000073 0.10000037\n",
            " 0.09999915 0.09999718 0.09999651 0.0999966 ]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.2155142e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.7988262e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "began purchasing tea year ago looked forward year past two year unable locate local store elated find amazon taste like cinnamon red candy apple love\n",
            "-----------\n",
            "Input sequence: [[1256  532   14   48  263  423  721   48  500   79   48 1183 2714  135\n",
            "    41 3793   31   32    4    2  508  396  267  455    9    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.3323435e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001954 0.09996866 0.10000766 0.10004798 0.10001065 0.09999767\n",
            " 0.09999445 0.09999759 0.09998011 0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000196 0.09999687 0.10000077 0.1000048  0.10000107 0.09999976\n",
            " 0.09999944 0.09999976 0.099998   0.09999757]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.3323435e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-5.3703647e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "took one said good russet potato chip flavoring sudden within second spread sens taste bud happy close thai food potato chip get chip spicy enough satisfy craving spice hint sweetness make habit forming flavoring included garlic ginger jalapeno cilantro spice felt great eat buy treat\n",
            "-----------\n",
            "Input sequence: [[ 330    7  193    3 3567   69   10  791 6843  735  332  898 3569    4\n",
            "  1039  154  599  618   11   69   10   17   10  246  100 1283  620  381\n",
            "   700  755   15 1379 4171  791 1105  518  493 1103 1724  381  774    8\n",
            "    42   25  129    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.2126253e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001955 0.09996862 0.10000764 0.10004803 0.10001068 0.09999765\n",
            " 0.09999446 0.09999763 0.09998009 0.09997564], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000196 0.09999686 0.10000077 0.10000481 0.10000107 0.09999977\n",
            " 0.09999945 0.09999977 0.09999802 0.09999757]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.2126253e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.7921877e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "wo get specific chip listed amazon however talk product overall well packaged popchips bag flimsy loud worry much getting smashed bag heavier item hold trying new food snack flavor tend purchase variety pack sample everything let tell chip packed flavor opinion heavy saturated favorite barbecue potato cheddar potato far realistic savory flavor couple favorite tasty time sea salt pepper potato sea salt vinegar potato bit strong first like flavor would say would like chip certainly accomplish taste ingredient original potato sour cream onion potato also tasty nothing necessarily rave least would call diet chip healthy alternative processed chip saw complaint popchips salty high sodium chip come across salty person consume much salt per bag popchips contain much sodium cup plain yogurt overall great buy decide price tag okay\n",
            "-----------\n",
            "Input sequence: [[   5  859  148  157   67  826  276  313  376   10  630    5  484  775\n",
            "  1923   58 1204   69  534   69  126 5697 1528    5  268   58  118   19\n",
            "   494   76  314   69  494   76  239   69   66  145   45    2    5   13\n",
            "    52   13    2   10  606 8088    4   61  327   69  449  224  548   69\n",
            "    24  118  226 3194 2105  290   13  573  171   10  107  303  918   10\n",
            "   498  629  375  302  149  350   10   97  996  302  686 1461   20   76\n",
            "   132   16  375  607   20  350   43  334 1013  414    8   25 1853   27\n",
            "  3452  602]]\n",
            "Value estimates: tf.Tensor([[-9.545123e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001954 0.09996862 0.10000762 0.10004803 0.10001069 0.09999764\n",
            " 0.09999446 0.09999766 0.09998009 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000196 0.09999686 0.10000077 0.10000481 0.10000107 0.09999977\n",
            " 0.09999945 0.09999977 0.09999802 0.09999757]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[9.545123e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.197855e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "great product flavor delicious loved fact single serve bag calorie\n",
            "-----------\n",
            "Input sequence: [[  8   6   5  70 199 245 335 642  16  84   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Value estimates: tf.Tensor([[1.2009816e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001951 0.09996866 0.10000759 0.10004799 0.1000107  0.09999765\n",
            " 0.09999447 0.0999977  0.09998012 0.09997565], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000195 0.09999687 0.10000076 0.1000048  0.10000107 0.09999976\n",
            " 0.09999944 0.09999976 0.099998   0.09999756]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.2009816e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.7653477e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "pack snack product tried many absolute favorite funny thing even like oreo crazy chocolate however thin crisp exactly thin crisp also right fend sweet craving premature hunger\n",
            "-----------\n",
            "Input sequence: [[  67   77    6   28   71 1237   58 1174   54   34    2  312  793   35\n",
            "   121  407  336  516  407  336   24   98 9104   62  620 9105 3785    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.0662438e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001951 0.09996864 0.10000757 0.10004801 0.10001072 0.09999763\n",
            " 0.09999447 0.09999773 0.09998012 0.09997563], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000195 0.09999686 0.10000075 0.1000048  0.10000107 0.09999976\n",
            " 0.09999944 0.09999976 0.099998   0.09999756]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.0662438e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-7.060277e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "arrived quick great value definitely pleased purchase likely buy\n",
            "-----------\n",
            "Input sequence: [[ 238  340    8  399  138  406  148 1170   25    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-6.5374675e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001952 0.09996862 0.10000756 0.10004803 0.10001073 0.09999763\n",
            " 0.09999447 0.09999774 0.0999801  0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000196 0.09999686 0.10000076 0.10000481 0.10000107 0.09999977\n",
            " 0.09999946 0.09999978 0.09999802 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[6.5374675e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.5053117e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "one best salsa found long time stay away variety pack two come worth money\n",
            "-----------\n",
            "Input sequence: [[  7  22 659  50 155  19 488 197 157  67  79  97 188 217   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Value estimates: tf.Tensor([[8.697375e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000195  0.09996862 0.10000753 0.10004802 0.10001074 0.09999762\n",
            " 0.09999447 0.09999776 0.0999801  0.0999756 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000195 0.09999686 0.10000075 0.1000048  0.10000107 0.09999976\n",
            " 0.09999944 0.09999976 0.099998   0.09999756]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-8.697375e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.002644e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "like werther hard candy may like pretty good caramel hard really sticky like filling br br eating bag wanted caramel really closely related different term br br cup tea like caramel really hard hard candy hard still may love think caramel soft chewy may br br tried warming really helped almost tempted raise star microwave though turn bubbling mass goo\n",
            "-----------\n",
            "Input sequence: [[   2 2690  116  267  168    2  133    3  796  116   18 1438    2  662\n",
            "     1    1  122   16  264  796   18 3345 2383  106 1121    1    1   43\n",
            "    14    2  796   18  116  116  267  116   74  168    9   59  796  364\n",
            "   832  168    1    1   28 3126   18  921  169 2523 1783  183  727  134\n",
            "   605 8200 1866 2683    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[7.163517e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001949 0.09996862 0.10000753 0.10004802 0.10001076 0.09999762\n",
            " 0.09999447 0.09999778 0.09998011 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000194 0.09999686 0.10000075 0.1000048  0.10000107 0.09999976\n",
            " 0.09999944 0.09999978 0.099998   0.09999756]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.163517e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.6494602e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "great product br br stevia powder raise blood glucose level br br use sparingly since much sweeter br br taste natural artifical sweetener healthy use since organic natural sweetener\n",
            "-----------\n",
            "Input sequence: [[   8    6    1    1  415  227 1783  968 2897  558    1    1   23 4133\n",
            "    63   20 1372    1    1    4  144 3213  354  107   23   63   94  144\n",
            "   354    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.8117756e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10003708 0.09997624 0.10004699 0.10007077 0.10001796 0.09999023\n",
            " 0.09996951 0.09995434 0.09995198 0.09998496], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000371 0.09999763 0.1000047  0.10000708 0.1000018  0.09999903\n",
            " 0.09999695 0.09999543 0.0999952  0.0999985 ]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.8117756e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-6.4743444e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "favorite brand coconut water one tried use real fruit juice flavoring well taste br br tried smaller size large enough get enough water gym br br thing like br br perfect size hour long gym routine br resealable cap smaller one lack br tasty like pina colada br br negative br br box make hard get last usually end squishing get last bit br br great coconut water perfect size cheaper buying locally sprout amazon save\n",
            "-----------\n",
            "Input sequence: [[  58   33  187   39    7   28   23  177  281  266  791   40    4    1\n",
            "     1   28  453  113  296  100   17  100   39 3907    1    1   54    2\n",
            "     1    1  110  113  475  155 3907 2587    1 1883 5712  453    7  952\n",
            "     1  118    2 2547 3027    1    1 1037    1    1   37   15  116   17\n",
            "   182  189  439 9009   17  182   66    1    1    8  187   39  110  113\n",
            "   249  158  666 4406   32  241    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-9.064864e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10011631 0.1000105  0.10022508 0.10017328 0.10005033 0.0999568\n",
            " 0.09985686 0.09975859 0.09982514 0.10002711], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10001163 0.10000105 0.10002251 0.10001733 0.10000504 0.09999568\n",
            " 0.09998569 0.09997586 0.09998252 0.10000271]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[9.064864e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.0872712e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "really like product taste great coffee tea lost weight cutting sugar replacing honey agave nectar\n",
            "-----------\n",
            "Input sequence: [[  18    2    6    4    8   12   14 1004  294 1727   47 2899  351 1309\n",
            "  1670    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-3.2714772e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000194  0.0999686  0.10000733 0.10004792 0.10001075 0.09999764\n",
            " 0.0999946  0.09999801 0.09998024 0.09997555], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000194 0.09999686 0.10000073 0.10000478 0.10000107 0.09999976\n",
            " 0.09999946 0.0999998  0.09999802 0.09999755]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[3.2714772e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(7.5328653e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "book eat one serving ease feel remorse wish bbq cheese flavored selection black pepper bestest yet\n",
            "-----------\n",
            "Input sequence: [[1422   42    7  255 1704  156 8050  265  438  310  349 1680  269  314\n",
            "  8051  347    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.0283635e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10005048 0.0999821  0.10007717 0.1000881  0.10002346 0.09998454\n",
            " 0.0999504  0.09992114 0.09993047 0.09999213], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000505 0.09999821 0.10000771 0.10000882 0.10000235 0.09999845\n",
            " 0.09999504 0.09999212 0.09999305 0.09999922]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.0283635e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.6704386e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "one important thing mentioned label use container hide info make sale course learn read q website studied label opened back label never mentioned ca use potted plant thanks bayer go back store return guess lot people wondered potted flower rose died knowing product see bee dwindle disappear reason systemic product affect fragrance flower year use fragrance got earthworm would know unless thoroughly dug dirt avoid\n",
            "-----------\n",
            "Input sequence: [[   7  844   54 1065  394   23  452 2273 1661   15  459  410 1932  284\n",
            "  8739  601 8740  394  426  136  394   95 1065   86   23 4665 1175  401\n",
            "  4663   53  136   41  709  490   75  170 2457 4665  980  800 2993 1719\n",
            "     6  165 2228 8741 3216  372 2509    6 1749 2859  980   48   23 2859\n",
            "    81 5948   13   68  547 2020 3754 1768  848    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.8494429e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002153 0.09996951 0.1000121  0.1000507  0.10001163 0.09999674\n",
            " 0.09999157 0.09999276 0.09997682 0.09997667], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000216 0.09999695 0.10000122 0.10000508 0.10000117 0.09999968\n",
            " 0.09999916 0.09999929 0.09999769 0.09999768]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.8494429e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.2584957e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "funny thing bought several week ago based strength review time got last week cup since using ounce water prepare cocoa thought tasted pretty good reasonably chocolaty br br sweet overly richness made check calorie count box calorie hey bad came back place review read recent review others realize use artificial sweetener honestly read would never known detect anything gave hint drank br br think like quick cocoa run happy enough good swiss miss packet costco maybe office want deal getting powder counter needing spoon get thing mixed sacrifice little convenience well worth\n",
            "-----------\n",
            "Input sequence: [[1174   54   51  219  204  263  639 1585   83   19   81  182  204   43\n",
            "    63  102  380   39  843  108  131  166  133    3 1243 2049    1    1\n",
            "    62  903 3298   44  892   84  874   37   84 1446  105  174  136  404\n",
            "    83  284 1292   83  225  919   23  373  354 1063  284   13   95 1032\n",
            "  2738  163  279  700 1447    1    1   59    2  340  108  377  154  100\n",
            "     3  812  584  285 1596  258  855   80  235  271  227 1722 2519 1274\n",
            "    17   54  471 2546   26  683   40  188    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.1450465e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001934 0.0999685  0.10000713 0.10004789 0.10001075 0.09999766\n",
            " 0.0999947  0.09999824 0.09998034 0.09997545], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000193 0.09999685 0.10000072 0.10000478 0.10000107 0.09999977\n",
            " 0.09999947 0.09999982 0.09999803 0.09999754]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.1450465e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.939198e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "saw ingredient box knew would disappointment would much better pretty easy make mix also plenty quality mix like pamela bob red mill huge disappointment waste money\n",
            "-----------\n",
            "Input sequence: [[ 498   61   37  882   13 1300   13   20   30  133   89   15   29   24\n",
            "   835   88   29    2 1418 1142  396  635  621 1300  603  217    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-4.004019e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10006246 0.09998722 0.10010399 0.10010363 0.10002838 0.09997951\n",
            " 0.09993342 0.09989167 0.09991132 0.09999844], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000624 0.09999873 0.1000104  0.10001036 0.10000284 0.09999795\n",
            " 0.09999335 0.09998916 0.09999113 0.09999984]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[4.004019e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(9.219612e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "received brick today disappointed find brick broken unusable plate busted completed half packaged one sleeve small bubble wrap shallow box protection packaging box went online try return eligible return first return ever tried year purchasing item amazon tune several order month yet one time want return defective product ca much careful eligible return future\n",
            "-----------\n",
            "Input sequence: [[ 229 4393  627  257   31 4393  546 7524 2147 2973 7525  207  480    7\n",
            "  5411  109 1332 1643 3467   37 7526  291   37  322  378   36  709 5457\n",
            "   709   45  709   92   28   48  532  137   32 4394  219   60  142  347\n",
            "     7   19   80  709 3729    6   86   20 1096 5457  709  850    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.3990947e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001927 0.09996857 0.10000706 0.10004775 0.10001072 0.09999766\n",
            " 0.09999475 0.09999832 0.09998041 0.09997549], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000193 0.09999686 0.10000071 0.10000478 0.10000108 0.09999978\n",
            " 0.09999948 0.09999983 0.09999805 0.09999755]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.3990947e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.2215154e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "buying milk hot chocolate month one best even got hooked granddaughter absolutely love great price great product\n",
            "-----------\n",
            "Input sequence: [[ 158  114   38   35  142    7   22   34   81  748 3846  300    9    8\n",
            "    27    8    6    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.2508382e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002404 0.09997062 0.10001776 0.10005393 0.10001268 0.09999566\n",
            " 0.09998797 0.09998654 0.09997278 0.09997802], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000024  0.09999706 0.10000177 0.10000539 0.10000127 0.09999956\n",
            " 0.09999879 0.09999865 0.09999727 0.0999978 ]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.2508382e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.8801456e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "chip delectably delicious low sodium diet give totally something truely love snack chip bursting flavor ca really tell missing salt kiss worth chip beleive total makeout\n",
            "-----------\n",
            "Input sequence: [[  10 6985   70  186  350  171   72  696   96 3593    9   77   10 3594\n",
            "     5   86   18  376 1231   76 3595  188   10 5183  884 6986    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.9339459e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.09997732 0.10008908 0.10000059 0.09990836 0.1001984  0.09978472\n",
            " 0.09992391 0.1001627  0.10007233 0.09988255], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.09999773 0.10000891 0.10000006 0.09999084 0.10001984 0.09997847\n",
            " 0.09999239 0.10001627 0.10000723 0.09998825]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.9339459e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.4531138e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "purchase food two boxer great dane dane allergy chicken one boxer weak stomach food perfect three dog love even picky one seems agree digestive tract dog food tried ca begin tell pleased lot research find quality food full filler wo break bank pleased food expensive brand tried\n",
            "-----------\n",
            "Input sequence: [[ 148   11   79 3810    8 3045 3045  427  176    7 3810  559  523   11\n",
            "   110  216   21    9   34  555    7  260  790 1144 3092   21   11   28\n",
            "    86 1994  376  406   75 1116   31   88   11  206 1198  228  760 2741\n",
            "   406   11  192   33   28    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.7474343e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001933 0.09996829 0.10000698 0.10004802 0.10001039 0.09999807\n",
            " 0.09999493 0.09999813 0.09998029 0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000195 0.09999683 0.10000071 0.10000481 0.10000104 0.09999982\n",
            " 0.09999949 0.09999982 0.09999803 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.7474343e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(6.326208e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "got christmas stocking stepfather foodie try cook like chef home love product use one onion recently always went bad could use sometimes threw time honestly remember last time used every single one inside savor pod grow keep week easily planning buying set mini savor pod actually use fresh herb storing herb container onion good idea drawback product clear plastic cover little tricky remove others mentioned wrestling ok long use product go bad\n",
            "-----------\n",
            "Input sequence: [[  81  457 1587 5468 2349   36  405    2 2060  214    9    6   23    7\n",
            "   548  398  103  322  105   46   23  456 1107   19 1063  611  182   19\n",
            "    49   90  335    7  472 1793  356 1712   99  204  409 2528  158  510\n",
            "   867 1793  356  161   23  127  724 3006  724  452  548    3  434 1807\n",
            "     6  663  362 1678   26 3845 1652  225 1065 5452  479  155   23    6\n",
            "    53  105    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.1502815e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10005227 0.09996779 0.10006119 0.10008896 0.1000163  0.09999345\n",
            " 0.0999651  0.09993415 0.09993981 0.09998096], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000522 0.09999677 0.10000612 0.10000889 0.10000163 0.09999934\n",
            " 0.09999651 0.09999341 0.09999398 0.09999809]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.1502815e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.648608e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "mint really strong great taste also convenient size carry pocket purse\n",
            "-----------\n",
            "Input sequence: [[ 617   18  145    8    4   24  553  113  441 1390 1510    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.1743089e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001946 0.0999679  0.10000701 0.10004846 0.10000978 0.09999874\n",
            " 0.09999514 0.09999757 0.09997997 0.09997591], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000195 0.09999679 0.1000007  0.10000484 0.10000098 0.09999987\n",
            " 0.09999952 0.09999976 0.099998   0.09999759]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.1743089e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-7.309107e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "feed hill science diet pet love vet tell honesty product quite certainly worst reseal ever encountered painfully difficult get close properly even resealed best still gap side allow air oxidize br br packaging important better pet live stale oxidized food would oxidized fat also called rancid imagine healthy rancid diet human well get idea br br posting review hill science diet product kind packaging experience product please take time let company know br br love animal want keep feeding vet tell good quite literally worst reseal ever misfortune br br theo\n",
            "-----------\n",
            "Input sequence: [[ 435 3035 1062  171  446    9  675  376 5323    6  205  606  878 3891\n",
            "    92 2293 5325  552   17  599 1677   34 9126   22   74 9127  342 1658\n",
            "   655 9128    1    1  291  844   30  446  527  610 4458   11   13 4458\n",
            "   150   24  626 1663 1024  107 1663  171 1166   40   17  434    1    1\n",
            "  5821   83 3035 1062  171    6  210  291  517    6  425  112   19  313\n",
            "   185   68    1    1    9  807   80   99  507  675  376    3  205 1395\n",
            "   878 3891   92 9129    1    1 9130    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.7322564e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001956 0.09996771 0.10000706 0.10004872 0.10000953 0.09999903\n",
            " 0.09999522 0.09999731 0.0999798  0.09997601], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000195 0.09999676 0.1000007  0.10000487 0.10000094 0.09999989\n",
            " 0.09999951 0.09999973 0.09999797 0.09999759]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.7322564e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.988665e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "excellent shipment product well looking forward purchase thanks br excellent shipment product well looking forward purchase thanks br excellent shipment product well looking forward purchase thanks\n",
            "-----------\n",
            "Input sequence: [[140 594   6  40 152 721 148 401   1 140 594   6  40 152 721 148 401   1\n",
            "  140 594   6  40 152 721 148 401   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Value estimates: tf.Tensor([[-2.3563436e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001966 0.09996754 0.10000711 0.10004896 0.10000931 0.09999929\n",
            " 0.09999529 0.09999708 0.09997965 0.09997612], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000197 0.09999676 0.10000072 0.1000049  0.10000094 0.09999993\n",
            " 0.09999953 0.09999972 0.09999797 0.09999762]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.3563436e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(5.4257373e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "used mix year yellow pound cake everyone seems love still able purchase local grocery going order product saw oz afraid would go old duncan hines pound cake recipe hope company realize damage time proven recipe downsize product\n",
            "-----------\n",
            "Input sequence: [[   49    29    48  1079   345   167   256   260     9    74   252   148\n",
            "    135   178   162    60     6   498   237  1746    13    53   111  1963\n",
            "   1845   345   167   160   428   185   919  1825    19  3031   160 10444\n",
            "      6     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[7.1770532e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001969 0.09996745 0.10000712 0.10004906 0.1000091  0.09999952\n",
            " 0.09999536 0.09999687 0.09997957 0.09997626], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000196 0.09999674 0.10000071 0.1000049  0.10000091 0.09999995\n",
            " 0.09999953 0.09999969 0.09999796 0.09999762]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.1770532e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.6525724e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "kind tea good taste smell wear like tea feel like thing chemical\n",
            "-----------\n",
            "Input sequence: [[ 210   14    3    4  234 3638    2   14  156    2   54  604    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.8935392e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001973 0.09996735 0.10000715 0.10004918 0.10000891 0.09999974\n",
            " 0.09999542 0.09999669 0.09997948 0.09997638], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000197 0.09999673 0.10000071 0.10000491 0.10000088 0.09999996\n",
            " 0.09999953 0.09999966 0.09999795 0.09999763]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.8935392e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.359999e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "stuff taste great decaf person perhaps melitta coffee try\n",
            "-----------\n",
            "Input sequence: [[124   4   8 244 686 692 430  12  36   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Value estimates: tf.Tensor([[-5.356116e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001981 0.09996721 0.10000719 0.10004938 0.10000876 0.09999993\n",
            " 0.09999546 0.0999965  0.09997934 0.09997643], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000198 0.09999672 0.10000072 0.10000494 0.10000088 0.09999999\n",
            " 0.09999955 0.09999965 0.09999794 0.09999765]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[5.356116e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.2332943e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "gluten free go mainstream addition gluten free br general mill good job making gluten free version famous brand br br gluten free know someone estimated million american affected gluten protein found wheat barley rye grain even know gluten toxin many especially celiac disease autism diabetes multiple sclerosis crohn disease host gluten intolerant gluten sensitivity br quite challenging following gluten free diet find afford product gluten free wheat one prevalent ingredient american br find best tasting gluten free food exclusively serving gluten free community year\n",
            "-----------\n",
            "Input sequence: [[  115    57    53  3033   679   115    57     1  1205   635     3   969\n",
            "    223   115    57   365  2641    33     1     1   115    57    68   400\n",
            "   5604  3089   881  3113   115   361    50   360  2166  1686   614    34\n",
            "     68   115  3789    71   254   803   993  3587  2862  1119  5547 10326\n",
            "    993  5286   115  2181   115  1738     1   205  4424   954   115    57\n",
            "    171    31  1638     6   115    57   360     7  3556    61   881     1\n",
            "     31    22   218   115    57    11  2469   255   115    57  1614    48\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[-9.245086e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001986 0.09996709 0.10000721 0.10004954 0.10000861 0.10000008\n",
            " 0.0999955  0.09999634 0.09997924 0.09997649], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000199 0.09999671 0.10000072 0.10000495 0.10000086 0.1\n",
            " 0.09999955 0.09999964 0.09999792 0.09999765]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[9.245086e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.1287684e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "hand best tasting hot chocolate available cafe escape whatever brand name taste watered artificial one taste thicker milkier love dark chocolate flavor although know dark probably could told difference regular cup cocoa stick flavor probably richer milk chocolate option hit house weather cool everyone always want hot chocolate br br something note work much better used oz per use per mug flavor much better try one watery\n",
            "-----------\n",
            "Input sequence: [[ 348   22  218   38   35  240  798 1385  701   33  504    4 1241  373\n",
            "     7    4 1113 9471    9  212   35    5  318   68  212  208   46  569\n",
            "   422   91   43  108  295    5  208 2350  114   35  386  541  363 1495\n",
            "   853  256  103   80   38   35    1    1   96  579   87   20   30   49\n",
            "   237  132   23  132 1131    5   20   30   36    7  752    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.6567513e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002244 0.09996812 0.10001297 0.10005294 0.10000952 0.09999917\n",
            " 0.09999193 0.0999899  0.09997508 0.09997793], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000224 0.09999681 0.1000013  0.10000529 0.10000095 0.09999992\n",
            " 0.09999919 0.099999   0.09999751 0.0999978 ]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.6567513e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-6.1173896e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "keep case office always least tin two desk visitor help folk stop grab mint others pop like candy meet find someone keep coming back give tin one asked save tin could use pillbox safety pin box like said theyre real hit since would able keep hand candy dish good alternative around nice around garlic lunch gave item star tasty sugar version mint sugar free item good full sugar counterpart fact tin wrapped plastic seems like waste irritating remove although totally get wrap still make easy deal\n",
            "-----------\n",
            "Input sequence: [[  99  147  855  103  290  950   79 1449 4978  247 1150  587 1419  617\n",
            "   225  329    2  267 1511   31  400   99  866  136   72  950    7 1034\n",
            "   241  950   46   23 6602 3107 4051   37    2  193 6603  177  541   63\n",
            "    13  252   99  348  267  499    3  303  209   82  209  518  451  279\n",
            "   137  183  118   47  365  617   47   57  137    3  206   47 4052  245\n",
            "   950  871  362  260    2  603 6604 1652  318  696   17 1643   74   15\n",
            "    89  235    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-4.0178597e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001993 0.09996693 0.10000727 0.10004974 0.10000836 0.10000037\n",
            " 0.09999558 0.09999608 0.09997909 0.09997664], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.100002   0.09999671 0.10000073 0.10000498 0.10000084 0.10000005\n",
            " 0.09999956 0.09999961 0.09999792 0.09999767]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[4.0178597e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(9.251481e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "kid like cocoa perfect ca make kid hot choco taste good count bad\n",
            "-----------\n",
            "Input sequence: [[ 202    2  108  110   86   15  202   38 6176    4    3  874  105    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-7.313809e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10001995 0.09996688 0.10000727 0.10004981 0.10000823 0.10000049\n",
            " 0.09999561 0.09999596 0.09997904 0.09997669], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000199 0.09999669 0.10000073 0.10000498 0.10000082 0.10000005\n",
            " 0.09999956 0.0999996  0.0999979  0.09999767]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[7.313809e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.6840722e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "lasted month sampled flavor got eat barbecue flavor wife favorite reordered barbecue great snack calorie purchased reduced fat pringles individual pack get lot chip popchips bag pringles\n",
            "-----------\n",
            "Input sequence: [[2080  142 3824    5   81   42 1204    5  491   58 3825 1204    8   77\n",
            "    84  175 1193  150 2024  677   67   17   75   10  375   16 2024    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.5317316e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10005254 0.09988556 0.09995175 0.10008025 0.09997419 0.10004492\n",
            " 0.10005938 0.10003059 0.10000754 0.09991325], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000525 0.09998856 0.09999517 0.10000802 0.09999742 0.10000449\n",
            " 0.10000593 0.10000306 0.10000075 0.09999132]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.5317316e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-8.1319886e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "clearly best canned clam chowder tasted refreshing canned soup without unnecessary preservative artificial flavoring supposed condensed like hearty thick soup better heated without adding milk water clam perfect cooked order look forward trying product amazon\n",
            "-----------\n",
            "Input sequence: [[1197   22  464  431  636  166  728  464  331   85 3056 1188  373  791\n",
            "   981 6019    2 2276  563  331   30 1852   85  576  114   39  431  110\n",
            "   608   60  184  721  215    6   32    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.765669e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002016 0.09996643 0.10000714 0.10005014 0.10000796 0.10000087\n",
            " 0.09999589 0.09999589 0.099979   0.09997655], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000202 0.09999665 0.10000071 0.10000502 0.1000008  0.10000008\n",
            " 0.09999959 0.09999959 0.09999791 0.09999765]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.765669e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.065634e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "purchased bag seemed size bag purchased realize ounce compared bag aware might perfect u bag potato chip cut might perfect kid head\n",
            "-----------\n",
            "Input sequence: [[ 175   16  647  113   16  175  919  380  529   16  983  250  110  203\n",
            "    16   69   10  384  250  110  202 1648    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.9429702e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002029 0.09996612 0.10000698 0.10005032 0.10000777 0.10000109\n",
            " 0.0999961  0.0999959  0.09997902 0.09997638], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000202 0.09999661 0.10000069 0.10000502 0.10000078 0.10000011\n",
            " 0.09999961 0.09999958 0.0999979  0.09999763]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.9429702e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(6.776526e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love flavor speed cocoa drink one night good stuff\n",
            "-----------\n",
            "Input sequence: [[   9    5 3491  108   64    7  566    3  124    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.8847517e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002878 0.09996958 0.10002577 0.10006125 0.10001104 0.09999775\n",
            " 0.09998433 0.09997509 0.09996562 0.09998079], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000289 0.09999696 0.10000258 0.10000613 0.10000111 0.09999978\n",
            " 0.09999844 0.09999752 0.09999657 0.09999809]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.8847517e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.3397657e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "many purchses made amazon past december pleased pocky chocolate cream covered biscuit stick pack arrived time surprised gift sure keep refridgerated\n",
            "-----------\n",
            "Input sequence: [[  71 7249   44   32  500 4209  406 1208   35  224 1460  292  295   67\n",
            "   238   19  460  251  123   99 7250    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.8243157e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002045 0.09996571 0.10000674 0.10005047 0.10000744 0.10000146\n",
            " 0.09999646 0.0999959  0.09997912 0.09997618], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000205 0.09999658 0.10000068 0.10000505 0.10000075 0.10000016\n",
            " 0.09999965 0.09999959 0.09999792 0.09999762]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.8243157e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-6.503148e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "believe dog food dog like start br br next think research make sure right br br pooch human grade product go dog food another br br decision size lb pound bag perfect buying br br amazon great way buy pounder\n",
            "-----------\n",
            "Input sequence: [[  319    21    11    21     2   539     1     1   317    59  1116    15\n",
            "    123    98     1     1  5634  1166  2142     6    53    21    11   194\n",
            "      1     1  2328   113   811   345    16   110   158     1     1    32\n",
            "      8    65    25 10817     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[-1.23835325e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10004448 0.09997574 0.10006028 0.10008161 0.1000171  0.09999158\n",
            " 0.09996268 0.09993689 0.09994088 0.09998874], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000444 0.09999757 0.10000603 0.10000815 0.10000171 0.09999915\n",
            " 0.09999625 0.09999368 0.09999409 0.09999887]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.23835325e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.851429e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "picked one use laptop running window home premium computer saw item said needed troubleshooting nothing worked researching online found many people run problem apparently firmware compatible window supposedly corrected newer run way tell one purchasing newer tried contacting blue twice hoping get firmware update check exchanging never got response attempt finally return\n",
            "-----------\n",
            "Input sequence: [[  901     7    23  2781   856   851   214  1159   929   498   137   193\n",
            "    416  4817   226   673  4478   378    50    71   170   377   119  1320\n",
            "   6312  3407   851  3309  4409  2619   377    65   376     7   532  2619\n",
            "     28  3574   489   652   810    17  6312  1031   892 10183    95    81\n",
            "   1748  2360   522   709     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[-3.1612366e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10008652 0.09999365 0.10015439 0.100136   0.10003411 0.09997407\n",
            " 0.09990323 0.0998333  0.09987379 0.10001094], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000864 0.09999935 0.10001543 0.10001359 0.10000341 0.0999974\n",
            " 0.09999032 0.09998333 0.09998737 0.10000109]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[3.1612366e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(7.2791176e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "adopted dalmatian earlier year heard lot cautionary tale special diet could pas trying dog food sadly name well love special occasion food mix half cup dry nasty side effect also like wingaling napa valley offering company high protein work u\n",
            "-----------\n",
            "Input sequence: [[2279 8352 1564   48  731   75 8353 8354  461  171   46 1488  215   21\n",
            "    11 1930  504   40    9  461 1429   11   29  207   43  275  839  342\n",
            "   857   24    2 8355 5791 2006 1368  185  149  361   87  203    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.0831753e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002052 0.09996498 0.10000597 0.10005058 0.10000701 0.10000201\n",
            " 0.09999721 0.09999649 0.09997953 0.09997574], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000205 0.09999649 0.1000006  0.10000505 0.10000069 0.1000002\n",
            " 0.09999972 0.09999965 0.09999795 0.09999757]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.0831753e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.4940913e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "like plockys br like br plockys br mean br taste br healthy br plockys br grab bag br thank plockys\n",
            "-----------\n",
            "Input sequence: [[   2 3619    1    2    1 3619    1  419    1    4    1  107    1 3619\n",
            "     1 1419   16    1  320 3619    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.1798976e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10013958 0.10001332 0.10026933 0.10020421 0.10005401 0.09995377\n",
            " 0.09983162 0.09970611 0.09979162 0.10003647], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10001396 0.10000134 0.10002694 0.10002043 0.1000054  0.09999538\n",
            " 0.09998316 0.09997062 0.09997916 0.10000365]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.1798976e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-7.3218886e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "beef stick honey great combination ole smokies beef stick full flavor adding honey give little twist sweetness put top honey stung ole smokies always favorite friend saddlebag pack perfect football party\n",
            "-----------\n",
            "Input sequence: [[ 638  295  351    8  726 2212 3414  638  295  206    5  576  351   72\n",
            "    26 1365  755  130  305  351 4851 2212 3414  103   58  200 6409   67\n",
            "   110 3214  643    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.9557832e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002067 0.09996462 0.10000581 0.1000508  0.10000683 0.10000224\n",
            " 0.09999744 0.09999652 0.09997956 0.09997554], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000207 0.09999646 0.10000058 0.10000508 0.10000068 0.10000022\n",
            " 0.09999974 0.09999965 0.09999796 0.09999755]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.9557832e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.5033954e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "taste like life saver hard sweet crunchy ring minty flavor pretty much describes crunchy mint shaped like ring\n",
            "-----------\n",
            "Input sequence: [[   4    2  395 2721  116   62  338 2220 3169    5  133   20 5908  338\n",
            "   617 2028    2 2220    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.2469136e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002089 0.09996454 0.10000611 0.1000511  0.10000681 0.10000228\n",
            " 0.09999729 0.09999613 0.0999793  0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000208 0.09999645 0.1000006  0.10000511 0.10000068 0.10000022\n",
            " 0.09999973 0.0999996  0.09999792 0.09999756]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.2469136e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(5.17376e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "new food dog seems adjusted well product thank wish coupon available item\n",
            "-----------\n",
            "Input sequence: [[ 159   11   21  260 3937   40    6  320  265 1307  240  137    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.4450448e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002106 0.09996457 0.10000637 0.10005125 0.1000068  0.1000023\n",
            " 0.09999719 0.09999578 0.09997913 0.09997563], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000021  0.09999646 0.10000064 0.10000512 0.10000068 0.10000023\n",
            " 0.09999972 0.09999957 0.09999791 0.09999757]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.4450448e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-5.629864e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "great size healthy satisfy craving something crisp reasonable calorie wise\n",
            "-----------\n",
            "Input sequence: [[   8  113  107 1283  620   96  336  595   84 1809    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[7.448197e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002124 0.09996448 0.10000661 0.10005151 0.10000678 0.10000231\n",
            " 0.09999705 0.09999544 0.0999789  0.09997563], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000212 0.09999646 0.10000066 0.10000515 0.10000067 0.10000023\n",
            " 0.09999971 0.09999954 0.09999789 0.09999757]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.448197e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.7150052e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "think hot cocoa taste great wife think watery wife big swiss miss drinker know hot cocoa sure buy cost paying k cup sometimes think better buying swiss miss packet use hot water function k cup machine\n",
            "-----------\n",
            "Input sequence: [[  59   38  108    4    8  491   59  752  491  164  812  584  672   68\n",
            "    38  108  123   25  278  971  795   43  456   59   30  158  812  584\n",
            "   285   23   38   39 2536  795   43  465    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.5346359e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002143 0.0999644  0.10000684 0.10005178 0.10000678 0.10000235\n",
            " 0.09999695 0.09999514 0.0999787  0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000214 0.09999644 0.10000069 0.10000518 0.10000068 0.10000023\n",
            " 0.0999997  0.09999952 0.09999787 0.09999756]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.5346359e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.5336532e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "understand dog food full review checkout give dog food star beat science diet purina one use use diamond natural le expensive\n",
            "-----------\n",
            "Input sequence: [[1088   21   11  206   83 9627   72   21   11  183  551 1062  171 1713\n",
            "     7   23   23 1733  144  104  192    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.4489955e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002157 0.09996438 0.10000704 0.10005195 0.10000677 0.10000237\n",
            " 0.09999687 0.09999489 0.09997855 0.09997564], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000215 0.09999644 0.1000007  0.10000519 0.10000068 0.10000025\n",
            " 0.09999969 0.09999949 0.09999786 0.09999757]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.4489955e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.3364566e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "omg thing delicious eater usually ohman liked much may two oops three\n",
            "-----------\n",
            "Input sequence: [[3686   54   70  794  189 7654  262   20  168   79 5509  216    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.6277654e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002167 0.09996441 0.10000721 0.10005203 0.10000675 0.10000238\n",
            " 0.09999679 0.09999466 0.09997844 0.0999757 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000215 0.09999643 0.10000072 0.10000519 0.10000067 0.10000023\n",
            " 0.09999967 0.09999946 0.09999783 0.09999757]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.6277654e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-6.0505845e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "discovered kavli thin cracker paris mark spencer kavli since bread happy moved u find also br br say kavli important part helping keep weight\n",
            "-----------\n",
            "Input sequence: [[  568  1617   407   304  5405  1601 10744  1617    63   233   154  1394\n",
            "    203    31    24     1     1    52  1617   844   387  2130    99   294\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[8.418243e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000218  0.09996434 0.10000737 0.10005223 0.10000675 0.10000239\n",
            " 0.09999671 0.09999444 0.09997829 0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000218 0.09999643 0.10000073 0.10000522 0.10000067 0.10000024\n",
            " 0.09999967 0.09999944 0.09999783 0.09999757]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-8.418243e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.9383651e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "potato enjoy potato chip also enjoy type potato product product really hit mark br br consider snack bag packed chip moderately seasoned full flavor consistency slightly like popcorn cake crisp crunchy puffy distinct potato br br best part bag clock calorie repeat simple calorie snack get full bag chip great content calorie content perfect accompany lunch without feeling guilty eating calorie bag br br personal favorite sea salt vinegar original barbecue flavor sweet smoky salt pepper cheddar sour cream onion flavor standard fair chip adequately evenly seasoned notice difference seasoning one chip br br great product well manufactured treat eat definitely buy future\n",
            "-----------\n",
            "Input sequence: [[  10   24  120  287   69    6    6   18  541 1601    1    1  787   77\n",
            "    16  630   10 5675 1521  206    5  776  393    2  232  167  336  338\n",
            "  4520 1625   69    1    1   22  387   16 8091   84 3281  706   84   77\n",
            "    17  206   16   10    8  476   84  476  110 8092  451   85  930 1760\n",
            "   122   84   16    1    1  938   58  494   76  239  327 1204    5   62\n",
            "  2478   76  314  534  449  224  548    5  704  828   10 4535 4883 1521\n",
            "   805  422  689    7   10    1    1    8    6   40 1982  129   42  138\n",
            "    25  850]]\n",
            "Value estimates: tf.Tensor([[-2.841821e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10003813 0.09997126 0.10004386 0.10007338 0.10001337 0.09999559\n",
            " 0.09997364 0.09995423 0.09995222 0.09998427], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000382 0.09999713 0.1000044  0.10000734 0.10000134 0.09999956\n",
            " 0.09999737 0.09999543 0.09999523 0.09999843]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.2222222202469136\n",
            "Clipped reward: 0.2222222202469136\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.841821e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(6.543616e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "best br year ago used loved moved could find purchased many sauce year trying find flavor recently found world market addicted everyone mentioned great way use br favorite use salad along little dressing eat tasty salad every day without cheese br br sodium mg per tablespoon amount added flavor worth every mg\n",
            "-----------\n",
            "Input sequence: [[  22    1   48  263   49  199 1394   46   31  175   71  117   48  215\n",
            "    31    5  398   50  657  297  966  256 1065    8   65   23    1   58\n",
            "    23  437  448   26  949   42  118  437   90   55   85  310    1    1\n",
            "   350 1516  132  841  173  213    5  188   90 1516    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[4.1630506e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002197 0.09996425 0.10000755 0.10005246 0.10000673 0.10000245\n",
            " 0.09999666 0.09999419 0.09997813 0.09997567], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000022  0.09999643 0.10000075 0.10000525 0.10000067 0.10000025\n",
            " 0.09999966 0.09999942 0.09999781 0.09999757]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-4.1630506e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-9.58576e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "ok finest european chocolate make keurig flavor taste good joined club get lowest possible cost charge join effort quit nice dieting enough chocolate keep track like convenience\n",
            "-----------\n",
            "Input sequence: [[ 479 3864 1509   35   15  288    5    4    3 4711 2011   17 1882 1120\n",
            "   278 1157 6160 1469 2416   82 2072  100   35   99 2752    2  683    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.6636446e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.100022   0.09996424 0.10000758 0.10005248 0.10000669 0.10000247\n",
            " 0.09999666 0.09999413 0.0999781  0.09997567], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000022  0.09999643 0.10000075 0.10000525 0.10000067 0.10000025\n",
            " 0.09999966 0.09999941 0.09999781 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.6636446e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.8306556e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "reading great review optimistically ordered tea problem sinus congestion often winter tried kind remedy little success unfortunately really anything taste ok bearable nothing relieve sinus congestion far thing found helped somewhat vicks personal warm mist humidifier neti xlear\n",
            "-----------\n",
            "Input sequence: [[  670     8    83 11025    93    14   119   886  2731   408  1061    28\n",
            "    210  3610    26  1392   444    18   163     4   479  4055   226  4607\n",
            "    886  2731   126    54    50   921   658 11026   938   998  4246 11027\n",
            "  11028 11029     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[-2.1509145e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002206 0.09996416 0.10000761 0.10005259 0.10000668 0.10000249\n",
            " 0.09999665 0.09999408 0.09997805 0.09997563], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000221 0.09999643 0.10000076 0.10000526 0.10000067 0.10000025\n",
            " 0.09999967 0.09999942 0.09999781 0.09999757]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.1509145e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.952669e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "whole family love sauce use primarily recreate dish maui add wonderful sweet spicy flavor sauce service order spectacular several bottle arrived broken replacement received within day amazon service fast easy reliable love amazon also many recipe look using sauce good go spectaculary coconut milk vegetable chicken shrimp pasta love\n",
            "-----------\n",
            "Input sequence: [[ 139  143    9  117   23 2515 5576  499 5026   78  179   62  246    5\n",
            "   117  420   60 4173  219  172  238  546 1070  229  735   55   32  420\n",
            "   346   89 2367    9   32   24   71  160  184  102  117    3   53 9781\n",
            "   187  114  486  176 2165  374    9    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.322046e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002212 0.09996411 0.10000763 0.10005267 0.10000668 0.10000252\n",
            " 0.09999666 0.09999403 0.09997801 0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000221 0.09999641 0.10000076 0.10000526 0.10000066 0.10000025\n",
            " 0.09999967 0.0999994  0.0999978  0.09999756]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.322046e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.0441408e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "ca believe check ingredient never would bought would known artificial sweetener first cup though got weird taste give wrote problem chemical taste concern health problem may like worth u\n",
            "-----------\n",
            "Input sequence: [[  86  319  892   61   95   13   51   13 1032  373  354   45   43  134\n",
            "    81  766    4   72 2026  119  604    4 1410  289  119  168    2  188\n",
            "   203    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.569026e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002213 0.0999641  0.10000765 0.10005267 0.10000664 0.10000253\n",
            " 0.09999666 0.09999398 0.099978   0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000221 0.09999641 0.10000076 0.10000526 0.10000066 0.10000025\n",
            " 0.09999967 0.09999939 0.0999978  0.09999756]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.569026e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-5.9153945e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "family absolutely love pancake waffle mix texture taste best especially using waffle maker add fruit item mix creative wish price great delivery ca beat recommend everyone\n",
            "-----------\n",
            "Input sequence: [[ 143  300    9   73  180   29  190    4   22  254  102  180  519   78\n",
            "   281  137   29 2663  265   27    8  447   86  551   56  256    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[6.8592553e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002215 0.09996408 0.10000767 0.10005269 0.10000663 0.10000256\n",
            " 0.09999666 0.09999395 0.09997799 0.0999756 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000221 0.0999964  0.10000076 0.10000526 0.10000066 0.10000025\n",
            " 0.09999967 0.09999939 0.0999978  0.09999756]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-6.8592553e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.5793972e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "using agave nectar several month found staple home madhava agave nectar good tasting good buy\n",
            "-----------\n",
            "Input sequence: [[ 102 1309 1670  219  142   50 1151  214 5208 1309 1670    3  218    3\n",
            "    25    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.6280774e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002219 0.09996405 0.10000768 0.10005274 0.10000662 0.10000257\n",
            " 0.09999666 0.09999392 0.09997797 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000222 0.0999964  0.10000077 0.10000528 0.10000066 0.10000026\n",
            " 0.09999967 0.0999994  0.0999978  0.09999756]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.6280774e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.7487868e-07, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "tried product personally dog love aging well getting bit grey bouncy ever year ago\n",
            "-----------\n",
            "Input sequence: [[  28    6  786   21    9 4700   40  271   66 1714 6395   92   48  263\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-6.7342494e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002222 0.09996402 0.10000771 0.1000528  0.10000662 0.10000259\n",
            " 0.09999666 0.09999388 0.09997794 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000223 0.0999964  0.10000078 0.10000528 0.10000067 0.10000026\n",
            " 0.09999967 0.0999994  0.0999978  0.09999756]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[6.7342494e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.5506226e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "brought dipping sauce dumpling egg roll made home taste great think sauce get thai place cause taste exact\n",
            "-----------\n",
            "Input sequence: [[ 991 1464  117 1846  306  912   44  214    4    8   59  117   17  618\n",
            "   404  792    4 1636    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[4.750437e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002224 0.09996402 0.10000772 0.1000528  0.1000066  0.1000026\n",
            " 0.09999666 0.09999386 0.09997794 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000223 0.0999964  0.10000078 0.10000528 0.10000067 0.10000026\n",
            " 0.09999967 0.09999939 0.0999978  0.09999756]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-4.750437e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.0938264e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "excellent candy u limit chocolate intake bar sectioned six piece help portion control make perfect sharing quibble sometimes hard get waxed paper candy quite sticky\n",
            "-----------\n",
            "Input sequence: [[  140   267   203  1424    35   992   337 10465   619   293   247   641\n",
            "    676    15   110  2798  4728   456   116    17 10466   979   267   205\n",
            "   1438     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[-5.127841e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002226 0.09996399 0.10000773 0.10005283 0.10000659 0.10000262\n",
            " 0.09999666 0.09999383 0.09997793 0.09997557], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000223 0.0999964  0.10000078 0.10000528 0.10000066 0.10000026\n",
            " 0.09999967 0.09999939 0.09999779 0.09999756]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[5.127841e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.1807318e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "know got good review yorkshire really like like iams cheaper\n",
            "-----------\n",
            "Input sequence: [[   68    81     3    83 10826    18     2     2  1633   249     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[9.168298e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10004939 0.09997574 0.10006864 0.10008791 0.10001767 0.09999122\n",
            " 0.09995812 0.09992678 0.09993451 0.09999003], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000495 0.09999757 0.10000686 0.10000879 0.10000177 0.09999913\n",
            " 0.09999581 0.09999269 0.09999345 0.099999  ]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-9.168298e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.1110704e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "husband mexican picky tortilla chip absolutely love texture light crispy rather thick crunchy actually usually prefers hearty cruncy chip like el ranchero flavor fantastic thilled bean rice corn base make incredibly flavorful touch onion garlic addition go embarrassing amount never ever like plain chip eat without anything else although particularly amazing fresh salsa highly recommend\n",
            "-----------\n",
            "Input sequence: [[ 195 2216  555 1411   10  300    9  190  196  586  299  563  338  161\n",
            "   189 2114 2276 5175   10    2 2311 7075    5  525 7076  231  181  230\n",
            "  1075   15 1926  432 1213  548  518  679   53 5223  173   95   92    2\n",
            "   334   10   42   85  163  333  318 1006  323  127  659  153   56    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-3.8766086e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10003649 0.0999701  0.10003963 0.10007124 0.10001238 0.09999666\n",
            " 0.09997648 0.09995869 0.09995516 0.09998312], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000365 0.09999701 0.10000397 0.10000712 0.10000124 0.09999967\n",
            " 0.09999765 0.09999587 0.09999552 0.09999831]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[3.8766086e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(8.9262227e-07, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "one thing dog like liver biscotti dog treat make best reward training treat used\n",
            "-----------\n",
            "Input sequence: [[   7   54   21    2 1359 1380   21  129   15   22 2067  976  129   49\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-7.608537e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10005906 0.09997985 0.10009029 0.10010044 0.1000216  0.09998718\n",
            " 0.09994444 0.09990297 0.09991907 0.09999512], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000591 0.09999798 0.10000903 0.10001004 0.10000216 0.09999872\n",
            " 0.09999445 0.0999903  0.09999191 0.09999951]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[7.608537e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.7519365e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "lovely tea rose petal abundant mix brew pot tea raise cup lip full sweet scent rose greets tea perfectly blended balanced color warm luscious want drink every day relaxation sheer enjoyment\n",
            "-----------\n",
            "Input sequence: [[1529   14  800 4684 8890   29  413  685   14 1783   43 2139  206   62\n",
            "  1262  800 8891   14  779 3633 1514  421  998 3899   80   64   90   55\n",
            "  4957 5996 2984    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.2556335e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002236 0.09996395 0.10000785 0.10005297 0.10000657 0.10000263\n",
            " 0.09999661 0.09999367 0.09997781 0.09997557], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000224 0.0999964  0.1000008  0.10000531 0.10000066 0.10000027\n",
            " 0.09999967 0.09999937 0.09999779 0.09999757]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.2556335e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(5.193793e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "huge fan genisoy soy crisp deep sea salted flavor br love crunch texture snack flavor subtle light heavy salty taste greasy lip finger eating also like really indulge feel regret eating many calorie soy crisp fav crunchy treat lt\n",
            "-----------\n",
            "Input sequence: [[ 621  344 3942  388  336  820  494 1109    5    1    9  391  190   77\n",
            "     5  975  196  775  302    4  609 2139 1138  122   24    2   18 3886\n",
            "   156 1600  122   71   84  388  336 2756  338  129 3314    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[7.4793675e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10005551 0.09997831 0.10008231 0.10009583 0.10002013 0.09998869\n",
            " 0.0999495  0.09991172 0.09992476 0.09999324], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000555 0.09999783 0.10000823 0.10000958 0.10000202 0.09999888\n",
            " 0.09999496 0.09999118 0.09999248 0.09999932]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.4793675e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.7221826e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "good stuff eating right sweet basil tomato sauce pasta neat shape cook nicely colorful tasty great al dente\n",
            "-----------\n",
            "Input sequence: [[   3  124  122   98   62 1294  358  117  374 3277  842  405  781 2440\n",
            "   118    8 2861 7666    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.0102173e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002239 0.09996394 0.10000788 0.100053   0.10000657 0.10000265\n",
            " 0.0999966  0.09999362 0.09997779 0.09997558], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000224 0.0999964  0.1000008  0.10000531 0.10000066 0.10000026\n",
            " 0.09999967 0.09999937 0.09999779 0.09999757]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.0102173e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.6286923e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "product great priced nearly twice retail local market dont mind paying little convenience home delivery much\n",
            "-----------\n",
            "Input sequence: [[   6    8  656  691  652 1887  135  297  951  571  971   26  683  214\n",
            "   447   20    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.6954025e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002242 0.09996393 0.10000793 0.10005305 0.10000658 0.10000265\n",
            " 0.09999658 0.09999356 0.09997775 0.09997558], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000224 0.09999639 0.1000008  0.10000531 0.10000065 0.10000026\n",
            " 0.09999965 0.09999936 0.09999777 0.09999755]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.6954025e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.9038114e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "box grove square hot cocoa arrived today tried delicious made big cup mistake happy flavor consistency taste discern little disappointed high sodium content nice fall start chill\n",
            "-----------\n",
            "Input sequence: [[  37  514  474   38  108  238  627   28   70   44  164   43 1315  154\n",
            "     5  776    4 4961   26  257  149  350  476   82  863  539 6143    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-7.701745e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002245 0.09996391 0.10000797 0.10005309 0.10000659 0.10000265\n",
            " 0.09999655 0.09999352 0.09997772 0.09997558], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000225 0.09999639 0.10000081 0.10000531 0.10000066 0.10000027\n",
            " 0.09999966 0.09999936 0.09999778 0.09999757]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[7.701745e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.7733983e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "made purchase based daughter recommendation good promised new waffle iron mix provides u wonderful breakfast add fresh strawberry blueberry top along syrup scrumdiddlyumptous\n",
            "-----------\n",
            "Input sequence: [[  44  148  639  325 1794    3 2541  159  180 1152   29 1232  203  179\n",
            "   417   78  127  682  693  305  448  367 8234    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.924998e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002245 0.09996393 0.10000799 0.10005308 0.10000658 0.10000264\n",
            " 0.09999654 0.09999348 0.09997769 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000224 0.09999639 0.1000008  0.10000531 0.10000065 0.10000026\n",
            " 0.09999964 0.09999934 0.09999776 0.09999755]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.924998e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-9.037626e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "brought bottle one carry pocket home fell love vacation belize couple drop trick pack ton flavor hot overpowers food\n",
            "-----------\n",
            "Input sequence: [[ 991  172    7  441 1390  214 1117    9 1662 7896  268  905 1184   67\n",
            "  1433    5   38 3564   11    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[6.9176895e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002248 0.09996394 0.10000803 0.10005311 0.10000659 0.10000265\n",
            " 0.09999653 0.09999345 0.09997769 0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000224 0.09999639 0.1000008  0.10000531 0.10000065 0.10000026\n",
            " 0.09999964 0.09999934 0.09999776 0.09999755]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-6.9176895e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.5928523e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "received box assorted popchips day ago support weight watcher meal plan absolutely love find fit plan without hesitation recommend variety chip great idea\n",
            "-----------\n",
            "Input sequence: [[ 229   37 2129  375   55  263 1354  294  854  248  596  300    9   31\n",
            "   733  596   85 5655   56  157   10    8  434    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-7.3510355e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000225  0.09996391 0.10000806 0.10005315 0.10000659 0.10000265\n",
            " 0.09999651 0.09999342 0.09997765 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000081 0.10000532 0.10000066 0.10000027\n",
            " 0.09999966 0.09999935 0.09999777 0.09999757]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[7.3510355e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.6926439e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "little skeptical ordering teriyaki stick version based couple review happy soft stick someone said nice crunch bit teriyaki milder others ordered smokey called ole smokeys get greasy mouth feel someone said pleasant tasting taste worth rating could based individual taste\n",
            "-----------\n",
            "Input sequence: [[  26 1720  259 3038  295  365  639  268   83  154  364  295  400  193\n",
            "    82  391   66 3038 1884  225   93 2282  626 2212 4850   17  609  353\n",
            "   156  400  193  827  218    4  188 1139   46  639  677    4    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-4.1071908e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002252 0.09996392 0.10000809 0.10005317 0.10000659 0.10000265\n",
            " 0.09999649 0.09999338 0.09997763 0.0999756 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000081 0.10000532 0.10000066 0.10000027\n",
            " 0.09999966 0.09999935 0.09999777 0.09999757]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[4.1071908e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(9.457174e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "turned fantastic little sweeter expecting still great may even consider dessert wine nice using cornucopia kit come complete supply need cork label topper etc use distilled water making wine dont want chance anything else always turned great give try farmwiner\n",
            "-----------\n",
            "Input sequence: [[  780   525    26  1372   705    74     8   168    34   787   837   654\n",
            "     82   102  3200   718    97  1453  1097   101  3956   394  4933   418\n",
            "     23  4578    39   223   654   951    80   744   163   333   103   780\n",
            "      8    72    36 11087     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[8.392772e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000258  0.09996537 0.10001546 0.10005739 0.10000793 0.10000126\n",
            " 0.09999182 0.09998525 0.09997237 0.09997737], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000258 0.09999654 0.10000154 0.10000574 0.10000079 0.10000013\n",
            " 0.09999918 0.09999853 0.09999724 0.09999774]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-8.392772e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.9325e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "shipping prompt product fully expected helped successful mama agata lemon cake flour failed\n",
            "-----------\n",
            "Input sequence: [[ 146 2190    6 1660  467  921 4510 9658 9659  665  167  283 4563    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[6.798766e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002254 0.09996393 0.10000812 0.10005318 0.10000659 0.10000264\n",
            " 0.09999648 0.09999333 0.09997761 0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000081 0.10000532 0.10000066 0.10000027\n",
            " 0.09999964 0.09999934 0.09999777 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-6.798766e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.5654692e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "received gift along homemade graham cracker husband become addicted love thing like lemon meringue pie adore luscious lemony spread graham pound cake etc thin layer delicious confection enlivens taste bud explosion flavor highly recommend product looking special treat\n",
            "-----------\n",
            "Input sequence: [[ 229  251  448  885 2177  304  195  684  966    9   54    2  665 8916\n",
            "   909 2051 3899 5001  898 2177  345  167  418  407 1711   70 3415 8917\n",
            "     4 1039 5481    5  153   56    6  152  461  129    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.4564708e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002257 0.09996389 0.10000814 0.10005324 0.10000659 0.10000264\n",
            " 0.09999646 0.09999329 0.09997755 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.09999639 0.10000081 0.10000532 0.10000066 0.10000026\n",
            " 0.09999964 0.09999932 0.09999776 0.09999756]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.4564708e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.3536693e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "made according package direction added cup mini chocolate chip awesome took longer cook box say maybe chocolate chip either way great definitely make\n",
            "-----------\n",
            "Input sequence: [[  44 1214  151 1059  213   43  867   35   10  424  330  397  405   37\n",
            "    52  258   35   10  286   65    8  138   15    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.0437786e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002942 0.0999669  0.10002356 0.1000621  0.1000094  0.09999976\n",
            " 0.0999867  0.09997632 0.09996659 0.09997927], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000294 0.09999669 0.10000235 0.10000621 0.10000094 0.09999997\n",
            " 0.09999867 0.09999764 0.09999666 0.09999792]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.0437786e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.4033902e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "mix first month finicky stomach eats fast drink fast eats anything routine would bring back also would eat nibble time month old came u severe diarrhea vet food fix either would eat anything everything let within day dog harmony farm fasting quick switch dog digestive issue gone oldest finicky eater healthily eating meal without pause hesitation youngest solid regular bathroom break able relax water intake result br purchase local grocery store hannaford ny price ingredient result ca beat\n",
            "-----------\n",
            "Input sequence: [[  29   45  142 1757  523  741  346   64  346  741  163 2587   13  875\n",
            "   136   24   13   42 3246   19  142  111  174  203 1773 1863  675   11\n",
            "  1192  286   13   42  163  276  313  735   55   21 1016  615 7952  340\n",
            "   926   21 1144  308  565 1762 1757  794 7953  122  248   85 7954 5655\n",
            "  2110 1118   91 3145  760  252 4494   39  992  402    1  148  135  178\n",
            "    41 7955 2146   27   61  402   86  551    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.01766655e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002257 0.09996395 0.10000817 0.10005321 0.10000659 0.10000264\n",
            " 0.09999643 0.09999326 0.09997757 0.09997563], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000082 0.10000532 0.10000066 0.10000027\n",
            " 0.09999964 0.09999932 0.09999776 0.09999757]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.01766655e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.3432534e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "first time trying wabash valley farm amish country baby br br pro okay nice mild nutty flavor hull pronounced amish baby white br br con tends briskly pop fact burned several pan popping tricky found microwave often work better pan popping mentioned hull much noticeable amish baby white br br purchased bag use wo ordering next time drive long distance nearest amish store\n",
            "-----------\n",
            "Input sequence: [[  45   19  215 2549 2006  615 1701  963  242    1    1 1003  602   82\n",
            "   588 2068    5 1316 2744 1701  242  198    1    1 1001 2086 8943  329\n",
            "   245 2155  219  942 1313 3845   50  727  408   87   30  942 1313 1065\n",
            "  1316   20 3206 1701  242  198    1    1  175   16   23  228  259  317\n",
            "    19 1710  155 3905 3380 1701   41    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.2761358e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002258 0.09996393 0.1000082  0.10005324 0.10000659 0.10000263\n",
            " 0.09999643 0.09999323 0.09997754 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000082 0.10000532 0.10000066 0.10000026\n",
            " 0.09999964 0.09999932 0.09999776 0.09999756]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.2761358e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-5.240992e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "looking alternative green white iced tea powder realized lipton brand contained sucralose come unsweetened version found stash tea online decided try using stevia sweetener bought lemon ginger br br comparison think lipton powdered iced tea used drinking like sweetened colored fruity adult different get used green tea taste upset stomach little drink hot tea usually drink white tea like mild taste br br tried using half third packet ounce water worked better would probably like white tea better stash make white tea iced tea powder mix anyway hope get used taste since right like really good deal far price\n",
            "-----------\n",
            "Input sequence: [[ 152  303  125  198  481   14  227 1181 2121   33 1575  880   97 1685\n",
            "   365   50  804   14  378  243   36  102  415  354   51  665  493    1\n",
            "     1 1095   59 2121  961  481   14   49  277    2 1108 1800 2431  783\n",
            "   106   17   49  125   14    4 1263  523   26   64   38   14  189   64\n",
            "   198   14    2  588    4    1    1   28  102  207 1153  285  380   39\n",
            "   673   30   13  208    2  198   14   30  804   15  198   14  481   14\n",
            "   227   29  730  428   17   49    4   63   98    2   18    3  235  126\n",
            "    27    0]]\n",
            "Value estimates: tf.Tensor([[-9.913967e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000226  0.09996391 0.10000821 0.10005329 0.1000066  0.10000264\n",
            " 0.09999643 0.09999322 0.09997752 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000225 0.09999639 0.10000081 0.10000532 0.10000066 0.10000026\n",
            " 0.09999964 0.09999932 0.09999774 0.09999756]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[9.913967e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.2827851e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "bought water college first week felt bad using roommate water time state away home ordered water delicious complaint bottle really well felt really drinking water huge plastic br br ask roommate buy water go home weekend give run walmart get case water bottle yay br br sometimes still think water longing sip coffee tea say would much better talking rain br br one college student battle deliciousness\n",
            "-----------\n",
            "Input sequence: [[  51   39 2169   45  204  774  105  102 2921   39   19  716  197  214\n",
            "    93   39   70  629  172   18   40  774   18  277   39  621  362    1\n",
            "     1  824 2921   25   39   53  214 1736   72  377 1094   17  147   39\n",
            "   172 2625    1    1  456   74   59   39 5802  997   12   14   52   13\n",
            "    20   30 1666 2626    1    1    7 2169 2906 3792 4248    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-6.153177e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002259 0.09996392 0.10000822 0.10005327 0.1000066  0.10000263\n",
            " 0.09999642 0.0999932  0.09997751 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000225 0.09999639 0.10000082 0.10000532 0.10000066 0.10000026\n",
            " 0.09999964 0.09999932 0.09999774 0.09999756]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[6.153177e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.4168253e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "like brew cocoa coffee nice mocha dark chocolate flavor quite nice especially mixed double black diamond coffee though best good price right compared brand\n",
            "-----------\n",
            "Input sequence: [[   2  413  108   12   82 2079  212   35    5  205   82  254  471 1009\n",
            "   269 1733   12  134   22    3   27   98  529   33    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.6233567e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002258 0.09996396 0.10000823 0.10005324 0.10000659 0.10000264\n",
            " 0.09999642 0.09999319 0.09997753 0.09997565], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000082 0.10000532 0.10000066 0.10000026\n",
            " 0.09999964 0.09999932 0.09999776 0.09999757]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.6233567e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.737891e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "got pack pretty good deal healthy baked chip usually buy taste great im officially br br pretty much sound like chip popped instead baked air ounce bag slightly ounches baked lay bag br br good buy get good deal like\n",
            "-----------\n",
            "Input sequence: [[  81   67  133    3  235  107  309   10  189   25    4    8 1489 8023\n",
            "     1    1  133   20  530    2   10  984  222  309  655  380   16  393\n",
            "  8024  309  747   16    1    1    3   25   17    3  235    2    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[4.039179e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10008552 0.09999117 0.10014955 0.10013464 0.10003231 0.09997615\n",
            " 0.09990701 0.09983774 0.09987684 0.10000913], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000855 0.09999911 0.10001495 0.10001346 0.10000324 0.09999762\n",
            " 0.0999907  0.09998378 0.09998769 0.10000091]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.39999999680000003\n",
            "Clipped reward: 0.39999999680000003\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-4.039179e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-9.300539e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "cooky tiny broken piece useless upon complaint second mailing arrived several week later cooky crumb cooky packed box pitiful single air bubble gave feedback expected effort improve packing packaging useless cooky enjoyed highlander past disappointment big waste money\n",
            "-----------\n",
            "Input sequence: [[ 141  562  546  293 3274  934  629  332 5393  238  219  204  624  141\n",
            "  1260  141  630   37 7433  335  655 1332  279 2511  467 1469 1873 1443\n",
            "   291 3274  141  468 3273  500 1300  164  603  217    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.8940007e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002265 0.0999639  0.10000832 0.10005337 0.10000661 0.10000262\n",
            " 0.09999636 0.09999309 0.09997744 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000084 0.10000534 0.10000066 0.10000027\n",
            " 0.09999964 0.09999932 0.09999775 0.09999757]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.8940007e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.3611337e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "everyone tried exclusive energy surprised unique ability pleasantly refresh br hope become readily available\n",
            "-----------\n",
            "Input sequence: [[ 256   28 6389  359  460  715 2063 1080 5945    1  428  684 1656  240\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.4128402e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10003687 0.0999701  0.10004023 0.10007172 0.10001243 0.09999665\n",
            " 0.09997616 0.09995795 0.09995469 0.09998322], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000369 0.09999701 0.10000402 0.10000717 0.10000124 0.09999966\n",
            " 0.09999762 0.0999958  0.09999546 0.09999833]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.4128402e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-7.858344e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "hot chocolate good right amount milk chocolate flavor price good deal worth\n",
            "-----------\n",
            "Input sequence: [[ 38  35   3  98 173 114  35   5  27   3 235 188   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Value estimates: tf.Tensor([[9.7165075e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002268 0.09996398 0.10000841 0.10005336 0.10000662 0.10000259\n",
            " 0.09999628 0.09999297 0.09997738 0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000084 0.10000534 0.10000066 0.10000026\n",
            " 0.09999964 0.0999993  0.09999774 0.09999758]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-9.7165075e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.2372991e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love popchips best individual serving bag flavor great taste excellent daughter grandson love barbeque found buying amazon cheaper amazon offer bigger bag also watch could eat whole bag\n",
            "-----------\n",
            "Input sequence: [[   9  375   22  677  255   16    5    8    4  140  325 1752    9 1236\n",
            "    50  158   32  249   32  888  702   16   24 1019   46   42  139   16\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.155076e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002272 0.09996396 0.10000848 0.10005342 0.10000664 0.10000259\n",
            " 0.09999625 0.09999291 0.09997734 0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000084 0.10000534 0.10000066 0.10000026\n",
            " 0.09999962 0.09999929 0.09999774 0.09999757]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.155076e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-7.2648213e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "reason ordered pop chip store regular salt vinegar barbeque love sour cream onion one actually love great calorie bag would able stop eating\n",
            "-----------\n",
            "Input sequence: [[ 372   93  329   10   41   91   76  239 1236    9  449  224  548    7\n",
            "   161    9    8   84   16   13  252  587  122    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.6775579e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002276 0.09996395 0.10000853 0.10005349 0.10000665 0.10000258\n",
            " 0.09999622 0.09999285 0.09997728 0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.09999639 0.10000084 0.10000534 0.10000066 0.10000025\n",
            " 0.09999962 0.09999928 0.09999771 0.09999757]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.6775579e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.862748e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "found product local walmart trying vainly find bread liked gluten free stay away brand opinion br br gluten free week seriously craving bread product made pancake morning product wow tasty light needed thin bit spread correctly first real carb product bread like eaten week needle say ate many carb headache br br seriously though product used moderation may help miss gluten product quite much look forward making bisquits recipe br way go product strike home run gluten free market\n",
            "-----------\n",
            "Input sequence: [[   50     6   135  1094   215 10305    31   233   262   115    57   488\n",
            "    197    33   484     1     1   115    57   204   970   620   233     6\n",
            "     44    73   326     6   580   118   196   416   407    66   898  3008\n",
            "     45   177   943     6   233     2   501   204  1530    52   458    71\n",
            "    943  1563     1     1   970   134     6    49  3583   168   247   584\n",
            "    115     6   205    20   184   721   223  4342   160     1    65    53\n",
            "      6  4279   214   377   115    57   297     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[7.691218e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002276 0.099964   0.10000857 0.10005347 0.10000665 0.10000258\n",
            " 0.09999619 0.0999928  0.09997727 0.09997571], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000084 0.10000534 0.10000066 0.10000025\n",
            " 0.09999962 0.09999928 0.09999772 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.691218e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.7709624e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "daughter autism craves hot spice pungent food absolute favorite chip call sour chip want lunch time love crispy kettle way cooked\n",
            "-----------\n",
            "Input sequence: [[ 325 3587 5166   38  381 3160   11 1237   58   10  573  449   10   80\n",
            "   451   19    9  586  191   65  608    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[9.701053e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002278 0.09996401 0.10000861 0.10005349 0.10000665 0.10000257\n",
            " 0.09999617 0.09999277 0.09997724 0.09997572], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000086 0.10000534 0.10000066 0.10000025\n",
            " 0.09999961 0.09999927 0.09999771 0.09999757]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-9.701053e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.2337406e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "soup lack key ingredient make canned clam chowder great partially hydrogenated vegetable oil dehydrated potato modified starch kind hydrolyzed corn gluten msg potassium chloride sodium phosphate disodium inosinate disodium guanylate succinic acid good classic new england clam chowder without classic ingredient br br instead first ingredient listed clam next telling got butter oh br br serious note bar harbor make good tasting clam chowder first list ingredient came snow campbell condensed new england clam chowder bar harbor stuff worth\n",
            "-----------\n",
            "Input sequence: [[ 331  952 2586   61   15  464  431  636    8 1413 1826  486  128 2543\n",
            "    69 1747 1448  210 9000  230  115 1011  751 2074  350 1954 2370 5799\n",
            "  2370 5798 9001  556    3 1224  159 1591  431  636   85 1224   61    1\n",
            "     1  222   45   61  896  431  317 2284   81  280  645    1    1 1541\n",
            "   579  337 1480   15    3  218  431  636   45  454   61  174 2003 4692\n",
            "  6019  159 1591  431  636  337 1480  124  188    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-8.261615e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10003337 0.09996855 0.10003232 0.10006719 0.10001098 0.09999813\n",
            " 0.09998116 0.09996665 0.09996033 0.09998134], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000333 0.09999685 0.10000324 0.10000671 0.1000011  0.09999982\n",
            " 0.09999812 0.09999666 0.09999602 0.09999813]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[8.261615e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.9023142e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "pocky incredibly good snack impressed asia packaging stupidly ordered something easy melt chocolate dead heat summer top package dessert pocky ordered degree weather melted liquid goo course expecting pocky box melted away took special care put pocky box reading protect heat pocky arriving perfect condition well stick together bit love asia anything\n",
            "-----------\n",
            "Input sequence: [[1208 1926    3   77  717 4312  291 7276   93   96   89 1187   35 2315\n",
            "   554  650  305  151  837 1208   93 2037 1495 1025  767 2683  410  705\n",
            "  1208   37 1025  197  330  461  412  130 1208   37  670 3241  554 1208\n",
            "  3143  110  710   40  295  593   66    9 4312  163    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-7.063249e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10004494 0.09997357 0.10005835 0.10008218 0.10001572 0.09999325\n",
            " 0.09996469 0.09993801 0.09994178 0.0999875 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000449 0.09999736 0.10000584 0.10000822 0.10000157 0.09999933\n",
            " 0.09999647 0.09999381 0.09999418 0.09999876]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[7.063249e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.6263783e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "jelly bean wonderful smaller regular jelly bean take away flavor would recommand anyone\n",
            "-----------\n",
            "Input sequence: [[ 904  231  179  453   91  904  231  112  197    5   13 7832  328    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[7.820501e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002279 0.099964   0.10000864 0.10005351 0.10000666 0.10000257\n",
            " 0.09999615 0.09999273 0.09997722 0.09997572], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.09999639 0.10000086 0.10000534 0.10000066 0.10000025\n",
            " 0.09999961 0.09999926 0.09999771 0.09999757]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.820501e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.8007308e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "hard find wintergreen small sugar free store red small peppermint common flavor wintergreen refreshing absolutely delicious driving cross country someone cut turn daughter hand say wintergreen pull one put hand right world\n",
            "-----------\n",
            "Input sequence: [[ 116   31 2608  109   47   57   41  396  109  540 1298    5 2608  728\n",
            "   300   70 3475 2826  963  400  384  605  325  348   52 2608 1512    7\n",
            "   130  348   98  657    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[7.266407e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002279 0.099964   0.10000862 0.10005351 0.10000666 0.10000257\n",
            " 0.09999616 0.09999275 0.09997723 0.09997572], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.09999639 0.10000084 0.10000534 0.10000066 0.10000025\n",
            " 0.09999961 0.09999926 0.09999771 0.09999757]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.266407e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.6731468e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "price great like taste coffee pretty picky coffee love drink strong one produce acidic coffee made strong make thin taste okay slight acidic taste like coffee really depending personal taste coffee like drink coffee strong dislike acidic taste last\n",
            "-----------\n",
            "Input sequence: [[  27    8    2    4   12  133  555   12    9   64  145    7 1076 1754\n",
            "    12   44  145   15  407    4  602 1186 1754    4    2   12   18 1341\n",
            "   938    4   12    2   64   12  145 1821 1754    4  182    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-7.4627023e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10005952 0.09997988 0.10009108 0.10010104 0.10002168 0.09998713\n",
            " 0.099944   0.09990202 0.09991846 0.09999526], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000595 0.09999798 0.10000911 0.1000101  0.10000216 0.09999871\n",
            " 0.09999439 0.0999902  0.09999184 0.09999952]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[7.4627023e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.7183565e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "first peanut free product bought son thought tasty kid liked reason think strawberry bar love soft texture non crumbly state make clean car ride since like apple chocolate bar best berry always left last amazon wonderful price wish could subscribe item\n",
            "-----------\n",
            "Input sequence: [[  45  324   57    6   51  274  131  118  202  262  372   59  682  337\n",
            "     9  364  190 1808 1836  716   15  533 1162 1861   63    2  455   35\n",
            "   337   22  907  103  502  182   32  179   27  265   46  429  137    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-8.200451e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002633 0.09996549 0.10001656 0.10005812 0.1000081  0.10000108\n",
            " 0.09999114 0.09998401 0.09997156 0.09997758], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000263 0.09999655 0.10000166 0.10000581 0.10000081 0.10000011\n",
            " 0.09999911 0.0999984  0.09999716 0.09999776]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[8.200451e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.8882303e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "melitta riviera sunset decaffeinated ground coffee turned good basic coffee bitter mellow brew taste like real coffee morning almond milk stevia pinch cinnamon though bad night even know could handle coffee delicious easy morning tummy besides brewing alone get nice decaffeinated coffee drinking especially winter mixing regular coffee various blend depending need br br packaging practical easy grind good automatic coffeemaker buy one\n",
            "-----------\n",
            "Input sequence: [[ 430 1180 1147 1176  379   12  780    3 1355   12  261 1533  413    4\n",
            "     2  177   12  326  640  114  415 2035  508  134  105  566   34   68\n",
            "    46 1487   12   70   89  326 1373 1442  870 1058   17   82 1176   12\n",
            "   277  254 1061 1026   91   12  944  221 1341  101    1    1  291 3085\n",
            "    89  739    3 2521 3692   25    7    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[6.7149354e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002272 0.09996396 0.10000846 0.10005341 0.10000663 0.1000026\n",
            " 0.09999627 0.09999292 0.09997735 0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000084 0.10000534 0.10000066 0.10000026\n",
            " 0.09999962 0.09999929 0.09999774 0.09999757]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-6.7149354e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.5461665e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "amazon suggestion star review like said gave star review spicy thai chip chip perfect people enjoy spicy chip whose taste bud appreciate added sweetness ginger flavor thing really dislike chip along rest flavor serving size half bag really eat half save rest later\n",
            "-----------\n",
            "Input sequence: [[  32 2462  183   83    2  193  279  183   83  246  618   10   10  110\n",
            "   170  120  246   10 2088    4 1039 1230  213  755  493    5   54   18\n",
            "  1821   10  448  549    5  255  113  207   16   18   42  207  241  549\n",
            "   624    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.0634014e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002268 0.09996395 0.10000839 0.10005337 0.10000661 0.10000262\n",
            " 0.0999963  0.099993   0.09997739 0.09997566], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000084 0.10000534 0.10000066 0.10000027\n",
            " 0.09999964 0.0999993  0.09999774 0.09999757]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.4999999962500001\n",
            "Clipped reward: 0.4999999962500001\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.0634014e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.448561e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "kellogg muselix delicious delivery http kellogg crispy blend mueslix raisin date almond unit pack\n",
            "-----------\n",
            "Input sequence: [[1589 7393   70  447  282 1589  586  221 1839 1555  470  640 1040   67\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.134722e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002267 0.0999639  0.10000835 0.10005338 0.10000661 0.10000262\n",
            " 0.09999634 0.09999306 0.09997742 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000084 0.10000534 0.10000066 0.10000026\n",
            " 0.09999964 0.09999932 0.09999774 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.134722e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.6128067e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "addicted candy try order another batch awhile candy eat ride home work traffic keep calm\n",
            "-----------\n",
            "Input sequence: [[ 966  267   36   60  194  577 1997  267   42 1861  214   87 9854   99\n",
            "  3449    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-4.85263e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000534  0.09997722 0.10007733 0.10009311 0.10001916 0.0999897\n",
            " 0.09995268 0.09991713 0.09992825 0.099992  ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000534 0.09999772 0.10000774 0.10000931 0.10000192 0.09999897\n",
            " 0.09999526 0.09999171 0.09999283 0.0999992 ]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[4.85263e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.1173618e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "wanted love despite sugar free calorie per pump opinion need three pump add enough flavor iced vanilla latte going calorie count favorable would however say think brand bit sweet calorie count overly important give go may looking side note calorie count unimportant recommend coconut cream flavor http amoretti premium coconut cream syrup delicious\n",
            "-----------\n",
            "Input sequence: [[ 264    9 1093   47   57   84  132 2773  484  101  216 2773   78  100\n",
            "     5  481  440 1765  162   84  874 2857   13  121   52   59   33   66\n",
            "    62   84  874  903  844   72   53  168  152  342  579   84  874 8912\n",
            "    56  187  224    5  282 8913 1159  187  224  367   70    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[6.665615e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000226  0.09996391 0.1000082  0.10005327 0.10000657 0.10000265\n",
            " 0.09999643 0.0999932  0.09997753 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.09999639 0.10000081 0.10000532 0.10000066 0.10000026\n",
            " 0.09999964 0.09999932 0.09999774 0.09999756]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-6.665615e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.5348103e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "year back prompted death one dog due inoperable brain tumor switched dog food without corn convinced right wrong animal died needlessly usage steriods prescribed cure constant ear infection believe right wrong recurring ear infection caused allergy corn turned main ingredient food sorry get soapbox address issue hand found food accident type store weight loss formula turn dog love seen spunky full energy got coon hound two jack russell mine bounce wall kind mine mellow laid back kinda dude gobble stuff seem stay full begging kitchen normal everyone skin seems smoother eye brighter heck think go bowl say looking good quality dog food one disappointed\n",
            "-----------\n",
            "Input sequence: [[   7   21  466 7919 3514 7920  720   21   11   85  230 2711   98  478\n",
            "   807 2993 7921 5181 7922 5636 2706 2974 1369 1639  319   98  478 3459\n",
            "  1369 1639 1842  427  230  780  890   61   11 1123   17 7923 2699  308\n",
            "   348   50   11 2472  287   41  294 1651  392  605   21    9  734 7924\n",
            "   206  359   81 7925 5637   79 1066 2578  581 7926 4496  210  581 1533\n",
            "  5638  136 1791 3697 2502  124  321  488  206 4497  762  538  256  567\n",
            "   260 1787 1160 3518 2346   59   53  536   52  152    3   88   21   11\n",
            "     7  257]]\n",
            "Value estimates: tf.Tensor([[7.3187875e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10008112 0.09998924 0.10013966 0.10012896 0.10003049 0.099978\n",
            " 0.09991325 0.09984858 0.09988385 0.10000677], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000811 0.09999891 0.10001396 0.10001289 0.10000305 0.0999978\n",
            " 0.09999133 0.09998485 0.09998839 0.10000068]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.3187875e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.6852082e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "better canned clam chowder bookbinder one come mind buy one preservative long list ingredient choice limited one add half milk pat butter along extra sea salt longer gently heated simmered boiled let flavor mingle better becomes clam potato would improve ingredient skimpy\n",
            "-----------\n",
            "Input sequence: [[  30  464  431  636 6016    7   97  571   25    7 1188  155  454   61\n",
            "   341 1631    7   78  207  114 4691  280  448  273  494   76  397 3103\n",
            "  1852 6017 4652  313    5 6018   30 2390  431   69   13 1873   61 4250\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-9.469904e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002261 0.09996388 0.10000817 0.10005328 0.10000657 0.10000266\n",
            " 0.09999646 0.09999325 0.09997755 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.09999639 0.10000081 0.10000532 0.10000065 0.10000026\n",
            " 0.09999964 0.09999932 0.09999774 0.09999755]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[9.469904e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.180535e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "popcorn good cant believe difference popcorn regular stuff story good purchase\n",
            "-----------\n",
            "Input sequence: [[ 232    3 1397  319  422  232   91  124 1482    3  148    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.2768877e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002261 0.09996389 0.10000819 0.10005328 0.10000657 0.10000266\n",
            " 0.09999645 0.09999322 0.09997754 0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.09999639 0.10000081 0.10000532 0.10000065 0.10000026\n",
            " 0.09999964 0.09999932 0.09999774 0.09999756]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.2768877e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(5.2427326e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "small chocolate cup specialty party item never able find past wanted amazon provides link used commonly called jello shot provide solid edible alternative small paper cup\n",
            "-----------\n",
            "Input sequence: [[ 109   35   43 2325  643  137   95  252   31  500  264   32 1232 2174\n",
            "    49 3443  626 2597  528 1536 1118 1128  303  109  979   43    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[4.348286e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000226  0.09996391 0.10000821 0.10005327 0.10000658 0.10000265\n",
            " 0.09999643 0.09999321 0.09997753 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.09999639 0.10000081 0.10000532 0.10000066 0.10000026\n",
            " 0.09999964 0.09999932 0.09999774 0.09999756]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-4.348286e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.001228e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "find difficult find black tea united state decent quality love pg tip brew nice rich reasonably priced\n",
            "-----------\n",
            "Input sequence: [[  31  552   31  269   14 2084  716  632   88    9 2779 1207  413   82\n",
            "   298 1243  656    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[5.995597e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002261 0.09996392 0.10000823 0.10005328 0.10000657 0.10000265\n",
            " 0.09999641 0.09999318 0.09997751 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000083 0.10000533 0.10000066 0.10000027\n",
            " 0.09999964 0.09999932 0.09999776 0.09999757]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-5.995597e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.38053365e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "admit fully expected dislike product approached dismissive attitude something trendy ca good right well wrong one coconut water refreshing delicious barely sweet really wonderful stuff hint pineapple add little bit acidity enhances basic taste water bet would make great summer drink one get tot try problem stock ca get\n",
            "-----------\n",
            "Input sequence: [[ 931 1660  467 1821    6 8659 8660 4218   96 4587   86    3   98   40\n",
            "   478    7  187   39  728   70 1221   62   18  179  124  700  352   78\n",
            "    26   66 2192 3028 1355    4   39 2270   13   15    8  650   64    7\n",
            "    17 5489   36  119  543   86   17    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-4.742752e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002477 0.09996482 0.10001306 0.1000561  0.10000747 0.10000174\n",
            " 0.09999336 0.09998785 0.09997405 0.09997675], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000248 0.09999648 0.10000131 0.1000056  0.10000075 0.10000017\n",
            " 0.09999933 0.09999879 0.09999741 0.09999767]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[4.742752e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.0920614e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "also bought two gift returning reason others unacceptable packaging unless already tried product nothing make want try assumed big mistake would kind packaging really sad product great\n",
            "-----------\n",
            "Input sequence: [[   24    51    79   251  2718   372   225  3133   291   547   537    28\n",
            "      6   226    15    80    36 10686   164  1315    13   210   291    18\n",
            "   1938     6     8     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[-1.039914e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002264 0.0999639  0.10000826 0.10005334 0.1000066  0.10000264\n",
            " 0.0999964  0.09999314 0.09997748 0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.09999638 0.10000083 0.10000533 0.10000066 0.10000026\n",
            " 0.09999964 0.09999931 0.09999775 0.09999756]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.039914e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.3945011e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "struggle giving even star thankful substitute condition need low acid coffee however admit taste like burnt coffee someone else put peets starbucks taste flavor leaf mouth done something think ever get used br br update father law would like say one like put mound creamer sugar coffee apparently notice difference taste brand another hope help\n",
            "-----------\n",
            "Input sequence: [[3347  600   34  183 2015  560  710  101  186  556   12  121  931    4\n",
            "     2 1140   12  400  333  130 3157  550    4    5  463  353  521   96\n",
            "    59   92   17   49    1    1 1031 1483 2109   13    2   52    7    2\n",
            "   130 4705  845   47   12 1320  805  422    4   33  194  428  247    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.2137902e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002263 0.09996393 0.10000827 0.1000533  0.1000066  0.10000265\n",
            " 0.0999964  0.09999313 0.09997749 0.09997564], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000083 0.10000533 0.10000066 0.10000027\n",
            " 0.09999964 0.09999932 0.09999775 0.09999757]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.2137902e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.7948403e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "got melted package completely destroyed stuck inside wrapper would think going ship chocolate summer time would pack something cold happy love candy peeled inside wrapper good\n",
            "-----------\n",
            "Input sequence: [[  81 1025  151  653 5071  802  472 1081   13   59  162  823   35  650\n",
            "    19   13   67   96  469  154    9  267 3576  472 1081    3    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.1609559e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002264 0.09996392 0.10000828 0.10005332 0.10000659 0.10000264\n",
            " 0.09999639 0.09999312 0.09997747 0.09997563], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000083 0.10000533 0.10000066 0.10000026\n",
            " 0.09999964 0.09999931 0.09999775 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.1609559e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.6732014e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love use empty container purse desk suitcase also line felt keep earring perfect little size disguise small valuable traveling love mint tiny powerful without burning mouth\n",
            "-----------\n",
            "Input sequence: [[   9   23 1252  452 1510 1449 4976   24  477  774   99 6600  110   26\n",
            "   113 4977  109 3474 2236    9  617  562 2600   85 1990  353    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[6.9586986e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002265 0.09996392 0.10000829 0.10005334 0.1000066  0.10000264\n",
            " 0.09999638 0.09999311 0.09997746 0.09997563], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000083 0.10000533 0.10000066 0.10000026\n",
            " 0.09999964 0.09999931 0.09999774 0.09999756]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-6.9586986e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.6022993e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "delighted discover coffee half acid regular brand served guest acid reflux problem enjoyed cuppa reported felt fine afterwards great coffee pantry guest stock discerning find taste starbucks dunkin donut simply harsh also loved charming packaging\n",
            "-----------\n",
            "Input sequence: [[1588 1726   12  207  556   91   33  815  945  556 2238  119  468 6139\n",
            "  2533  774  253 1721    8   12 1493  945  543 4746   31    4  550 2075\n",
            "  1042  583 2895   24  199 3245  291    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-4.8064708e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002265 0.0999639  0.1000083  0.10005335 0.1000066  0.10000262\n",
            " 0.09999637 0.09999309 0.09997744 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.09999638 0.10000083 0.10000533 0.10000066 0.10000026\n",
            " 0.09999964 0.09999931 0.09999774 0.09999756]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[4.8064708e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.1067331e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "excellent tea flavorful cinnamon fresh powerful overall slightly sweet without needing sugar excellent milk straight\n",
            "-----------\n",
            "Input sequence: [[ 140   14  432  508  127 2600  414  393   62   85 2519   47  140  114\n",
            "  1012    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.767919e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002266 0.09996393 0.10000831 0.10005335 0.1000066  0.10000264\n",
            " 0.09999637 0.09999309 0.09997746 0.09997564], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000083 0.10000533 0.10000066 0.10000026\n",
            " 0.09999964 0.09999931 0.09999774 0.09999756]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.767919e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.070781e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "ordered east coast supplier even shipped bag frozen water dark chocolate coating turned light live west coast seller ca got snicker couple day instead br shipping cost le shipped via post instead via br lowest price paid candy best quality\n",
            "-----------\n",
            "Input sequence: [[  93 3228 2999 1989   34  382   16  923   39  212   35 1732  780  196\n",
            "   527 3279 2999  698   86   81 4776  268   55  222    1  146  278  104\n",
            "   382 1265  712  222 1265    1 1882   27  749  267   22   88    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.8989598e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002265 0.09996391 0.10000832 0.10005334 0.1000066  0.10000263\n",
            " 0.09999636 0.09999308 0.09997743 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000084 0.10000534 0.10000066 0.10000027\n",
            " 0.09999964 0.09999932 0.09999775 0.09999757]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.8989598e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(6.675102e-07, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "flavor mild tried brewing longer using cooler water temp flavor almost nonexistant would purchase\n",
            "-----------\n",
            "Input sequence: [[    5   588    28   870   397   102  2264    39  3425     5   169 10518\n",
            "     13   148     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[2.6974442e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002266 0.09996393 0.10000833 0.10005335 0.1000066  0.10000264\n",
            " 0.09999636 0.09999307 0.09997744 0.09997565], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000083 0.10000533 0.10000066 0.10000026\n",
            " 0.09999964 0.09999931 0.09999774 0.09999756]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.6974442e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-6.2110876e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "good packaged ground coffee decaf definitely strong coffee flavor great winding cup coffee late night wo keep br br sealed package hold ten ounce ground coffee bag feel sturdy prefer keep ground coffee original br br coffee price going may good idea compare price try like get better price amazon subscribe save option versus getting coffee bean local coffee shop grinding home coffee shop grind\n",
            "-----------\n",
            "Input sequence: [[    3   480   379    12   244   138   145    12     5     8 10569    43\n",
            "     12  1302   566   228    99     1     1   913   151   697  1792   380\n",
            "    379    12    16   156  1920   343    99   379    12   327     1     1\n",
            "     12    27   162   168     3   434   861    27    36     2    17    30\n",
            "     27    32   429   241   386  2669   271    12   231   135    12   671\n",
            "   1799   214    12   671   739     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[-3.6203592e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10008302 0.09999005 0.10014393 0.10013144 0.10003128 0.09997721\n",
            " 0.09991055 0.09984389 0.09988081 0.10000777], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000831 0.09999901 0.1000144  0.10001314 0.10000312 0.09999772\n",
            " 0.09999105 0.09998439 0.09998808 0.10000078]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[3.6203592e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(8.336199e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "great ham soup base used ham bean seasoned greenbeans great flavor\n",
            "-----------\n",
            "Input sequence: [[   8 2856  331 1075   49 2856  231 1521 6796    8    5    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.0198993e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002265 0.09996393 0.10000829 0.10005333 0.1000066  0.10000265\n",
            " 0.09999637 0.09999312 0.09997746 0.09997564], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000083 0.10000533 0.10000066 0.10000026\n",
            " 0.09999964 0.09999931 0.09999775 0.09999756]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.0198993e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.6509854e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "hand best formula market sadly breast milk dried fine formula poor son many gi stomach gas cry reflux etc issue alimentum month even tried ready eat heard corn free also tried hypoallergenic version enfamel nothing made br br researching found scary thing basically made using chemical baby horrible reaction toxin google anyway found organic formula buy seperate made egg organically chemical nervous son many issue want make worse tried seriously changed son life completely different baby longer even give acid reflux med anymore mean course still much better son since week know say toddler go site fda approved infant say toddler fully support breast feeding first year cals fat nutrient vit mineral pretty much leading brand organic use corn syrup seriously try formula\n",
            "-----------\n",
            "Input sequence: [[  28  902   42  731  230   57   24   28 7869  365 7870  226   44    1\n",
            "     1 4478   50 2957   54  869   44  102  604  242  763 1327 3789 2195\n",
            "   730   50   94  392   25 5606   44  306 4404  604 2659  274   71  308\n",
            "    80   15  947   28  970  674  274  395  653  106  242  397   34   72\n",
            "   556 2238 5607  708  419  410   74   20   30  274   63  204   68   52\n",
            "  1234   53  769 2000 4003 2193   52 1234 1660 1354 2938  507   45   48\n",
            "  3616  150 1228 3791 1897  133   20 2657   33   94   23  230  367  970\n",
            "    36  392]]\n",
            "Value estimates: tf.Tensor([[2.2681684e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002264 0.09996392 0.10000826 0.10005331 0.10000659 0.10000265\n",
            " 0.09999641 0.09999316 0.0999775  0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000083 0.10000533 0.10000066 0.10000027\n",
            " 0.09999964 0.09999932 0.09999775 0.09999757]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.2681684e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-5.2226455e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "mixed whipped cream blueberry lemon curd delicious easy quick summertime dessert delight guest\n",
            "-----------\n",
            "Input sequence: [[ 471 1202  224  693  665 8918   70   89  340 8919  837 2012  945    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.5694817e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10004647 0.09990438 0.09996757 0.10007557 0.09998173 0.1000351\n",
            " 0.10004308 0.10001861 0.09999841 0.0999291 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000465 0.09999043 0.09999676 0.10000756 0.09999817 0.1000035\n",
            " 0.10000431 0.10000186 0.09999984 0.09999291]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.5694817e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(5.916451e-07, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love pancake mix find exact one store always order online keep stock home mix water add fresh chopped banana strawberry healthy option swap syrup honey cook lil butter awesome breakfast\n",
            "-----------\n",
            "Input sequence: [[   9   73   29   31 1636    7   41  103   60  378   99  543  214   29\n",
            "    39   78  127 1451  746  682  107  386 5680  367  351  405 2876  280\n",
            "   424  417    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-6.464903e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002934 0.0999668  0.10002333 0.10006201 0.10000933 0.09999982\n",
            " 0.09998685 0.09997655 0.09996673 0.09997918], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000293 0.09999669 0.10000233 0.1000062  0.10000093 0.09999998\n",
            " 0.09999868 0.09999765 0.09999667 0.09999792]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[6.464903e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.4886031e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "little shocked health food product made chinese grown ingredient curious see carbon footprint bite also keep mind chinese ingredient product found kind contaminant lead toy melamine milk exported food product ingredient snack widely available united state support product company source locally consider economy sell slightly cheaper price purchasing choice make difference let stop expecting corporation government take care safety economy never change way company business benefit long term health economical make purchase decision wisely\n",
            "-----------\n",
            "Input sequence: [[  26 1835  289   11    6   44 1452 1474   61 3849  165 2758 3367  578\n",
            "    24   99  571 1452   61    6   50  210 8797 2986 1718 3890  114 5962\n",
            "    11    6   61   77 3602  240 2084  716 1354    6  185  699  666  787\n",
            "  2950  495  393  249   27  532  341   15  422  313  587  705 5963 4864\n",
            "   112  412 3107 2950   95  483   65  185 1349  722  155 1121  289 1582\n",
            "    15  148 2328 8798    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[4.4166864e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002258 0.09996389 0.10000815 0.10005324 0.10000657 0.10000265\n",
            " 0.09999646 0.09999326 0.09997757 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.09999639 0.10000081 0.10000532 0.10000066 0.10000027\n",
            " 0.09999964 0.09999932 0.09999776 0.09999756]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-4.4166864e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.0169778e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "stuff really work preventing cramping middle latter stage ride pop water bottle set flavor fine go easy\n",
            "-----------\n",
            "Input sequence: [[ 124   18   87 4890 3992  995 6489 1769 1861  329   39  172  510    5\n",
            "   253   53   89    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[4.9824553e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002256 0.09996388 0.10000812 0.10005322 0.10000656 0.10000266\n",
            " 0.09999648 0.09999329 0.09997758 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000081 0.10000532 0.10000066 0.10000027\n",
            " 0.09999964 0.09999932 0.09999776 0.09999756]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-4.9824553e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.14725035e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "mile chai wonderful right balance mellowness spiciness tried chai bit spicy one well balanced great almond milk bonus point organic much one trust organic label br br compare peet chai like mile better imo peet little much spicy side although still like peet may prefer flavor profile\n",
            "-----------\n",
            "Input sequence: [[1560 2898  179   98  661 9890 3203   28 2898   66  246    7   40 1514\n",
            "     8  640  114 1567  390   94   20    7 1306   94  394    1    1  861\n",
            "  2445 2898    2 1560   30 3499 2445   26   20  246  342  318   74    2\n",
            "  2445  168  343    5 4095    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-9.292165e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002257 0.09996387 0.1000081  0.10005324 0.10000657 0.10000268\n",
            " 0.09999651 0.09999333 0.09997761 0.09997558], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.09999639 0.10000081 0.10000532 0.10000066 0.10000027\n",
            " 0.09999964 0.09999934 0.09999776 0.09999756]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[9.292165e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.1396085e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "read review customer excited ordering trying mix morning made waffle stonewall kitchen mix bisquick waffle stonewall waffle bisquick waffle served several people tasting everyone felt br br agreement stonewall kitchen product worth significant extra cost furthermore available local super market whereas bisquick stocked one time purchase u\n",
            "-----------\n",
            "Input sequence: [[ 284   83  436  738  259  215   29  326   44  180 1209  762   29  201\n",
            "   180 1209  180  201  180  815  219  170  218  256  774    1    1 5754\n",
            "  1209  762    6  188 2327  273  278 3439  240  135  370  297 3442  201\n",
            "  2678    7   19  148  203    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.6817482e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002255 0.09996387 0.10000808 0.10005321 0.10000656 0.10000268\n",
            " 0.09999653 0.09999336 0.09997763 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000081 0.10000532 0.10000066 0.10000027\n",
            " 0.09999966 0.09999935 0.09999777 0.09999756]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.6817482e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.872371e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "happen like better sea salt vinegar chip found country\n",
            "-----------\n",
            "Input sequence: [[1276    2   30  494   76  239   10   50  963    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.5107087e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002251 0.09996389 0.10000804 0.10005315 0.10000654 0.10000268\n",
            " 0.09999653 0.09999338 0.09997765 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000081 0.10000532 0.10000066 0.10000028\n",
            " 0.09999967 0.09999935 0.09999777 0.09999757]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.5107087e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.4785127e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "spicy version ketchup bad expensive regular version sweet dessert horrible annie organic much better flavor cost lot le even heinz organic better deal gave three star instead two glass plastic\n",
            "-----------\n",
            "Input sequence: [[ 246  365 1405  105  192   91  365   62  837  763 2855   94   20   30\n",
            "     5  278   75  104   34 2853   94   30  235  279  216  183  222   79\n",
            "   756  362    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-6.068287e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002253 0.09996386 0.10000804 0.1000532  0.10000655 0.10000269\n",
            " 0.09999655 0.09999341 0.09997765 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000081 0.10000532 0.10000066 0.10000027\n",
            " 0.09999966 0.09999935 0.09999777 0.09999756]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[6.068287e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.3972783e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "coffee good distinctive aroma taste like buttered movie theater popcorn huge hazelnut flavored coffee fan good typically taste like hazelnut may like search true hazelnut flavor test make popcorn microwave later make coffee see similarity\n",
            "-----------\n",
            "Input sequence: [[  12    3 2910  492    4    2 4750 1761 3811  232  621 1293  349   12\n",
            "   344    3 1570    4    2 1293  168    2 1352  695 1293    5  908   15\n",
            "   232  727  624   15   12  165 5038    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.224542e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002253 0.09996385 0.10000802 0.10005321 0.10000656 0.1000027\n",
            " 0.09999657 0.09999344 0.09997766 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.09999639 0.10000081 0.10000532 0.10000066 0.10000027\n",
            " 0.09999966 0.09999935 0.09999777 0.09999756]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.224542e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.8196271e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "eat junk food like enjoy guilty pleasure br br cooky neither healthy tasty stick chewy chocolate chip cooky\n",
            "-----------\n",
            "Input sequence: [[  42 1030   11    2  120 1760 1420    1    1  141 1569  107  118  295\n",
            "   832   35   10  141    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.3521283e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10005466 0.0999778  0.10008022 0.10009474 0.10001969 0.09998915\n",
            " 0.09995084 0.09991394 0.0999262  0.09999269], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000548 0.09999779 0.10000803 0.10000948 0.10000197 0.09999892\n",
            " 0.09999509 0.0999914  0.09999263 0.09999928]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.3521283e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-7.7185505e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "experimenting different brand since purchased keurig last christmas one okay good green mountain breakfast blend everyday staple tried green mountain columbian yet closer comparison however make larger cup coffee one brew noticibly weaker gm breakfast br br also please note love timothy world italian blend definitely amount favorite\n",
            "-----------\n",
            "Input sequence: [[ 2579   106    33    63   175   288   182   457     7   602     3   125\n",
            "    711   417   221  1158  1151    28   125   711  3879   347  1812  1095\n",
            "    121    15   443    43    12     7   413 11015  3108  2852   417     1\n",
            "      1    24   425   579     9  2275   657  1255   221   138   173    58\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[1.7121132e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10008633 0.09999153 0.1001514  0.10013568 0.10003263 0.09997579\n",
            " 0.09990583 0.09983569 0.09987552 0.10000957], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000864 0.09999916 0.10001515 0.10001358 0.10000326 0.09999759\n",
            " 0.09999059 0.09998357 0.09998756 0.10000096]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.7121132e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.942258e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love tea flavorful yet cut grass flavor green tea mild even left steeping become mellow flavor kid enjoy great without br loose leaf tea steeped leaf unfurl long slender little tea go long way enjoy\n",
            "-----------\n",
            "Input sequence: [[   9   14  432  347  384 1968    5  125   14  588   34  502 3252  684\n",
            "  1533    5  202  120    8   85    1  668  463   14 2896  463 4305  155\n",
            "  5419   26   14   53  155   65  120    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-6.6164744e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002263 0.0999639  0.10000824 0.10005332 0.1000066  0.10000265\n",
            " 0.09999641 0.09999318 0.0999775  0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000226 0.0999964  0.10000083 0.10000533 0.10000066 0.10000027\n",
            " 0.09999964 0.09999932 0.09999775 0.09999756]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[6.6164744e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.52350385e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "new food allergy son diagnosed severe fa since still breastfed drastically alter br br learning brand stuck eating chicken breast potato every meal stumbled upon local whole food excited try br br overall really like got pretty good texture taste heft dense want gag two bite also light eat whole box really big br br know alot people complain agree somewhat bar ounce calorie par many breakfast bar like berry flavor best closest real non fa specialty flavor overally grateful bar tote several diaper bag car know really need quick snack wo left stranded\n",
            "-----------\n",
            "Input sequence: [[ 159   11  427  274 1406 1773 5321   63   74 7285 7286 3251    1    1\n",
            "  2848   33  802  122  176 2938   69   90  248 2095  934  135  139   11\n",
            "   738   36    1    1  414   18    2   81  133    3  190    4 7287 1314\n",
            "    80 4321   79  578   24  196   42  139   37   18  164    1    1   68\n",
            "  1163  170 1583  790  658  337  380   84 3129   71  417  337    2  907\n",
            "     5   22 1939  177 1808 5321 2325    5 7288 2700  337 5322  219 2939\n",
            "    16 1162   68   18  101  340   77  228  502 7289    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.8702995e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10005436 0.09997763 0.10007948 0.10009437 0.10001957 0.0999893\n",
            " 0.09995133 0.09991477 0.09992672 0.09999251], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000545 0.09999777 0.10000796 0.10000944 0.10000196 0.09999894\n",
            " 0.09999514 0.09999148 0.09999268 0.09999926]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.8702995e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.306559e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "like lot sesame oil use salad regularly great quality flavor aroma ca beat organic\n",
            "-----------\n",
            "Input sequence: [[   2   75 1517  128   23  437 1426    8   88    5  492   86  551   94\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.6279882e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002273 0.09996399 0.10000851 0.10005342 0.10000664 0.10000259\n",
            " 0.09999622 0.09999286 0.09997731 0.09997571], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000227 0.0999964  0.10000084 0.10000534 0.10000066 0.10000026\n",
            " 0.09999962 0.09999929 0.09999774 0.09999757]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.6279882e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.7485548e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "cereal difficult find store appreciate able purchase amazon husband really like look forward delivering every month seems like unlikely thing look forward little thing count looney\n",
            "-----------\n",
            "Input sequence: [[ 462  552   31   41 1230  252  148   32  195   18    2  184  721 4200\n",
            "    90  142  260    2 5374   54  184  721   26   54  874 7388    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[8.246983e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10004323 0.09992712 0.09999284 0.10007433 0.09999236 0.10002178\n",
            " 0.10001983 0.09999744 0.09998317 0.09994784], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000432 0.09999271 0.09999929 0.10000743 0.09999924 0.10000218\n",
            " 0.10000198 0.09999974 0.09999833 0.09999478]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-8.246983e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.8989314e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "dog anything treat buying five pound bag last year dry easy put pocket last forever\n",
            "-----------\n",
            "Input sequence: [[  21  163  129  158  714  345   16  182   48  275   89  130 1390  182\n",
            "  1690    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.4755809e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002283 0.09996393 0.10000864 0.10005359 0.10000666 0.10000259\n",
            " 0.09999617 0.09999274 0.0999772  0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.0999964  0.10000087 0.10000536 0.10000067 0.10000026\n",
            " 0.09999962 0.09999927 0.09999772 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.4755809e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.3976725e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "black licorice taste like artificial nasty artificial black dye coat tongue teeth wonderfully soft chewy took box work everyone agreed best black licorice ever tasted\n",
            "-----------\n",
            "Input sequence: [[ 269  311    4    2  373  839  373  269 4457  631 1730  836 1664  364\n",
            "   832  330   37   87  256 2294   22  269  311   92  166    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-7.4795976e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10005839 0.09997933 0.10008846 0.10009956 0.10002118 0.09998764\n",
            " 0.09994566 0.09990487 0.09992032 0.09999461], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000584 0.09999794 0.10000885 0.10000996 0.10000212 0.09999876\n",
            " 0.09999456 0.09999049 0.09999204 0.09999947]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[7.4795976e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.7222466e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "best decaf family tried long time smooth bitter enough flavor without strong like brand tried like decaffeinated using natural swiss water process instead chemical big plus many brand tell decaffeinate coffee usually buy whole bean ground nice fine save time grind get right suggest following instruction given bag best taste seal tightly store refrigerator keep flavor one buying\n",
            "-----------\n",
            "Input sequence: [[  22  244  143   28  155   19  270  261  100    5   85  145    2   33\n",
            "    28    2 1176  102  144  812   39  765  222  604  164  272   71   33\n",
            "   376 3958   12  189   25  139  231  379   82  253  241   19  739   17\n",
            "    98  799  954  829  485   16   22    4 1947 3144   41 1937   99    5\n",
            "     7  158    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.4614003e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002284 0.09996396 0.10000864 0.10005355 0.10000664 0.10000261\n",
            " 0.09999619 0.09999271 0.09997723 0.09997569], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.0999964  0.10000087 0.10000536 0.10000067 0.10000026\n",
            " 0.09999963 0.09999928 0.09999773 0.09999757]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.4614003e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.3649772e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "artificial sweetener ruined leaf fake sugar taste mouth husband drink diet soda even noticed least pricey\n",
            "-----------\n",
            "Input sequence: [[ 373  354 5184  463 1629   47    4  353  195   64  171  713   34  531\n",
            "   290  876    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.0684554e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002285 0.09996391 0.10000861 0.10005357 0.10000663 0.10000261\n",
            " 0.09999619 0.09999271 0.09997722 0.09997566], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.0999964  0.10000087 0.10000536 0.10000067 0.10000026\n",
            " 0.09999962 0.09999927 0.09999773 0.09999757]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.0684554e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.4601979e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "natural beef soft taste drier outer surface like matter personal taste product good br suggest trying company old fashioned strong hickory flavor good bite spice drier br company superb customer service\n",
            "-----------\n",
            "Input sequence: [[ 144  638  364    4 3938 4737 4416    2  759  938    4    6    3    1\n",
            "   799  215  185  111 2668  145 4849    5    3  578  381 3938    1  185\n",
            "  1553  436  420    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.7640854e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002288 0.09996384 0.10000861 0.10005365 0.10000662 0.10000262\n",
            " 0.09999621 0.09999272 0.0999772  0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000228 0.09999638 0.10000086 0.10000536 0.10000066 0.10000025\n",
            " 0.09999962 0.09999927 0.09999772 0.09999756]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.7640854e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.061988e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "hot like low star reviewer got suckered seeing name oz size people might like flavor fish sauce mix according ingredient label looking hot ai\n",
            "-----------\n",
            "Input sequence: [[  38    2  186  183  511   81 7369 1946  504  237  113  170  250    2\n",
            "     5  585  117   29 1214   61  394  152   38 3261    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-9.192829e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002287 0.09996384 0.10000858 0.10005362 0.10000661 0.10000263\n",
            " 0.09999623 0.09999274 0.09997722 0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999638 0.10000086 0.10000536 0.10000066 0.10000026\n",
            " 0.09999962 0.09999927 0.09999772 0.09999757]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[9.192829e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.1167354e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "using treat quite dog love dog also way food quite time acting kind nothing major exactly right well happened quit using treat week noticed dog came back life eating like crazy certain pin treat something keep mind using pet seems little kilter\n",
            "-----------\n",
            "Input sequence: [[ 102  129  205   21    9   21   24   65   11  205   19 4558  210  226\n",
            "  1266  516   98   40 1339 2416  102  129  204  531   21  174  136  395\n",
            "   122    2  793 1502 4051  129   96   99  571  102  446  260   26 8192\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.7216062e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002285 0.09996387 0.10000856 0.10005356 0.10000659 0.10000264\n",
            " 0.09999625 0.09999276 0.09997726 0.09997562], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999639 0.10000086 0.10000536 0.10000066 0.10000028\n",
            " 0.09999963 0.09999928 0.09999773 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.7216062e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.9641152e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "regularly purchase item bulk loved also dairy br however last purchase disappointing opening brand new package noticed black thing mix carefully removed find dead flour beetle sifted mix found dead bug br br second time writing review amazon publish first review thank br purchasing item\n",
            "-----------\n",
            "Input sequence: [[ 1426   148   137   589   199    24  1348     1   121   182   148   978\n",
            "   1064    33   159   151   531   269    54    29  1881  2629    31  2315\n",
            "    283  5950  5210    29    50  2315  2420     1     1   332    19  1813\n",
            "     83    32 10387    45    83   320     1   532   137     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[1.0459543e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002287 0.09996384 0.10000855 0.10005359 0.10000659 0.10000265\n",
            " 0.09999626 0.09999277 0.09997725 0.0999756 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999639 0.10000086 0.10000536 0.10000066 0.10000026\n",
            " 0.09999963 0.09999928 0.09999773 0.09999757]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.0459543e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.408388e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "familiar safcol brand tuna addict gave shot tuna taste like good quality found tomato basil flavor bit bland better something plain pack punch hoping still great option low calorie low fat meal\n",
            "-----------\n",
            "Input sequence: [[2381 4947   33  864 1763  279  528  864    4    2    3   88   50  358\n",
            "  1294    5   66  646   30   96  334   67 1785  810   74    8  386  186\n",
            "    84  186  150  248    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-2.2567194e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002291 0.09996378 0.10000855 0.10005368 0.1000066  0.10000267\n",
            " 0.09999628 0.09999277 0.09997723 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999638 0.10000087 0.10000537 0.10000066 0.10000027\n",
            " 0.09999963 0.09999929 0.09999773 0.09999756]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[2.2567194e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(5.196339e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "like people switched organic dog food scare trying lot different food settled one dog like feel good feeding\n",
            "-----------\n",
            "Input sequence: [[   2  170  720   94   21   11 2575  215   75  106   11 3106    7   21\n",
            "     2  156    3  507    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.4372745e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002289 0.09996379 0.10000854 0.10005362 0.10000658 0.10000267\n",
            " 0.09999628 0.09999277 0.09997726 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999638 0.10000085 0.10000536 0.10000065 0.10000026\n",
            " 0.09999963 0.09999927 0.09999773 0.09999756]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.4372745e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.3094489e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love pasta love seem able digest pasta taste great easy digest added bonus healthy low calorie tried every version pasta amazing reviewer complained pasta firm case simply need cook bit longer regular pasta light feather wonderful taste light would think eating homemade pasta almost hard beleive stuff come box\n",
            "-----------\n",
            "Input sequence: [[   9  374    9  321  252 1626  374    4    8   89 1626  213 1567  107\n",
            "   186   84   28   90  365  374  323  511 1538  374 1421  147  583  101\n",
            "   405   66  397   91  374  196 4479  179    4  196   13   59  122  885\n",
            "   374  169  116 5183  124   97   37    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.49532025e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002287 0.09996381 0.10000852 0.10005358 0.10000658 0.10000268\n",
            " 0.0999963  0.0999928  0.09997728 0.09997559], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999638 0.10000085 0.10000536 0.10000066 0.10000028\n",
            " 0.09999964 0.09999928 0.09999773 0.09999757]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.49532025e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.44308e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "parisian cafe blend wonderful thick fit correctly senseo machine box advertises universal fit\n",
            "-----------\n",
            "Input sequence: [[4791  798  221  179  563  733 3008 1247  465   37 4255 9859  733    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.1538116e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000229  0.09996378 0.10000852 0.10005362 0.10000657 0.10000268\n",
            " 0.09999631 0.0999928  0.09997728 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999638 0.10000085 0.10000536 0.10000065 0.10000026\n",
            " 0.09999963 0.09999928 0.09999773 0.09999756]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.1538116e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-7.2619096e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "drinking green tea powder year come love slightly bitter tannic flavor decided try stash brand instead normal japanese brand even universe stash product green colored powder flavor seriously stash brand us maltodextrin base dehydrated tea added real authentic green tea powder supposed tea additive br br drink lot green tea disappointed stash product strongly recommend go japanese brand contains tea br br tried return amazon allow grocery item returned\n",
            "-----------\n",
            "Input sequence: [[ 277  125   14  227   48   97    9  393  261 5989    5  243   36  804\n",
            "    33  222  538 1206   33   34 8852  804    6  125 1800  227    5  970\n",
            "   804   33  816 1602 1075 2543   14  213  177 1598  125   14  227  981\n",
            "    14 1190    1    1   64   75  125   14  257  804    6 2755   56   53\n",
            "  1206   33  572   14    1    1   28  709   32 1658  178  137 1400    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-7.879287e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002291 0.09996375 0.10000852 0.10005366 0.10000658 0.10000269\n",
            " 0.09999631 0.0999928  0.09997726 0.09997553], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999637 0.10000084 0.10000536 0.10000065 0.10000026\n",
            " 0.09999963 0.09999927 0.09999772 0.09999754]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[7.879287e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.814279e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love price good flavor really good peppermint one favorite would gladly take others though others lacking peppermint fan buying others get low thanks much\n",
            "-----------\n",
            "Input sequence: [[   9   27    3    5   18    3  540    7   58   13 3931  112  225  134\n",
            "   225 2032  540  344  158  225   17  186  401   20    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.4683038e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002291 0.09996375 0.10000851 0.10005366 0.10000657 0.10000269\n",
            " 0.09999631 0.0999928  0.09997726 0.09997552], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999637 0.10000084 0.10000536 0.10000065 0.10000026\n",
            " 0.09999963 0.09999927 0.09999772 0.09999754]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.4683038e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.380916e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "amazon price may higher grocery store store good way br first tried princess cruise ship found good filling stay br super please find\n",
            "-----------\n",
            "Input sequence: [[  32   27  168  535  178   41   41    3   65    1   45   28 4356 4025\n",
            "   823   50    3  662  488    1  370  425   31    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.5911148e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002288 0.09996378 0.1000085  0.10005359 0.10000656 0.10000269\n",
            " 0.09999633 0.09999281 0.09997729 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999638 0.10000085 0.10000536 0.10000066 0.10000028\n",
            " 0.09999964 0.09999928 0.09999773 0.09999756]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.5911148e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.6636513e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "produce extremely fresh made delicious thai soup item plenty spare\n",
            "-----------\n",
            "Input sequence: [[1076  622  127   44   70  618  331  137  835 3473    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.07424985e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10003246 0.09996791 0.10002998 0.10006598 0.10001047 0.09999867\n",
            " 0.09998273 0.09996915 0.09996197 0.09998064], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000325 0.0999968  0.100003   0.1000066  0.10000105 0.09999987\n",
            " 0.09999827 0.09999692 0.0999962  0.09999807]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.07424985e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.4735402e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love product bottle design terrible order get last body wash bottle timely manner would normally store bottle upside pointy top impossible must stand shower try shake remaining product length bottle squirt take much time want take redesign bottle flat top please\n",
            "-----------\n",
            "Input sequence: [[   9    6  172 1351  788   60   17  182  564 1559  172 1319 1764   13\n",
            "   729   41  172 3037 6116  305 1463  316  768 1444   36 1195 2296    6\n",
            "  1784  172 5370  112   20   19   80  112 6259  172 1227  305  425    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.8831175e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002293 0.09996371 0.10000851 0.10005368 0.10000657 0.1000027\n",
            " 0.09999632 0.09999278 0.09997725 0.0999755 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999637 0.10000084 0.10000536 0.10000065 0.10000026\n",
            " 0.09999963 0.09999927 0.09999772 0.09999754]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.8831175e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.3360735e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "dog love food maintained healthy weight many year vet happy general health coat teeth bag sent directly home without shipping charge terrific lb size available area\n",
            "-----------\n",
            "Input sequence: [[  21    9   11 5650  107  294   71   48  675  154 1205  289  631  836\n",
            "    16  623  924  214   85  146 1157 1280  811  113  240  644    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-5.0384556e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002293 0.09996375 0.10000853 0.10005366 0.10000657 0.10000269\n",
            " 0.09999631 0.09999277 0.09997726 0.09997553], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999637 0.10000085 0.10000536 0.10000065 0.10000026\n",
            " 0.09999963 0.09999927 0.09999772 0.09999754]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[5.0384556e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.1601499e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "product simply cheap liquor since taste quality important prefer drink grey goose straight however occasion absolutely delicious tiny splash olive juice product quick fix stop purchasing olive order use juice worth taste worse\n",
            "-----------\n",
            "Input sequence: [[   6  583  385 2054   63    4   88  844  343   64 1714 8174 1012  121\n",
            "  1429  300   70  562  916  473  266    6  340 1192  587  532  473   60\n",
            "    23  266  188    4  947    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.9497105e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002291 0.09996378 0.10000853 0.10005362 0.10000656 0.1000027\n",
            " 0.09999631 0.09999276 0.09997728 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999637 0.10000085 0.10000536 0.10000065 0.10000028\n",
            " 0.09999963 0.09999927 0.09999773 0.09999756]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.9497105e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.4893364e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "bought water pet chinchilla tank tony love water never seen drink much life bought water chinchilla drink tap water spring water best br mad though purchased item week ago cheaper wtf br overall love item great br tasted taste great\n",
            "-----------\n",
            "Input sequence: [[  51   39  446 6148 9418 9419    9   39   95  734   64   20  395   51\n",
            "    39 6148   64 2760   39 1101   39   22    1 3623  134  175  137  204\n",
            "   263  249 9420    1  414    9  137    8    1  166    4    8    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.9238555e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10007304 0.09998544 0.10012108 0.10011847 0.10002704 0.0999816\n",
            " 0.09992509 0.09986892 0.09989705 0.10000221], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000731 0.09999855 0.10001212 0.10001185 0.10000271 0.09999817\n",
            " 0.09999252 0.0999869  0.0999897  0.10000023]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.9238555e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.4298386e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "mccann instant irish oatmeal variety pack regular apple cinnamon maple brown sugar box pack br br fan mccann oat thought give instant variety try found hardy meal sweet great folk like surgery need food palatable easily digestible fiber wo make bloat\n",
            "-----------\n",
            "Input sequence: [[1323  496 1972  597  157   67   91  455  508  940  371   47   37   67\n",
            "     1    1  344 1323 1110  131   72  496  157   36   50 4870  248   62\n",
            "     8 1150    2 3973  101   11 1854  409 4871  544  228   15 4872    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.9864936e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002298 0.09996371 0.10000859 0.10005375 0.10000658 0.1000027\n",
            " 0.09999628 0.0999927  0.0999772  0.09997552], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000229 0.09999637 0.10000085 0.10000537 0.10000066 0.10000027\n",
            " 0.09999962 0.09999926 0.09999771 0.09999755]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.9864936e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.5741097e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "tried many brand sardine favorite even low sodium full flavor excellent choice\n",
            "-----------\n",
            "Input sequence: [[ 28  71  33 808  58  34 186 350 206   5 140 341   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Value estimates: tf.Tensor([[3.8505286e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002297 0.09996375 0.10000861 0.10005371 0.10000657 0.10000268\n",
            " 0.09999626 0.09999267 0.0999772  0.09997555], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999637 0.10000087 0.10000537 0.10000066 0.10000027\n",
            " 0.09999962 0.09999926 0.09999772 0.09999756]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.8505286e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-8.866156e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "son made patience precise water temperature half hour done appeared risen feared worse determined polite agreed sandwich using bread amazing apparently rise baking br br great tangy flavor perfect meat sandwich imho heavy fortunately lot deli meat since whole loaf disappeared within br br sourdough peasant bread far sure delicious well\n",
            "-----------\n",
            "Input sequence: [[ 274   44 5267 3641   39 1697  207  475  521 2691 7164 7165  947 4287\n",
            "  7166 2294  561  102  233  323 1320 2322  389    1    1    8 1235    5\n",
            "   110  357  561 3600  775 2492   75 3179  357   63  139 1240 4288  735\n",
            "     1    1 7167 7168  233  126  123   70   40    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.6103497e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002297 0.09996378 0.10000864 0.10005371 0.10000658 0.10000268\n",
            " 0.09999625 0.09999266 0.0999772  0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999638 0.10000087 0.10000537 0.10000066 0.10000027\n",
            " 0.09999962 0.09999926 0.09999772 0.09999756]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.6103497e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.707941e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "also routine baking ingredient put bread along sunflower seed organic wheat flour also put smoothie stir fry dish anything think good price really must healthy diet\n",
            "-----------\n",
            "Input sequence: [[  24 2587  389   61  130  233  448 1824  482   94  360  283   24  130\n",
            "  2684 1164 2113  499  163   59    3   27   18  316  107  171    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.1706783e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002301 0.09996374 0.10000866 0.10005376 0.10000658 0.10000268\n",
            " 0.09999623 0.09999261 0.09997715 0.09997553], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999637 0.10000087 0.10000537 0.10000066 0.10000025\n",
            " 0.09999961 0.09999926 0.09999771 0.09999755]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.1706783e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.6956002e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "wanted make authentic italian margherita pizza home ordered caputo flour tomato amazing taste liek tomato favorite italian pizza restaurant label say basil detect visually taste basil stuff jsut awesome ordered another can shipping kill though\n",
            "-----------\n",
            "Input sequence: [[ 264   15 1598 1255 7823  648  214   93 7824  283  358  323    4 7825\n",
            "   358   58 1255  648  737  394   52 1294 2738 7826    4 1294  124 7827\n",
            "   424   93  194  383  146 2955  134    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-5.4551456e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002302 0.09996375 0.10000869 0.10005378 0.10000659 0.10000268\n",
            " 0.09999622 0.0999926  0.09997714 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999638 0.10000087 0.10000538 0.10000066 0.10000026\n",
            " 0.09999962 0.09999926 0.09999771 0.09999756]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[5.4551456e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.2560967e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love sorghum flour mild flavor smell easily mixed flour blend gluten free baking one favorite along millet sweet rice coconut almond\n",
            "-----------\n",
            "Input sequence: [[   9 2734  283  588    5  234  409  471  283  221  115   57  389    7\n",
            "    58  448 5543   62  181  187  640    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[8.072742e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.100023   0.09996377 0.10000869 0.10005375 0.10000658 0.10000267\n",
            " 0.09999621 0.09999257 0.09997714 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999637 0.10000087 0.10000537 0.10000066 0.10000027\n",
            " 0.09999961 0.09999925 0.09999771 0.09999756]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-8.072742e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.858811e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "others said really mild flavor instruction call packet per oz water packet per br br decided give try basically lazy wanted unsweetened unlemoned iced tea could make moment br br started packet per oz water packet per oz water got flavor using packet per oz water placed fairly large order could experiment throughout fall winter br br since using triple amount product order get flavor probably order item\n",
            "-----------\n",
            "Input sequence: [[ 225  193   18  588    5  829  573  285  132  237   39  285  132    1\n",
            "     1  243   72   36  869 2704  264 1685 8851  481   14   46   15 2053\n",
            "     1    1  307  285  132  237   39  285  132  237   39   81    5  102\n",
            "   285  132  237   39 1507  847  296   60   46 2087 1436  863 1061    1\n",
            "     1   63  102 2730  173    6   60   17    5  208   60  137    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[5.4194256e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002303 0.09996378 0.10000872 0.10005378 0.1000066  0.10000268\n",
            " 0.0999962  0.09999256 0.09997714 0.09997558], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999637 0.10000087 0.10000537 0.10000066 0.10000025\n",
            " 0.09999961 0.09999925 0.09999771 0.09999755]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-5.4194256e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.247866e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "flavor vita coco produce pineapple combination far best enough flavor keep interesting overpowering\n",
            "-----------\n",
            "Input sequence: [[   5 1360  985 1076  352  726  126   22  100    5   99 1312 1165    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.0549005e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002305 0.09996375 0.10000873 0.10005382 0.10000659 0.10000267\n",
            " 0.09999619 0.09999253 0.09997711 0.09997555], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999638 0.10000087 0.10000538 0.10000066 0.10000026\n",
            " 0.09999961 0.09999925 0.09999771 0.09999756]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.0549005e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.4290093e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "great waffle mix allergy preservative find food general great tasting without preservative huge challenge tried several mix one far best totally understand review bad taste chemical read label mix see one full ingredient certain kind ingredient mix need levening use real butter tub butter contains water nasty stuff best waffle ever\n",
            "-----------\n",
            "Input sequence: [[   8  180   29  427 1188   31   11 1205    8  218   85 1188  621 2441\n",
            "    28  219   29    7  126   22  696 1088   83  105    4  604  284  394\n",
            "    29  165    7  206   61 1502  210   61   29  101 8237   23  177  280\n",
            "  2243  280  572   39  839  124   22  180   92    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[5.144375e-08]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002305 0.09996377 0.10000875 0.10005381 0.1000066  0.10000268\n",
            " 0.09999619 0.09999252 0.0999771  0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999638 0.10000087 0.10000538 0.10000066 0.10000026\n",
            " 0.09999961 0.09999925 0.09999771 0.09999756]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-5.144375e-08]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.1845361e-07, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "hi black tea everyday done past year habit mine ahmad tea one favorite brand highly recommend like black tea think going remain favorite next year\n",
            "-----------\n",
            "Input sequence: [[4076  269   14 1158  521  500   48 1379  581 2002   14    7   58   33\n",
            "   153   56    2  269   14   59  162 3496   58  317   48    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[7.283963e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002305 0.09996378 0.10000876 0.10005379 0.1000066  0.10000267\n",
            " 0.09999619 0.09999251 0.09997711 0.09997558], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999637 0.10000087 0.10000537 0.10000066 0.10000025\n",
            " 0.09999961 0.09999924 0.09999771 0.09999755]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.283963e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.6771892e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "curious stonewall since reading amazon review sure spending pancake mix day found big sur la tab store san francisco thought chance try looking fwd saturday morning made first thing today say underwhelming nothing special tried following instruction using low fat milk healthier butter alright great esp considering price doctored bit added madagascar vanilla flaxseed psyllium usually pancake tasted bit better overall rating star ok stuck eat purchase probably try next time full fat milk butter recommended see make difference probably highly recommend garvey organic pancake mix also amazon taste much better fluffier like whole grain pancake also love kodiak buttermilk mix also amazon healthy hearty good even kid love best add water make portable even took u vacay hawaii\n",
            "-----------\n",
            "Input sequence: [[ 131  744   36  152 8257 3015  326   44   45   54  627   52 5076  226\n",
            "   461   28  954  829  102  186  150  114  355  280 2415    8 3067  868\n",
            "    27 5752   66  213 4954  440 1083 8258  189   73  166   66   30  414\n",
            "  1139  183  479  802   42  148  208   36  317   19  206  150  114  280\n",
            "   366  165   15  422  208  153   56 8259   94   73   29   24   32    4\n",
            "    20   30 4568    2  139  614   73   24    9 8260 1233   29   24   32\n",
            "   107 2276    3   34  202    9   22   78   39   15 1609   34  330  203\n",
            "  8261 5753]]\n",
            "Value estimates: tf.Tensor([[2.9807338e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002305 0.09996376 0.10000876 0.10005382 0.10000659 0.10000266\n",
            " 0.09999617 0.09999248 0.09997708 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999638 0.10000088 0.10000538 0.10000066 0.10000026\n",
            " 0.09999961 0.09999925 0.09999771 0.09999756]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.9807338e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-6.8633844e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "ordering cooky beware arrived crumbles want box stale crumb order away\n",
            "-----------\n",
            "Input sequence: [[ 259  141 1217  238 3580   80   37  610 1260   60  197    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.933456e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002306 0.09996375 0.10000878 0.10005385 0.1000066  0.10000266\n",
            " 0.09999616 0.09999248 0.09997706 0.09997556], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999637 0.10000088 0.10000539 0.10000066 0.10000027\n",
            " 0.09999962 0.09999926 0.09999771 0.09999756]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.933456e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(4.4519846e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "oregonian make point sharing snack friend visit state tell kettle brand potato chip microbrew br br kettle brand potato chip unmistakable light gold color rich flavor amazing crunch kettle brand chip also healthier snacking option major chip brand kettle brand chip trans fat msg artificial flavor coloring company also line organic potato chip product certified br br annette solomon reporter salem statesman journal noted glass wine go nicely spicy thai chip solomon wrote could missing wonderful pairing chip spicy would want select white wine also moderate amount acid subdue strong flavor ginger lime garlic cilantro without classically riesling fit parameter perfectly br br also recommend http kettle chip honey dijon http kettle chip sea salt vinegar br br honey dijon chip bring terrific balance salty tangy sweet crunchy brand tried use much mustard flavor overpowers honey dijon pairing honey dijon chip make great side dish bbq plate baked bean coleslaw potato salad grilled meat naturally also go great br br sea salt vinegar chip perfect complement vegetable tray cucumber carrot celery cherry tomato skip dip balance tangy chip alternating bite raw br br summary highly recommend kettle brand chip great buy\n",
            "-----------\n",
            "Input sequence: [[ 493 2027  518 1724   85 4165 3563  733 4166  779    1    1   24   56\n",
            "   282  191   10  351 1592  282  191   10  494   76  239    1    1  351\n",
            "  1592   10  875 1280  661  302 1235   62  338   33   28   23   20  914\n",
            "     5 3564  351 1592 3182  351 1592   10   15    8  342  499  438 2147\n",
            "   309  231 5120   69  437 2645  357 1330   24   53    8    1    1  494\n",
            "    76  239   10  110 4156  486 1890 5119  895 3559  725  358 1919  860\n",
            "   661 1235   10 4157  578  509    1    1 3208  153   56  191   33   10\n",
            "     8   25]]\n",
            "Value estimates: tf.Tensor([[1.8216811e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002749 0.09996571 0.10001875 0.10005953 0.10000841 0.1000008\n",
            " 0.09998986 0.09998152 0.09996998 0.09997796], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000275 0.09999657 0.10000187 0.10000595 0.10000084 0.10000008\n",
            " 0.09999899 0.09999815 0.099997   0.0999978 ]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.8216811e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.194543e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "coffee really bold opinion fall along medium roast flavor decent smooth coffee think really bold like though seriously overpriced\n",
            "-----------\n",
            "Input sequence: [[  12   18  625  484  863  448  818  442    5  632  270   12   59   18\n",
            "   625    2  134  970 2449    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-3.270443e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002691 0.09996544 0.10001741 0.1000588  0.10000817 0.10000105\n",
            " 0.09999071 0.09998298 0.09997093 0.09997763], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000268 0.09999654 0.10000174 0.10000587 0.10000081 0.10000011\n",
            " 0.09999907 0.0999983  0.09999709 0.09999776]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[3.270443e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(7.530474e-07, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "still six year away centennial oreo cookie first manufactured nabisco something exciting people dip tea biscuit english tend use copyrighted oreo biscuit sandwich cookie quite similar hydrox cookie produced sunshine oreo dominated market extent stopped making hydrox back would considered modern oreo cookie developed originally mound shaped think name come greek word hill two circular chocolate wafer sweet white filling commonly called cream br br course today consumer restrict tradition oreo cookie oreo cream instead traditional white well orange colored cream halloween red christmas get oreo double portion filling mention mixing matching two flavor filling carmel chocolate coffee cream peanut butter chocolate want original cookie coating chocolate fudge white chocolate fudge winter oreo flavor cookie br br interested watching weight open bag ever type oreo personal preference sitting beginning eating open could go stale putting cookie jar make accessible even allays fear freshness nabisco taken approach weight watching oreo lover go reduced fat oreo identical size original le fat per serving mini oreo version packaged snack pack rather really think wrapped tray add short list oreo thin br br baked chocolate wafer snack almost pack lightly sprinkled white speck take place aforementioned cream someone like cream wafer wary thought scarffing bunch would like eating chocolate wafer without white cream lighter taste even without glass milk handy considered essentially eating traditional oreo cooky since oreo taste round come calorie pack help draw line nice round number come caloric intake six oz pack oz box pack contains gram gram fat milligram cholesterol also find one healthy living tip front pack make meal appetizer side dish instead larger main entree course thinking putting bowl vanilla ice cream would really mess whole healthy living bit\n",
            "-----------\n",
            "Input sequence: [[ 986   77  169   67 1077 2172  198 9087  112  404 4706  224  400    2\n",
            "   224  986 9088  131 9089  977   13    2  122   35  986   85  198  224\n",
            "  1458    4   34   85  756  114 1295 1581 3677  122 1041  312  141   63\n",
            "   312    4 1535   97   84   67  247 2807  477   82 1535  750   97 5709\n",
            "   992  619  237   67  237   37   67  572  736  736  150 3788 1308   24\n",
            "    31    7  107 1277 1207 1067   67   15  248 3479  342  499  222  443\n",
            "   890 2863  410  911  974  536  440  512  224   13   18  877  139  107\n",
            "  1277   66]]\n",
            "Value estimates: tf.Tensor([[-1.1775479e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002983 0.09996668 0.10002396 0.10006259 0.10000936 0.09999982\n",
            " 0.09998655 0.09997576 0.09996624 0.09997916], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000298 0.09999666 0.10000239 0.10000626 0.10000093 0.09999998\n",
            " 0.09999865 0.09999758 0.09999663 0.09999792]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.1775479e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.711418e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "got tasted strait bottle tasted like smoky flavored milk yuck depressed stuck bottle sat shelf forgot last weekend tasted zevia cream soda pleased flavor tasted weird smokey like lorann oil gotten tried doctor soda little sf vanilla torani syrup tablespoon heavy cream tasted amazing odd smokiness gone wonderful rich br br wanted see would help lorann oil put cup whipping cream bowl added teaspoon vanilla tasted tasted fine added one drop oil strong stirred tasted much better whipped put fruit br br always whip drop vanilla dessert whip cream happy accident find use added vanilla really add new depth flavor taste different bottle br br potent use drop increase tasting add much ruin recipe use light touch\n",
            "-----------\n",
            "Input sequence: [[1736  166 7024  224  713  406    5  166  766 2282    2 5202  128 1106\n",
            "    28 1485  713   26 5203  440 3606  367  841  775  224  166  323 1296\n",
            "  7025  565  179  298    1    1  264  165   13  247 5202  128  130   43\n",
            "  5204  224  536  213 1299  440  166  166  253  213    7  905  128  145\n",
            "  3607  166   20   30 1202  130  281    1    1  103 2452  905  440  837\n",
            "  2452  224  154 2472   31   23  213  440   18   78  159 3174    5    4\n",
            "   106  172    1    1 2666   23  905 1171  218   78   20 2021  160   23\n",
            "   196 1213]]\n",
            "Value estimates: tf.Tensor([[2.7751842e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10009965 0.09999693 0.10018088 0.10015289 0.1000379  0.09997039\n",
            " 0.0998873  0.09980321 0.09985448 0.10001636], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000996 0.0999997  0.10001808 0.10001529 0.10000379 0.09999704\n",
            " 0.09998873 0.09998032 0.09998545 0.10000164]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.7751842e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-6.390092e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "gave gift brother fan hot sauce thought give try wooden packaging looked nice sturdy enough could used br brother say liked sauce would share chirstmas day never got chance try\n",
            "-----------\n",
            "Input sequence: [[ 279  251 1248  344   38  117  131   72   36 2780  291  423   82 1920\n",
            "   100   46   49    1 1248   52  262  117   13  819 5271   55   95   81\n",
            "   744   36    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.1778328e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002309 0.09996381 0.10000888 0.10005385 0.10000661 0.10000264\n",
            " 0.0999961  0.09999237 0.09997701 0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999638 0.10000088 0.10000538 0.10000066 0.10000026\n",
            " 0.09999961 0.09999923 0.0999977  0.09999756]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.1778328e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.7120466e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "good corn product eating case corn way faster expected well packed store pantry nicely\n",
            "-----------\n",
            "Input sequence: [[   3  230    6  122  147  230   65 1898  467   40  630   41 1493  781\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-5.55524e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002314 0.0999638  0.10000893 0.10005393 0.10000663 0.10000264\n",
            " 0.09999607 0.09999231 0.09997697 0.0999756 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000023  0.09999637 0.10000089 0.10000539 0.10000066 0.10000026\n",
            " 0.09999961 0.09999923 0.09999769 0.09999756]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[5.55524e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.2791444e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "excellent coffee people tight schedule fiancee fell love brother law one everyone visit house try cup keep coming back also like fact wide variety coffee flavor choose\n",
            "-----------\n",
            "Input sequence: [[ 140   12  170 1542 1995 9457 1117    9 1248 2109    7  256 1215  363\n",
            "    36   43   99  866  136   24    2  245 1966  157   12    5  955    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-8.132325e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002316 0.09996379 0.10000897 0.10005396 0.10000664 0.10000262\n",
            " 0.09999604 0.09999227 0.09997693 0.09997561], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000232 0.09999639 0.1000009  0.1000054  0.10000066 0.10000026\n",
            " 0.09999961 0.09999923 0.0999977  0.09999757]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[8.132325e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.8725435e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "tried martha white turtle fudge chocolate chip cookie recipe worst cooky ever made either someone staff martha white lopsided sense humor taste bud taken permanent vacation wasted time lot money chocolate pecan white either need tweek recipe take website unsuspecting housewife waste money time worthless cooky husband picked one way kitchen within two second came back threw garbage\n",
            "-----------\n",
            "Input sequence: [[  28 4485  198 5052 2359   35   10  403  160  878  141   92   44  286\n",
            "   400 2385 4485  198 7893 1275 7894    4 1039 1303 4487 1662 1865   19\n",
            "    75  217   35 2259  198  286  101 5619  160  112  601 3993 7895  603\n",
            "   217   19 5273  141  195  901    7   65  762  735   79  332  174  136\n",
            "  1107 1381    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.8609918e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002316 0.09996382 0.10000901 0.10005395 0.10000664 0.10000262\n",
            " 0.09999602 0.09999223 0.09997692 0.09997564], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000232 0.09999639 0.1000009  0.1000054  0.10000066 0.10000027\n",
            " 0.09999961 0.09999923 0.09999769 0.09999757]\n",
            "Generated summary: one\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.8609918e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-6.5876684e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "cold weather brew tea pot keep simmering brew lemon ginger ginger lemon tea cup made base husband drink ca get use medicinal hate licorise helped great deal last winter\n",
            "-----------\n",
            "Input sequence: [[ 469 1495  413   14  685   99 7633  413  665  493  493  665   14   43\n",
            "    44 1075  195   64   86   17   23 2208  613 7634  921    8  235  182\n",
            "  1061    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[8.030537e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002316 0.09996383 0.10000903 0.10005395 0.10000664 0.10000262\n",
            " 0.099996   0.09999219 0.0999769  0.09997564], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000232 0.09999639 0.1000009  0.1000054  0.10000066 0.10000026\n",
            " 0.0999996  0.09999922 0.09999769 0.09999757]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-8.030537e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.8490931e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "practically fall category healthy snack well almost single serving bag mean wo overeating fact anyway greasy way made huge plus nice crisp crunch bag filled air part good job keeping chip whole case got though two bag containted nothing broken bit rest couple broken chip broken one also noticed find nearly much coating flavoring finger experienced eating br br purchasing case try flavor good idea decent value flavor incredibly strong point like wo ordering mixed case salt pepper tasted like pepper making hot tasting chip seasalt vinegar really strong vinegar taste enjoy love bbq flavored chip kind strong probably would purchase bbq one future would say someone offered original really bland compared others br br one liked sour cream onion cheddar milder br br give star liked flavor definitely high mark type chip size serving fact try flavor one order\n",
            "-----------\n",
            "Input sequence: [[  66  549  268  546   10  546    7   24  531   31  691   20 1732  791\n",
            "  1138 1980  122    1    1  532  147   36    5    3  434  632  399    5\n",
            "  1926  145  390    2  228  259  471  147   76  314  166    2  314  223\n",
            "    38  218   10 8116  239   18  145  239    4  120    9  438  349   10\n",
            "   210  145  208   13  148  438    7  850   13   52  400 1124  327   18\n",
            "   646  529  225    1    1    7  262  449  224  548  534 1884    1    1\n",
            "    72  183  262    5  138  149 1601  287   10  113  255  245   36    5\n",
            "     7   60]]\n",
            "Value estimates: tf.Tensor([[-5.7855623e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000232  0.09996383 0.10000907 0.10005401 0.10000665 0.10000262\n",
            " 0.09999599 0.09999218 0.09997688 0.09997565], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000232 0.09999638 0.1000009  0.1000054  0.10000066 0.10000026\n",
            " 0.0999996  0.09999921 0.09999768 0.09999756]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[5.7855623e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.3321783e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "product described shipped promptly consuming part medically supervised diet bread allowed\n",
            "-----------\n",
            "Input sequence: [[    6  1788   382  1860  1491   387  6231 10743   171   233  1382     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[4.252388e-08]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000232  0.09996383 0.10000909 0.10005401 0.10000665 0.10000261\n",
            " 0.09999597 0.09999213 0.09997685 0.09997565], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000232 0.09999638 0.1000009  0.1000054  0.10000066 0.10000026\n",
            " 0.09999959 0.09999921 0.09999768 0.09999756]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-4.252388e-08]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-9.791485e-08, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "working always carry lunch much better food court much better regulation nutrient intake finding item high protein without high fat difficult task tuna excellent little chicken sea white tuna cup fill bill put one lunch fresh fruit veggie item perhaps dried fruit nut good nutrition worry weight gain also camping like take batch tuna cup along case cup size right one br br minor problem latest tuna cup might batch problem latest tuna dry almost choke seemed rather tasteless cup past seemed much better satisfied present one however like product serving size deter future br br gary peterson\n",
            "-----------\n",
            "Input sequence: [[ 925  103  441  451   20   30   11 9241   20   30 9242 1228  992  637\n",
            "   137  149  361   85  149  150  552 6099  864  140   26  176  494  198\n",
            "   864   43  894  932  130    7  451  127  281  667  137  692  761  281\n",
            "   339    3  719  972  294  959   24 2141    2  112  577  864   43  448\n",
            "   147   43  113   98    7    1    1 2969  119 1987  864   43  250  577\n",
            "   119 1987  864  275  169 2271  647  299 1223   43  500  647   20   30\n",
            "   833 1239    7  121    2    6  255  113 9243  850    1    1 3082 3083\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.164287e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002322 0.09996383 0.10000911 0.10005402 0.10000666 0.1000026\n",
            " 0.09999595 0.09999211 0.09997684 0.09997565], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000232 0.09999638 0.1000009  0.1000054  0.10000066 0.10000025\n",
            " 0.09999959 0.09999921 0.09999768 0.09999756]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.164287e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.6808714e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "liked idea small popcorn pop really well popper much popcorn flavor pretty bummed\n",
            "-----------\n",
            "Input sequence: [[ 262  434  109  232  329   18   40  941   20  232    5  133 3715    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[4.1325347e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002322 0.09996385 0.10000913 0.10005403 0.10000667 0.1000026\n",
            " 0.09999595 0.0999921  0.09997683 0.09997567], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000232 0.09999638 0.1000009  0.1000054  0.10000066 0.10000025\n",
            " 0.09999959 0.0999992  0.09999768 0.09999756]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-4.1325347e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-9.515495e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "coffee great organic ingredient pesticide worry plus taste good healing effect ganoderma\n",
            "-----------\n",
            "Input sequence: [[  12    8   94   61 2248  972  272    4    3 3469  857 6596    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-5.430302e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002323 0.09996383 0.10000915 0.10005405 0.10000666 0.10000259\n",
            " 0.09999593 0.09999207 0.09997681 0.09997567], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000091 0.10000541 0.10000067 0.10000026\n",
            " 0.0999996  0.09999921 0.09999768 0.09999757]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[5.430302e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.250376e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "great chip taste br seem much better br need buy big bag\n",
            "-----------\n",
            "Input sequence: [[  8  10   4   1 321  20  30   1 101  25 164  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "Value estimates: tf.Tensor([[-4.250221e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002324 0.09996386 0.10000917 0.10005405 0.10000667 0.10000259\n",
            " 0.09999593 0.09999205 0.09997681 0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000093 0.10000541 0.10000067 0.10000026\n",
            " 0.0999996  0.09999921 0.09999768 0.09999757]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[4.250221e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(9.786498e-07, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "ca kind coffee maker work forced buy coffee shop starbuck across street economy one want pay high price started coffee club u buy coffee bag separate creamer enjoy fresh hot tasty coffee every day without paying coffee shop price thanks folgers\n",
            "-----------\n",
            "Input sequence: [[  86  210   12  519   87 2942   25   12  671 3635  996 3694 2950    7\n",
            "    80  503  149   27  307   12 2011  203   25   12   16 1745  845  120\n",
            "   127   38  118   12   90   55   85  971   12  671   27  401 2951    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.1916869e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002323 0.09996387 0.10000917 0.10005403 0.10000666 0.10000259\n",
            " 0.0999959  0.09999203 0.09997679 0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000232 0.09999639 0.10000092 0.1000054  0.10000066 0.10000025\n",
            " 0.09999958 0.0999992  0.09999767 0.09999757]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.1916869e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.7439464e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "seldom unpopped kernel nice flavor wonderful whole lot say popcorn always buy guy continue\n",
            "-----------\n",
            "Input sequence: [[8952 3340  801   82    5  179  139   75   52  232  103   25  649  590\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-6.502481e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002325 0.09996384 0.1000092  0.10005409 0.10000668 0.10000259\n",
            " 0.0999959  0.09999201 0.09997676 0.09997567], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000091 0.10000541 0.10000067 0.10000026\n",
            " 0.0999996  0.0999992  0.09999768 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[6.502481e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.4972558e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "originally received mix gift friend gift pack family tried gift loved immediately super yummy waffle mix waffle turn tasting delicious need add topping butter placing yet another order waffle mix go quickly around house since everyone favorite breakfast item\n",
            "-----------\n",
            "Input sequence: [[1270  229   29  251  200  251   67  143   28  251  199  732  370  433\n",
            "   180   29  180  605  218   70  101   78 1335  280 4565  347  194   60\n",
            "   180   29   53  487  209  363   63  256   58  417  137    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.0031401e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002328 0.09996384 0.10000921 0.1000541  0.10000668 0.10000259\n",
            " 0.09999589 0.099992   0.09997676 0.09997567], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999638 0.10000091 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.0999992  0.09999768 0.09999757]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.0031401e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.3098255e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "excellent quality flaxseed toasted little pan even made great snack also powdered coffee grinder toasting little powder delicious delicious nutritious awesome planning cereal tomorrow maybe sprinkle veggie think also try bob quinoa museli\n",
            "-----------\n",
            "Input sequence: [[ 140   88 1083 2713   26  942   34   44    8   77   24  961   12 2010\n",
            "  4669   26  227   70   70 1273  424 2528  462 4212  258 1497  667   59\n",
            "    24   36 1142 3025 8790    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[7.0204364e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002325 0.09996387 0.10000922 0.10005406 0.10000667 0.10000259\n",
            " 0.09999589 0.09999198 0.09997678 0.09997569], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000093 0.10000541 0.10000067 0.10000026\n",
            " 0.0999996  0.0999992  0.09999768 0.09999757]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.0204364e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.6165104e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "ordered beef turkey flavor dog would even take mouth flavor dry real aroma try small quantity first donated entire order humane society\n",
            "-----------\n",
            "Input sequence: [[  93  638 1470    5   21   13   34  112  353    5  275  177  492   36\n",
            "   109  782   45 2961  688   60 5425 5426    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[8.356321e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002326 0.09996387 0.10000923 0.10005406 0.10000667 0.10000259\n",
            " 0.09999588 0.09999198 0.09997676 0.09997569], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000093 0.10000541 0.10000067 0.10000026\n",
            " 0.0999996  0.0999992  0.09999768 0.09999757]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-8.356321e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.9241073e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "chip best tasted filled chemical taste tangy vinegar well potato greasy perfectly crispy like salt vinegar tanginess even bother try definitely zip love child friend love even year old love\n",
            "-----------\n",
            "Input sequence: [[  10   22  166  948  604    4 1235  239   40   69  609  779  586    2\n",
            "    76  239 6840   34 1384   36  138 2211    9  616  200    9   34   48\n",
            "   111    9    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.3145378e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002328 0.09996385 0.10000924 0.10005412 0.10000669 0.10000258\n",
            " 0.09999587 0.09999196 0.09997674 0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999638 0.10000093 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.0999992  0.09999767 0.09999757]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.3145378e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.0268524e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "loved original oreo cakesters first debuted shied away eating regular basis high calorie fat content serving saw commercial calorie version could hardly wait try must say impressed br br calorie snack cake dry mealy consistency cake moist decadent taste like original smaller would recommend anyone liked original version watching calorie good job nabisco\n",
            "-----------\n",
            "Input sequence: [[ 199  327  312 1305   45 9102 9103  197  122   91 1301  149   84  150\n",
            "   476  255  498 1219   84  365   46 1376  690   36  316   52  717    1\n",
            "     1   84   77  167  275 5187  776  167  967 4028    4    2  327  453\n",
            "    13   56  328  262  327  365 1182   84    3  969 1178    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[6.0115067e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002327 0.09996387 0.10000925 0.10005409 0.10000668 0.10000257\n",
            " 0.09999587 0.09999196 0.09997676 0.09997569], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000093 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.0999992  0.09999768 0.09999757]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-6.0115067e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.3841969e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "pleased product would definitely recommend dog jack russell dachshund enjoy newman dog food liked knowing organic kibble perfect size easy chewing dog enjoyed newman month nibbled decided alternate month another dog food give dog variety\n",
            "-----------\n",
            "Input sequence: [[ 406    6   13  138   56   21 1066 2578 3804  120  211   21   11  262\n",
            "  1719   94  965  110  113   89 1127   21  468  211  142 6339  243 5690\n",
            "   142  194   21   11   72   21  157    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[2.1029698e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002328 0.09996387 0.10000926 0.10005409 0.10000668 0.10000258\n",
            " 0.09999587 0.09999195 0.09997674 0.0999757 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000093 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.0999992  0.09999768 0.09999757]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-2.1029698e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-4.8422626e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "really worried ordered phantom power would make overheat apparently worried nothing use paired blue yeti pro seriously beefy microphone running shielded cable eighty foot away absolutely great br br one downside seen piece kit occasionally register usb device granted seen happen always want double check connection\n",
            "-----------\n",
            "Input sequence: [[   18  1267    93  1961   865    13    15 10214  1320  1267   226    23\n",
            "   3211   489 10215  1003   970 10216  1546   856  4816  1547 10217  1552\n",
            "    197   300     8     1     1     7  1737   734   293   718  2291  5853\n",
            "    814  1177  1627   734  1276   103    80  1009   892  3041     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "Value estimates: tf.Tensor([[1.00015654e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002329 0.09996387 0.10000926 0.10005412 0.10000669 0.10000258\n",
            " 0.09999587 0.09999195 0.09997674 0.0999757 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000093 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.09999919 0.09999767 0.09999757]\n",
            "Generated summary: love\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.00015654e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.3029455e-07, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "appears little watery taste bad kid fascinated keurig probably enjoy\n",
            "-----------\n",
            "Input sequence: [[1439   26  752    4  105  202 9510  288  208  120    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-6.799393e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002329 0.09996386 0.10000927 0.10005412 0.10000669 0.10000257\n",
            " 0.09999586 0.09999193 0.09997673 0.09997569], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999638 0.10000093 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.09999919 0.09999767 0.09999757]\n",
            "Generated summary: flavor\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[6.799393e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.5656227e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "soon got bag decaf made big mug filled house wonderful aroma high quality fresh brewed coffee finely ground still used amount normally turned great added soy milk sat back enjoyed rare treat coffee break definitely buy winter month treat excellent hot coffee time day night\n",
            "-----------\n",
            "Input sequence: [[ 513   81   16  244   44  164 1131  948  363  179  492  149   88  127\n",
            "   933   12 2414  379   74   49  173  729  780    8  213  388  114 2107\n",
            "   136  468 1921  129   12  760  138   25 1061  142  129  140   38   12\n",
            "    19   55  566    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.3896876e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002993 0.09994725 0.09999792 0.10006031 0.09999974 0.10001162\n",
            " 0.10000887 0.09999903 0.09998255 0.09996271], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000299 0.09999473 0.09999979 0.10000603 0.09999997 0.10000116\n",
            " 0.10000088 0.0999999  0.09999826 0.09999627]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.3896876e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-3.1998723e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "used daughter candy land birthday party kid loved full size still sooooo cute\n",
            "-----------\n",
            "Input sequence: [[  49  325  267 3147 1135  643  202  199  206  113   74 2802  973    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[7.3350093e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002328 0.09996389 0.10000927 0.10005409 0.10000668 0.10000258\n",
            " 0.09999585 0.09999193 0.09997673 0.09997571], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000093 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.09999919 0.09999768 0.09999757]\n",
            "Generated summary: br\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-7.3350093e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.6889428e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "tried every coffee brand available keurig one far best extraordinarily smooth rich closest starbucks thing add healthy splash bolthouse good\n",
            "-----------\n",
            "Input sequence: [[  28   90   12   33  240  288    7  126   22 8632  270  298 1939  550\n",
            "    54   78  107  916 8633    3    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[5.0313247e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10006606 0.0999824  0.10010532 0.10010943 0.10002418 0.09998458\n",
            " 0.09993508 0.09988625 0.09990829 0.09999847], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.1000066  0.09999824 0.10001053 0.10001094 0.10000242 0.09999846\n",
            " 0.09999351 0.09998862 0.09999083 0.09999985]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-5.0313247e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.1585053e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "smooth rich flavor even largest setting dark blend satisfying cup coffee recommend friend product arrived time well packaged\n",
            "-----------\n",
            "Input sequence: [[ 270  298    5   34 3532  591  212  221  785   43   12   56  200    6\n",
            "   238   19   40  480    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.0570365e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002331 0.09996385 0.10000928 0.10005415 0.10000669 0.10000258\n",
            " 0.09999584 0.09999191 0.09997671 0.09997568], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999638 0.10000093 0.10000541 0.10000066 0.10000025\n",
            " 0.09999958 0.09999918 0.09999767 0.09999757]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.0570365e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.4339275e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "great candy family loved smaller imagined thought expensive small however germany get easier shipping usa make expenive great product fun usa family receive\n",
            "-----------\n",
            "Input sequence: [[   8  267  143  199  453 3232  131  192  109  121 2915   17  687  146\n",
            "  1200   15 7160    8    6  660 1200  143 1071    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.2313583e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000233  0.09996387 0.10000929 0.10005412 0.10000669 0.10000257\n",
            " 0.09999584 0.09999191 0.09997671 0.0999757 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999638 0.10000093 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.09999919 0.09999767 0.09999757]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.2313583e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-7.4404666e-06, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "trying eat healthier one thing really love chip salty snack kind popchips really trick satisfying craving though really care pepper flavor like others buy\n",
            "-----------\n",
            "Input sequence: [[ 215   42  355    7   54   18    9   10  302   77  210  375   18 1184\n",
            "   785  620  134   18  412  314    5    2  225   25    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[5.642321e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002422 0.09996428 0.10001135 0.1000553  0.10000706 0.10000219\n",
            " 0.09999454 0.09998965 0.09997525 0.09997619], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000242 0.09999643 0.10000114 0.10000553 0.10000071 0.10000022\n",
            " 0.09999945 0.09999897 0.09999753 0.09999762]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-5.642321e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.29918935e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "must bit wuss soup taste imagine fire might taste typically like spicy food good flavor find case soup flavor killed burn\n",
            "-----------\n",
            "Input sequence: [[ 316   66 6552  331    4 1024 4020  250    4 1570    2  246   11    3\n",
            "     5   31  147  331    5 4930 1318    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[3.8784674e-07]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002331 0.09996387 0.10000931 0.10005414 0.10000669 0.10000258\n",
            " 0.09999584 0.0999919  0.09997671 0.0999757 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999638 0.10000093 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.09999919 0.09999767 0.09999757]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-3.8784674e-07]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-8.9304996e-07, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love oreo hate filling prevent scape filling good calorie wise\n",
            "-----------\n",
            "Input sequence: [[   9  312  613  662 2018 9118  662    3   84 1809    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.1429278e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002332 0.09996386 0.10000931 0.10005416 0.10000669 0.10000257\n",
            " 0.09999583 0.09999189 0.09997669 0.0999757 ], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000093 0.10000542 0.10000067 0.10000025\n",
            " 0.09999958 0.09999919 0.09999767 0.09999757]\n",
            "Generated summary: UNK\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.1429278e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.6317017e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "happy amazon got back could order second case eat wheat pack pound around middle bread wheat gluten free cost way br br eaten kind rice cake found break apart spreading nut butter also generally rice cake pkg round regular rice cake package rice cake piece bag also much like consuming slice bread without crust nice thin eat much good br br try dissatisfied regular rice cake must gluten free bread believe sorry amazon price good free shipping though box sort big pretty light store easily away live alone next last pkg first case stale stored cool dark garage original cardboard br br also made belgium help anyone packaging air tight come pkgs box perfect sized box mine arrived without sign damage yet find even single cracked rice cake rather neutral taste make special butter spread like real well take equal part room temperature butter olive oil water blend ingredient smooth refrigerate set get hard always spreadable taste really good use organic butter olive oil filtered water spread good believe better straight br br also use one cake make single sided sandwich rice cake using two would two piece bread seem work well single sided sandwhich rice cake enjoyable br br hope help decide try everyone given good comment\n",
            "-----------\n",
            "Input sequence: [[ 655 1542   97 9431   37  110 1051   37  581  238   85 1389 1825  347\n",
            "    31   34  335 2125  181  167  299 6152    4   15  461  280  898    2\n",
            "   177   40  112 1396  387 1251 1697  280  473  128   39  221   61  270\n",
            "  3760  510   17  116  103 9432    4   18    3   23   94  280  473  128\n",
            "  2771   39  898    3  319   30 1012    1    1   24   23    7  167   15\n",
            "   335 4759  561  181  167  102   79   13   79  293  233  321   87   40\n",
            "   335 4759 9433  181  167 1362    1    1  428  247 1853   36  256  485\n",
            "     3 1167]]\n",
            "Value estimates: tf.Tensor([[8.167993e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000233  0.09996387 0.10000931 0.10005412 0.10000668 0.10000256\n",
            " 0.09999582 0.09999188 0.0999767  0.09997571], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000093 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.09999919 0.09999767 0.09999757]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-8.167993e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.8807432e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "product taste stale full artificial br real peppermint product honest doesnt even taste like real cocoa either\n",
            "-----------\n",
            "Input sequence: [[   6    4  610  206  373    1  177  540    6 1337 2473   34    4    2\n",
            "   177  108  286    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[9.033944e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.1000233  0.09996388 0.10000931 0.10005412 0.10000669 0.10000256\n",
            " 0.09999583 0.09999187 0.0999767  0.09997571], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999639 0.10000093 0.10000541 0.10000067 0.10000025\n",
            " 0.09999958 0.09999918 0.09999767 0.09999757]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-9.033944e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.0801343e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "love pico pica add flavor hot eat least meal every day good egg good pizza good br br really ca go wrong\n",
            "-----------\n",
            "Input sequence: [[   9 2675 3053   78    5   38   42  290  248   90   55    3  306    3\n",
            "   648    3    1    1   18   86   53  478    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.6921935e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002334 0.09996384 0.10000933 0.10005418 0.1000067  0.10000257\n",
            " 0.09999582 0.09999187 0.09997667 0.09997569], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999638 0.10000093 0.10000542 0.10000067 0.10000025\n",
            " 0.09999958 0.09999919 0.09999767 0.09999757]\n",
            "Generated summary: like\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.6921935e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(3.8964485e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "honey dijon chip bring terrific balance salty tangy sweet crunchy brand tried use much mustard flavor overpowers honey dijon br br chip make great side dish bbq plate baked bean coleslaw potato salad grilled meat naturally also go great br br oregonian proud share delectable snack friend especially living outside state experienced gourmet chip tell kettle brand potato chip microbrews br br kettle brand potato chip unmistakable light gold color rich flavor amazing crunch kettle brand chip also healthier snacking option major chip brand kettle brand chip trans fat msg artificial flavor coloring company also line organic potato chip product certified br br also recommend kettle chip flavor http kettle chip sea salt vinegar http kettle chip spicy thai br br annette solomon reporter salem statesman journal recently noted glass wine go nicely chip solomon wrote could missing wonderful pairing chip spicy would want select white wine also moderate amount acid subdue strong flavor ginger lime garlic cilantro without classically riesling fit parameter perfectly\n",
            "-----------\n",
            "Input sequence: [[  69   10 3561  196 1023  421  298    5  323  391  191   33   10   24\n",
            "   355 1086  386 1266   10   33  191   33   10  883  150 1011  373    5\n",
            "  2025  185   24  477   94   69   10    6  678    1    1   24   56  191\n",
            "    10    5  282  191   10  494   76  239  282  191   10  246  618    1\n",
            "     1 4160 2870 4161 4162 4163 3562  398 1716  756  654   53  781   10\n",
            "  2870 2026   46 1231  179 3182   10  246   13   80 1778  198  654   24\n",
            "  2262  173  556 4164  145    5  493 2027  518 1724   85 4165 3563  733\n",
            "  4166  779]]\n",
            "Value estimates: tf.Tensor([[4.6286013e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10005229 0.09997642 0.10007438 0.10009161 0.10001854 0.09999038\n",
            " 0.09995463 0.09992026 0.09993031 0.09999114], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000522 0.09999764 0.10000743 0.10000916 0.10000185 0.09999903\n",
            " 0.09999546 0.09999202 0.09999304 0.09999911]\n",
            "Generated summary: good\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-4.6286013e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-1.0657728e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "even though item listed gluten free category ingredient state contains wheat protein order need gf food bad reviewing amazon\n",
            "-----------\n",
            "Input sequence: [[  34  134  137  896  115   57 2618   61  716  572  360  361   60  101\n",
            "   369   11  105 2655   32    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[1.241018e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002332 0.09996389 0.10000935 0.10005414 0.10000669 0.10000256\n",
            " 0.09999581 0.09999183 0.09997667 0.09997572], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.0999964  0.10000094 0.10000542 0.10000068 0.10000027\n",
            " 0.09999958 0.09999919 0.09999767 0.09999758]\n",
            "Generated summary: taste\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[-1.241018e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(-2.8575343e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "excited try sauce based review nothing special taste way sweet nearly spicy enough even kid agree reminds honey mixed sweet pickle relish sound good go interested something spicy hot even little sour might want keep looking\n",
            "-----------\n",
            "Input sequence: [[ 738   36  117  639   83  226  461    4   65   62  691  246  100   34\n",
            "   202  790 1586  351  471   62 2829 4593  530    3   53 1579   96  246\n",
            "    38   34   26  449  250   80   99  152    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-1.00530415e-05]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002336 0.09996387 0.1000094  0.10005422 0.10000671 0.10000256\n",
            " 0.09999578 0.0999918  0.09997664 0.09997571], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000233 0.09999638 0.10000093 0.10000542 0.10000067 0.10000025\n",
            " 0.09999958 0.09999917 0.09999766 0.09999757]\n",
            "Generated summary: product\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[1.00530415e-05]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(2.3148084e-05, shape=(), dtype=float32)\n",
            "INPUT TEXT:\n",
            "bought daughter grad party well strawberry love thing great product\n",
            "-----------\n",
            "Input sequence: [[  51  325 3662  643   40  682    9   54    8    6    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "Value estimates: tf.Tensor([[-6.6139937e-06]], shape=(1, 1), dtype=float32)\n",
            "Action probabilities before softmax: tf.Tensor(\n",
            "[0.10002336 0.09996387 0.10000941 0.10005422 0.10000671 0.10000255\n",
            " 0.09999576 0.09999177 0.09997661 0.09997571], shape=(10,), dtype=float32)\n",
            "Action probabilities after softmax: [0.10000234 0.09999639 0.10000095 0.10000543 0.10000068 0.10000026\n",
            " 0.09999958 0.09999919 0.09999767 0.09999758]\n",
            "Generated summary: great\n",
            "Raw reward (ROUGE score): 0.0\n",
            "Clipped reward: 0.0\n",
            "Normalized reward: 0.0\n",
            "Returns: [0.]\n",
            "Advantages: tf.Tensor([[6.6139937e-06]], shape=(1, 1), dtype=float32)\n",
            "Loss: tf.Tensor(1.5229327e-05, shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Training loop with reward normalization, reward clipping, and compute returns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize variables\n",
        "losses = []\n",
        "epoch_losses = []\n",
        "# Reward clipping function\n",
        "def clip_reward(reward):\n",
        "    return max(min(reward, 1.0), -1.0)\n",
        "\n",
        "# Compute returns function\n",
        "def compute_returns(rewards, gamma):\n",
        "    returns = []\n",
        "    G = 0\n",
        "    for r in reversed(rewards):\n",
        "        G = r + gamma * G\n",
        "        returns.insert(0, G)\n",
        "    return np.array(returns)\n",
        "\n",
        "# Training loop\n",
        "NUM_EPOCHS = 3\n",
        "gamma = 0.99  # Discount factor\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for text, summary in zip(X_train, y_train):\n",
        "        # Preprocess input text\n",
        "        print(\"INPUT TEXT:\")\n",
        "        print(text)\n",
        "        print(\"-----------\")\n",
        "        state = tokenizer.texts_to_sequences([text])\n",
        "        state = tf.keras.preprocessing.sequence.pad_sequences(state, maxlen=max_length, padding='post')\n",
        "        if np.isnan(state).any():\n",
        "            print(\"NaN values found in input sequence:\", state)\n",
        "            continue\n",
        "        print(\"Input sequence:\", state)  # Debug print\n",
        "        # Forward pass through critic network to get value estimates\n",
        "        _, value = actor_critic(state)\n",
        "        if np.isnan(value).any():\n",
        "            print(\"NaN values found in value estimates:\", value)\n",
        "            continue\n",
        "        print(\"Value estimates:\", value)  # Debug print\n",
        "        # Generate summary using the actor network\n",
        "        generated_summary = generate_summary(actor_critic, text)\n",
        "        print(\"Generated summary:\", generated_summary)  # Debug print\n",
        "        # Calculate reward (ROUGE score)\n",
        "        reward = calculate_rouge(str(generated_summary), str(summary))\n",
        "        print(\"Raw reward (ROUGE score):\", reward)  # Debug print\n",
        "        # Reward clipping\n",
        "        reward = clip_reward(reward)\n",
        "        print(\"Clipped reward:\", reward)  # Debug print\n",
        "        # Normalize reward\n",
        "        reward = (reward - np.mean(reward)) / (np.std(reward) + 1e-8)\n",
        "        print(\"Normalized reward:\", reward)  # Debug print\n",
        "        # Compute returns and advantages\n",
        "        returns = compute_returns([reward], gamma)\n",
        "        print(\"Returns:\", returns)  # Debug print\n",
        "        advantages = returns - value\n",
        "        print(\"Advantages:\", advantages)  # Debug print\n",
        "        # Perform training step\n",
        "        loss = train_step(actor_critic, state, summary, returns, advantages)\n",
        "        print(\"Loss:\", loss)  # Debug print\n",
        "        epoch_losses.append(loss)\n",
        "    epoch_loss_avg = np.mean(epoch_losses)\n",
        "    losses.append(epoch_loss_avg)\n",
        "\n",
        "# Plot the loss graph\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKEhS1UrLBBj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}